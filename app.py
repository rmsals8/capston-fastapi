import logging
import asyncio
import copy
import sys
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from typing import Dict, List, Any, Optional, Set, Tuple
import os
import json
import re
import time
import datetime
from dotenv import load_dotenv
import aiohttp
import math
from openai import OpenAI

# ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ ì„í¬íŠ¸
from scheduler.utils import detect_and_resolve_time_conflicts
from scheduler import (
    create_enhancement_chain,
    apply_time_inference,
    apply_priorities,
    enhance_schedule_with_relationships,
    parse_datetime,
    generate_multiple_options  
)

 
# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),  # ì½˜ì†” ì¶œë ¥ ëª…ì‹œ
        logging.StreamHandler(sys.stderr)   # ì—ëŸ¬ë„ í™•ì‹¤íˆ ì¶œë ¥
    ]
)

# ëª¨ë“  ë¡œê±° ë ˆë²¨ ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ë‹¤ë¥¸ ëª¨ë“ˆë“¤ë„ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
scheduler_logger = logging.getLogger('multiple_options')
scheduler_logger.setLevel(logging.INFO)

relationship_logger = logging.getLogger('relationship_analyzer')
relationship_logger.setLevel(logging.INFO)

priority_logger = logging.getLogger('priority_analyzer')
priority_logger.setLevel(logging.INFO)

time_logger = logging.getLogger('time_inference')
time_logger.setLevel(logging.INFO)

utils_logger = logging.getLogger('scheduler.utils')
utils_logger.setLevel(logging.INFO)

# ë¡œê·¸ í…ŒìŠ¤íŠ¸
logger.info("ğŸ”¥ ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
logger.info(f"   í˜„ì¬ ë¡œê·¸ ë ˆë²¨: {logger.level}")
logger.info(f"   í•¸ë“¤ëŸ¬ ìˆ˜: {len(logger.handlers)}")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì „ì— ë¡œê·¸
logger.info("ğŸ“ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹œì‘")
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
# API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") 
GOOGLE_MAPS_API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")
KAKAO_REST_API_KEY = os.getenv("KAKAO_REST_API_KEY", "357d3401893dc5c9cbefc83bb65df4ee")
FOURSQUARE_API_KEY = os.getenv("FOURSQUARE_API_KEY", "fsq3VpVQLn5hZptfpIHLogZHRb7vAbteiSkiUlZT4QvpC8U=")

if not OPENAI_API_KEY:
    logger.error("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    raise ValueError("OPENAI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="3ì¤‘ API ì •í™•í•œ ì£¼ì†Œ ê²€ìƒ‰ ì¼ì • ì¶”ì¶œ API", version="3.0.0")

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í•œêµ­ ì§€ì—­ ì •ë³´
KOREA_REGIONS = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": {"ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
               "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
               "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"},
    "ë¶€ì‚°ê´‘ì—­ì‹œ": {"ê°•ì„œêµ¬", "ê¸ˆì •êµ¬", "ê¸°ì¥êµ°", "ë‚¨êµ¬", "ë™êµ¬", "ë™ë˜êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë¶êµ¬", "ì‚¬ìƒêµ¬",
               "ì‚¬í•˜êµ¬", "ì„œêµ¬", "ìˆ˜ì˜êµ¬", "ì—°ì œêµ¬", "ì˜ë„êµ¬", "ì¤‘êµ¬", "í•´ìš´ëŒ€êµ¬"},
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": {"ë‚¨êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬", "ìˆ˜ì„±êµ¬", "ì¤‘êµ¬"},
    "ì¸ì²œê´‘ì—­ì‹œ": {"ê°•í™”êµ°", "ê³„ì–‘êµ¬", "ë‚¨ë™êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ë¶€í‰êµ¬", "ì„œêµ¬", "ì—°ìˆ˜êµ¬", "ì˜¹ì§„êµ°", "ì¤‘êµ¬"},
    "ê´‘ì£¼ê´‘ì—­ì‹œ": {"ê´‘ì‚°êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬"},
    "ëŒ€ì „ê´‘ì—­ì‹œ": {"ëŒ€ë•êµ¬", "ë™êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ì¤‘êµ¬"},
    "ìš¸ì‚°ê´‘ì—­ì‹œ": {"ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°", "ì¤‘êµ¬"},
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {"ì„¸ì¢…ì‹œ"},
    "ê²½ê¸°ë„": {"ê°€í‰êµ°", "ê³ ì–‘ì‹œ", "ê³¼ì²œì‹œ", "ê´‘ëª…ì‹œ", "ê´‘ì£¼ì‹œ", "êµ¬ë¦¬ì‹œ", "êµ°í¬ì‹œ", "ê¹€í¬ì‹œ", "ë‚¨ì–‘ì£¼ì‹œ",
             "ë™ë‘ì²œì‹œ", "ë¶€ì²œì‹œ", "ì„±ë‚¨ì‹œ", "ìˆ˜ì›ì‹œ", "ì‹œí¥ì‹œ", "ì•ˆì‚°ì‹œ", "ì•ˆì„±ì‹œ", "ì•ˆì–‘ì‹œ", "ì–‘ì£¼ì‹œ",
             "ì–‘í‰êµ°", "ì—¬ì£¼ì‹œ", "ì—°ì²œêµ°", "ì˜¤ì‚°ì‹œ", "ìš©ì¸ì‹œ", "ì˜ì™•ì‹œ", "ì˜ì •ë¶€ì‹œ", "ì´ì²œì‹œ", "íŒŒì£¼ì‹œ",
             "í‰íƒì‹œ", "í¬ì²œì‹œ", "í•˜ë‚¨ì‹œ", "í™”ì„±ì‹œ"},
    "ê°•ì›íŠ¹ë³„ìì¹˜ë„": {"ê°•ë¦‰ì‹œ", "ê³ ì„±êµ°", "ë™í•´ì‹œ", "ì‚¼ì²™ì‹œ", "ì†ì´ˆì‹œ", "ì–‘êµ¬êµ°", "ì–‘ì–‘êµ°", "ì˜ì›”êµ°", "ì›ì£¼ì‹œ",
                  "ì¸ì œêµ°", "ì •ì„ êµ°", "ì² ì›êµ°", "ì¶˜ì²œì‹œ", "íƒœë°±ì‹œ", "í‰ì°½êµ°", "í™ì²œêµ°", "í™”ì²œêµ°", "íš¡ì„±êµ°"},
    "ì¶©ì²­ë¶ë„": {"ê´´ì‚°êµ°", "ë‹¨ì–‘êµ°", "ë³´ì€êµ°", "ì˜ë™êµ°", "ì˜¥ì²œêµ°", "ìŒì„±êµ°", "ì œì²œì‹œ", "ì¦í‰êµ°", "ì§„ì²œêµ°", "ì²­ì£¼ì‹œ", "ì¶©ì£¼ì‹œ"},
    "ì¶©ì²­ë‚¨ë„": {"ê³„ë£¡ì‹œ", "ê³µì£¼ì‹œ", "ê¸ˆì‚°êµ°", "ë…¼ì‚°ì‹œ", "ë‹¹ì§„ì‹œ", "ë³´ë ¹ì‹œ", "ë¶€ì—¬êµ°", "ì„œì‚°ì‹œ", "ì„œì²œêµ°",
             "ì•„ì‚°ì‹œ", "ì˜ˆì‚°êµ°", "ì²œì•ˆì‹œ", "ì²­ì–‘êµ°", "íƒœì•ˆêµ°", "í™ì„±êµ°"},
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„": {"ê³ ì°½êµ°", "êµ°ì‚°ì‹œ", "ê¹€ì œì‹œ", "ë‚¨ì›ì‹œ", "ë¬´ì£¼êµ°", "ë¶€ì•ˆêµ°", "ìˆœì°½êµ°", "ì™„ì£¼êµ°",
                  "ìµì‚°ì‹œ", "ì„ì‹¤êµ°", "ì¥ìˆ˜êµ°", "ì „ì£¼ì‹œ", "ì •ìì‹œ", "ì§„ì•ˆêµ°"},
    "ì „ë¼ë‚¨ë„": {"ê°•ì§„êµ°", "ê³ í¥êµ°", "ê³¡ì„±êµ°", "ê´‘ì–‘ì‹œ", "êµ¬ë¡€êµ°", "ë‚˜ì£¼ì‹œ", "ë‹´ì–‘êµ°", "ëª©í¬ì‹œ", "ë¬´ì•ˆêµ°",
             "ë³´ì„±êµ°", "ìˆœì²œì‹œ", "ì‹ ì•ˆêµ°", "ì—¬ìˆ˜ì‹œ", "ì˜ê´‘êµ°", "ì˜ì•”êµ°", "ì™„ë„êµ°", "ì¥ì„±êµ°", "ì¥í¥êµ°",
             "ì§„ë„êµ°", "í•¨í‰êµ°", "í•´ë‚¨êµ°", "í™”ìˆœêµ°"},
    "ê²½ìƒë¶ë„": {"ê²½ì‚°ì‹œ", "ê²½ì£¼ì‹œ", "ê³ ë ¹êµ°", "êµ¬ë¯¸ì‹œ", "êµ°ìœ„êµ°", "ê¹€ì²œì‹œ", "ë¬¸ê²½ì‹œ", "ë´‰í™”êµ°", "ìƒì£¼ì‹œ",
             "ì„±ì£¼êµ°", "ì•ˆë™ì‹œ", "ì˜ë•êµ°", "ì˜ì–‘êµ°", "ì˜ì£¼ì‹œ", "ì˜ì²œì‹œ", "ì˜ˆì²œêµ°", "ìš¸ë¦‰êµ°", "ìš¸ì§„êµ°",
             "ì˜ì„±êµ°", "ì²­ë„êµ°", "ì²­ì†¡êµ°", "ì¹ ê³¡êµ°", "í¬í•­ì‹œ"},
    "ê²½ìƒë‚¨ë„": {"ê±°ì œì‹œ", "ê±°ì°½êµ°", "ê³ ì„±êµ°", "ê¹€í•´ì‹œ", "ë‚¨í•´êµ°", "ë°€ì–‘ì‹œ", "ì‚¬ì²œì‹œ", "ì‚°ì²­êµ°", "ì–‘ì‚°ì‹œ",
             "ì˜ë ¹êµ°", "ì§„ì£¼ì‹œ", "ì°½ë…•êµ°", "ì°½ì›ì‹œ", "í†µì˜ì‹œ", "í•˜ë™êµ°", "í•¨ì•ˆêµ°", "í•¨ì–‘êµ°", "í•©ì²œêµ°"},
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {"ì„œê·€í¬ì‹œ", "ì œì£¼ì‹œ"}
}
def clean_korean_text(text: str) -> str:
    import re
    cleaned = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,()-]', '', text)
    return cleaned.strip()
# ----- ëª¨ë¸ ì •ì˜ -----
class ScheduleRequest(BaseModel):
    voice_input: str
@app.post("/new-extract-schedule")
async def new_extract_schedule(request: ScheduleRequest):
    """ğŸ†• ì™„ì „íˆ ìƒˆë¡œìš´ ë‹¤ì¤‘ ì˜µì…˜ ì¼ì • ì¶”ì¶œ ì—”ë“œí¬ì¸íŠ¸"""
    from datetime import datetime
    import sys
    
    print("ğŸ”¥ğŸ”¥ğŸ”¥ NEW EXTRACT SCHEDULE ì‹œì‘! ğŸ”¥ğŸ”¥ğŸ”¥")
    print(f"ğŸ”¥ í˜„ì¬ ì‹œê°„: {datetime.now()}")
    print(f"ğŸ”¥ ì…ë ¥ ë°ì´í„°: {request.voice_input}")
    print(f"ğŸ”¥ ì…ë ¥ ê¸¸ì´: {len(request.voice_input)}ì")
    sys.stdout.flush()
    
    logger.info("ğŸ†• NEW EXTRACT SCHEDULE ì‹œì‘!")
    logger.info(f"ì…ë ¥: {request.voice_input}")
    
    try:
        print("ğŸ”¥ Step 1: LLM ì²´ì¸ ìƒì„± ì‹œì‘")
        chain = create_schedule_chain()
        print("ğŸ”¥ Step 1: LLM ì²´ì¸ ìƒì„± ì™„ë£Œ")
        
        print("ğŸ”¥ Step 2: LLM í˜¸ì¶œ ì‹œì‘")
        result = await asyncio.wait_for(
            run_in_executor(lambda: chain.invoke({"input": request.voice_input})),
            timeout=20
        )
        print(f"ğŸ”¥ Step 2: LLM ì‘ë‹µ ìˆ˜ì‹ , íƒ€ì…: {type(result)}")
        print(f"ğŸ”¥ Step 2: LLM ì‘ë‹µ ë‚´ìš©: {str(result)[:200]}...")
        
        print("ğŸ”¥ Step 3: ê²°ê³¼ íŒŒì‹±")
        if isinstance(result, dict):
            schedule_data = result
        else:
            schedule_data = safe_parse_json(str(result))
        
        fixed_count = len(schedule_data.get('fixedSchedules', []))
        flexible_count = len(schedule_data.get('flexibleSchedules', []))
        print(f"ğŸ”¥ Step 3: íŒŒì‹± ì™„ë£Œ - ê³ ì •: {fixed_count}ê°œ, ìœ ì—°: {flexible_count}ê°œ")
        
        # ê°„ë‹¨í•œ ë‹¤ì¤‘ ì˜µì…˜ ì‘ë‹µ ìƒì„± (ë³µì¡í•œ ë¡œì§ ì—†ì´)
        print("ğŸ”¥ Step 4: ê°„ë‹¨í•œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±")
        
        simple_options = []
        for i in range(5):
            option = {
                "optionId": i + 1,
                "fixedSchedules": schedule_data.get('fixedSchedules', []),
                "flexibleSchedules": schedule_data.get('flexibleSchedules', [])
            }
            simple_options.append(option)
        
        final_result = {"options": simple_options}
        
        print(f"ğŸ”¥ Step 4: ê°„ë‹¨í•œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ - {len(simple_options)}ê°œ ì˜µì…˜")
        print("ğŸ”¥ğŸ”¥ğŸ”¥ NEW EXTRACT SCHEDULE ì™„ë£Œ! ğŸ”¥ğŸ”¥ğŸ”¥")
        
        return UnicodeJSONResponse(content=final_result, status_code=200)
        
    except Exception as e:
        print(f"ğŸ”¥ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ğŸ”¥ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        
        error_result = {
            "options": [
                {
                    "optionId": 1,
                    "fixedSchedules": [],
                    "flexibleSchedules": []
                }
            ]
        }
        
        print("ğŸ”¥ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜")
        return UnicodeJSONResponse(content=error_result, status_code=200)
class DynamicRouteOptimizer:
    """ë™ì  ê²½ë¡œ ìµœì í™” ë° ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±ê¸°"""
    
    def __init__(self, kakao_api_key: str):
        self.kakao_api_key = kakao_api_key
    
    async def create_multiple_options(self, enhanced_data: Dict, voice_input: str) -> Dict:
        """ì™„ì „ ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± - used_locations ìŠ¤ì½”í”„ ë¬¸ì œ ìˆ˜ì •"""
        
        def force_log(msg):
            print(f"ğŸ¯ {msg}")
            logger.info(msg)
        
        force_log("ğŸ†• ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œì‘ (used_locations ìŠ¤ì½”í”„ ìˆ˜ì •)")
        force_log(f"ì…ë ¥ ë°ì´í„°: voice_input='{voice_input}'")
        
        # ì…ë ¥ ë°ì´í„° ìƒì„¸ ë¡œê¹…
        fixed_schedules = enhanced_data.get("fixedSchedules", [])
        force_log(f"ê³ ì • ì¼ì • ìˆ˜: {len(fixed_schedules)}ê°œ")
        for i, schedule in enumerate(fixed_schedules):
            force_log(f"  ê³ ì • ì¼ì • {i+1}: '{schedule.get('name', 'N/A')}' (ID: {schedule.get('id', 'N/A')})")
        
        if len(fixed_schedules) < 2:
            force_log("âš ï¸ ê²½ë¡œ ë¶„ì„ì— í•„ìš”í•œ ìµœì†Œ ì¼ì • ë¶€ì¡± (2ê°œ ë¯¸ë§Œ)")
            return {"options": [enhanced_data]}  # ë‹¨ì¼ ì˜µì…˜ ë°˜í™˜
        
        # 1. ê²½ë¡œ ì •ë³´ ìë™ ì¶”ì¶œ
        start_schedule = fixed_schedules[0]
        end_schedule = fixed_schedules[-1]
        
        start_coord = (start_schedule.get("latitude"), start_schedule.get("longitude"))
        end_coord = (end_schedule.get("latitude"), end_schedule.get("longitude"))
        
        force_log(f"ğŸ“ ê²½ë¡œ ë¶„ì„:")
        force_log(f"  ì‹œì‘: {start_schedule.get('name')} ({start_coord})")
        force_log(f"  ì¢…ë£Œ: {end_schedule.get('name')} ({end_coord})")
        
        # 2. ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ìë™ ì‹ë³„
        variable_schedules = self.identify_variable_schedules(fixed_schedules, voice_input)
        
        force_log(f"ğŸ” ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ì‹ë³„ ê²°ê³¼: {len(variable_schedules)}ê°œ")
        for i, var_info in enumerate(variable_schedules):
            force_log(f"  ë³€ê²½ ê°€ëŠ¥ {i+1}: ì¸ë±ìŠ¤={var_info['index']}, ë¸Œëœë“œ='{var_info['brand']}', ì›ë³¸ëª…='{var_info['original_name']}'")
        
        if not variable_schedules:
            force_log("âš ï¸ ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì •ì´ ì—†ìŒ â†’ ë‹¨ì¼ ì˜µì…˜ ë°˜í™˜")
            return {"options": [enhanced_data]}
        
        # ğŸ”¥ ì „ì—­ ìœ„ì¹˜ ì¶”ì  - í´ë˜ìŠ¤ ë ˆë²¨ë¡œ ì´ë™í•˜ì—¬ í™•ì‹¤í•œ ê³µìœ  ë³´ì¥
        global_used_locations = set()
        
        force_log(f"ğŸ”„ ì „ì—­ used_locations ì´ˆê¸°í™”: {len(global_used_locations)}ê°œ")
        
        # 3. ê° ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì •ì— ëŒ€í•´ ë™ì  ì˜µì…˜ ìƒì„±
        options = []
        successful_options = 0  # ì„±ê³µí•œ ì˜µì…˜ ìˆ˜ ì¶”ì 
        
        for option_num in range(5):
            force_log(f"ğŸ”„ ì˜µì…˜ {option_num + 1} ë™ì  ìƒì„± ì‹œì‘")
            force_log(f"  í˜„ì¬ ì „ì—­ used_locations: {len(global_used_locations)}ê°œ - {list(global_used_locations)}")
            
            option_data = copy.deepcopy(enhanced_data)
            option_modified = False
            current_option_locations = set()  # í˜„ì¬ ì˜µì…˜ì—ì„œ ì‚¬ìš©í•  ìœ„ì¹˜ë“¤
            
            for var_info in variable_schedules:
                schedule_idx = var_info["index"]
                schedule = option_data["fixedSchedules"][schedule_idx]
                brand_name = var_info["brand"]
                
                force_log(f"  ğŸ“ ì¼ì • ìˆ˜ì •: ì¸ë±ìŠ¤={schedule_idx}, ë¸Œëœë“œ='{brand_name}'")
                force_log(f"    í˜„ì¬ ì´ë¦„: '{schedule.get('name')}'")
                force_log(f"    í˜„ì¬ ìœ„ì¹˜: '{schedule.get('location')}'")
                
                # ğŸ”¥ í˜„ì¬ ìœ„ì¹˜ë¥¼ ì²« ë²ˆì§¸ ì˜µì…˜ì—ì„œëŠ” ì‚¬ìš©ëœ ìœ„ì¹˜ì— ì¶”ê°€
                current_location = schedule.get("location", "")
                if option_num == 0 and current_location and current_location.strip():
                    global_used_locations.add(current_location)
                    force_log(f"    ğŸ“ ì›ë³¸ ìœ„ì¹˜ë¥¼ ì „ì—­ì— ì¶”ê°€: {current_location}")
                    force_log(f"    ğŸ“Š ì „ì—­ used_locations ì—…ë°ì´íŠ¸: {len(global_used_locations)}ê°œ")
                
                # 4. ë™ì  ì¤‘ê°„ ì§€ì—­ ê³„ì‚°
                force_log(f"  ğŸ—ºï¸ ì¤‘ê°„ ì§€ì—­ ê³„ì‚° (ì˜µì…˜ {option_num + 1})")
                intermediate_areas = await self.calculate_intermediate_areas(
                    start_coord, end_coord, option_num, total_options=5
                )
                force_log(f"    ê³„ì‚°ëœ ì¤‘ê°„ ì§€ì—­: {intermediate_areas}")
                
                # 5. í•´ë‹¹ ì§€ì—­ì—ì„œ ë¸Œëœë“œ ê²€ìƒ‰ (ğŸ”¥ ì „ì—­ used_locations ì‚¬ë³¸ ì „ë‹¬)
                force_log(f"  ğŸ” ë¸Œëœë“œ ê²€ìƒ‰: '{brand_name}' (ì „ì—­ ì œì™¸: {len(global_used_locations)}ê°œ)")
                force_log(f"    ì œì™¸í•  ìœ„ì¹˜ ëª©ë¡: {list(global_used_locations)}")
                
                # ğŸ”¥ used_locations ì‚¬ë³¸ì„ ì „ë‹¬í•˜ì—¬ find_optimal_branchì—ì„œ ì‹¤ì œë¡œ ìˆ˜ì •ë˜ì§€ ì•Šë„ë¡ í•¨
                used_locations_copy = global_used_locations.copy()
                
                best_location = await self.find_optimal_branch(
                    brand_name, intermediate_areas, start_coord, end_coord, used_locations_copy
                )
                
                if best_location:
                    new_location = best_location.get("address", "")
                    force_log(f"    âœ… ê²€ìƒ‰ ì„±ê³µ: {best_location.get('name')}")
                    force_log(f"      ì£¼ì†Œ: {new_location}")
                    
                    # ğŸ”¥ ì¤‘ë³µ ì²´í¬ (find_optimal_branchê°€ ì‚¬ë³¸ì„ ìˆ˜ì •í–ˆìœ¼ë¯€ë¡œ ì›ë³¸ì€ ê·¸ëŒ€ë¡œ)
                    if new_location in global_used_locations:
                        force_log(f"    âš ï¸ ì´ë¯¸ ì „ì—­ì—ì„œ ì‚¬ìš©ëœ ìœ„ì¹˜: {new_location}")
                        continue  # ì´ ì¼ì •ì€ ìˆ˜ì •í•˜ì§€ ì•Šê³  ë„˜ì–´ê°
                    elif new_location != current_location:
                        # ìœ„ì¹˜ ì—…ë°ì´íŠ¸
                        old_location = schedule.get("location")
                        schedule["location"] = new_location
                        schedule["latitude"] = best_location["latitude"]
                        schedule["longitude"] = best_location["longitude"]
                        schedule["name"] = best_location["name"]
                        
                        # ğŸ”¥ í˜„ì¬ ì˜µì…˜ì—ì„œ ì‚¬ìš©í•  ìœ„ì¹˜ë¡œ ì„ì‹œ ì €ì¥
                        current_option_locations.add(new_location)
                        
                        option_modified = True
                        force_log(f"    ğŸ”„ ìœ„ì¹˜ ë³€ê²½:")
                        force_log(f"      ì´ì „: {old_location}")
                        force_log(f"      ì´í›„: {new_location}")
                        force_log(f"    ğŸ“ í˜„ì¬ ì˜µì…˜ ìœ„ì¹˜ ëª©ë¡ì— ì¶”ê°€: {new_location}")
                    else:
                        force_log(f"    âš ï¸ ë™ì¼í•œ ìœ„ì¹˜ë¼ì„œ ë³€ê²½ ì—†ìŒ: {new_location}")
                else:
                    force_log(f"    âŒ ê²€ìƒ‰ ì‹¤íŒ¨: ìƒˆë¡œìš´ ìœ„ì¹˜ ì—†ìŒ (ëª¨ë“  í›„ë³´ê°€ ì´ë¯¸ ì‚¬ìš©ë¨)")
                    
                    # ğŸ”¥ ë” ì´ìƒ ìƒˆë¡œìš´ ìœ„ì¹˜ê°€ ì—†ìœ¼ë©´ ì˜µì…˜ ìƒì„± ì¤‘ë‹¨
                    if option_num > 0:  # ì²« ë²ˆì§¸ ì˜µì…˜ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ
                        force_log(f"    â­ï¸ ìƒˆë¡œìš´ ìœ„ì¹˜ê°€ ì—†ì–´ì„œ ì˜µì…˜ ìƒì„± ì¤‘ë‹¨")
                        break
            
            # 6. ìˆ˜ì •ëœ ì˜µì…˜ë§Œ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
            if option_modified or option_num == 0:  # ì²« ë²ˆì§¸ëŠ” ì›ë³¸ ìœ ì§€
                # ğŸ”¥ í˜„ì¬ ì˜µì…˜ì˜ ìœ„ì¹˜ë“¤ì„ ì „ì—­ì— ì¶”ê°€ (ì„±ê³µì ìœ¼ë¡œ ì˜µì…˜ì´ ìƒì„±ëœ ê²½ìš°ì—ë§Œ)
                for location in current_option_locations:
                    global_used_locations.add(location)
                    force_log(f"    âœ… ì „ì—­ used_locationsì— ì¶”ê°€: {location}")
                
                force_log(f"    ğŸ“Š ì „ì—­ used_locations ìµœì¢… ìƒíƒœ: {len(global_used_locations)}ê°œ")
                force_log(f"      ëª©ë¡: {list(global_used_locations)}")
                
                # ê³ ìœ  ID ë¶€ì—¬
                current_time = int(time.time() * 1000)
                for j, schedule in enumerate(option_data["fixedSchedules"]):
                    old_id = schedule.get("id")
                    new_id = f"{current_time}_{option_num + 1}_{j + 1}"
                    schedule["id"] = new_id
                    force_log(f"    ğŸ†” ID ì—…ë°ì´íŠ¸: {old_id} â†’ {new_id}")
                
                options.append({
                    "optionId": option_num + 1,
                    "fixedSchedules": option_data["fixedSchedules"],
                    "flexibleSchedules": option_data.get("flexibleSchedules", [])
                })
                
                successful_options += 1
                force_log(f"  âœ… ì˜µì…˜ {option_num + 1} ìƒì„± ì™„ë£Œ (ìˆ˜ì •ë¨: {option_modified})")
                force_log(f"    ì„±ê³µí•œ ì˜µì…˜ ìˆ˜: {successful_options}")
                
            else:
                force_log(f"  âŒ ì˜µì…˜ {option_num + 1} ê±´ë„ˆë›°ê¸° (ë³€ê²½ì‚¬í•­ ì—†ìŒ)")
            
            # ğŸ”¥ ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´: ë” ì´ìƒ ìƒˆë¡œìš´ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
            if not option_modified and option_num > 0:
                force_log(f"â¹ï¸ ë” ì´ìƒ ìƒˆë¡œìš´ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì¡°ê¸° ì¢…ë£Œ (ì˜µì…˜ {option_num + 1})")
                break
        
        # 7. ì¤‘ë³µ ì œê±° (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
        unique_options = self.remove_duplicate_options(options)
        force_log(f"ğŸ”„ ì¤‘ë³µ ì œê±° ê²°ê³¼: {len(options)}ê°œ â†’ {len(unique_options)}ê°œ")
        
        # 8. ìµœì¢… ê²°ê³¼
        force_log(f"ğŸ‰ ë™ì  ì˜µì…˜ ìƒì„± ì™„ë£Œ: {len(unique_options)}ê°œ")
        force_log(f"ğŸ“Š ìµœì¢… ì „ì—­ used_locations: {len(global_used_locations)}ê°œ")
        for i, location in enumerate(global_used_locations):
            force_log(f"  ìœ„ì¹˜ {i+1}: {location}")
        
        # ìƒì„±ëœ ì˜µì…˜ë“¤ ìƒì„¸ ë¡œê¹…
        for i, option in enumerate(unique_options):
            force_log(f"ğŸ“‹ ìµœì¢… ì˜µì…˜ {i+1}:")
            for j, schedule in enumerate(option.get("fixedSchedules", [])):
                force_log(f"  ì¼ì • {j+1}: '{schedule.get('name')}' @ {schedule.get('location')}")
        
        return {"options": unique_options}
    
    def identify_variable_schedules(self, schedules: List[Dict], voice_input: str) -> List[Dict]:
        """ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ìë™ ì‹ë³„"""
        def force_log(msg):
            print(f"ğŸ” {msg}")
            logger.info(msg)
        
        force_log("ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ì‹ë³„ ì‹œì‘")
        force_log(f"ì…ë ¥: ì¼ì • ìˆ˜={len(schedules)}, ìŒì„±='{voice_input}'")        
        variable_schedules = []
        
        # ë¸Œëœë“œ í‚¤ì›Œë“œ ë™ì  ê°ì§€
        brand_keywords = {
            # â˜• ì»¤í”¼ ì „ë¬¸ì  (ê²½ìŸ ë¸Œëœë“œë“¤)
            "ìŠ¤íƒ€ë²…ìŠ¤": ["ìŠ¤íƒ€ë²…ìŠ¤", "starbucks"],
            "ì»¤í”¼ë¹ˆ": ["ì»¤í”¼ë¹ˆ", "coffee bean", "coffeebean"],
            "í• ë¦¬ìŠ¤": ["í• ë¦¬ìŠ¤", "hollys", "í• ë¦¬ìŠ¤ì»¤í”¼"],
            "íˆ¬ì¸í”Œë ˆì´ìŠ¤": ["íˆ¬ì¸í”Œë ˆì´ìŠ¤", "twosome", "íˆ¬ì¸"],
            "ì´ë””ì•¼": ["ì´ë””ì•¼", "ediya", "ì´ë””ì•¼ì»¤í”¼"],
            "í´ë°”ì…‹": ["í´ë°”ì…‹", "paul bassett"],
            "íƒì•¤íƒìŠ¤": ["íƒì•¤íƒìŠ¤", "tom n toms"],
            "ì—”ì ¤ë¦¬ë„ˆìŠ¤": ["ì—”ì ¤ë¦¬ë„ˆìŠ¤", "angelinus"],
            "ë©”ê°€ì»¤í”¼": ["ë©”ê°€ì»¤í”¼", "mega coffee", "ë©”ê°€mgcì»¤í”¼"],
            "ì»´í¬ì¦ˆì»¤í”¼": ["ì»´í¬ì¦ˆ", "compose coffee"],
            "ì‹ì‚¬": ["ì‹ì‚¬", "ì €ë…", "ì ì‹¬", "ì•„ì¹¨", "ë°¥", "ë§›ì§‘", "ì‹ë‹¹"],          
            # ğŸ° ì¹´í˜ & ë””ì €íŠ¸
            "ì¹´í˜": ["ì¹´í˜", "cafe", "ì»¤í”¼", "coffee"],
            "ë² ì´ì»¤ë¦¬": ["ë² ì´ì»¤ë¦¬", "bakery", "ë¹µì§‘", "íŒŒë¦¬ë°”ê²Œëœ¨", "ëšœë ˆì¥¬ë¥´"],
            "ë””ì €íŠ¸": ["ë””ì €íŠ¸", "dessert", "ì¼€ì´í¬", "ë§ˆì¹´ë¡±", "ì•„ì´ìŠ¤í¬ë¦¼"],
            
            # ğŸ” íŒ¨ìŠ¤íŠ¸í‘¸ë“œ
            "ë§¥ë„ë‚ ë“œ": ["ë§¥ë„ë‚ ë“œ", "mcdonald", "ë§¥ë”œ"],
            "ë²„ê±°í‚¹": ["ë²„ê±°í‚¹", "burger king"],
            "ë¡¯ë°ë¦¬ì•„": ["ë¡¯ë°ë¦¬ì•„", "lotteria"],
            "kfc": ["kfc", "ì¹˜í‚¨"],
            "ì„œë¸Œì›¨ì´": ["ì„œë¸Œì›¨ì´", "subway"],
            
            # ğŸ• í”¼ì
            "ë„ë¯¸ë…¸í”¼ì": ["ë„ë¯¸ë…¸", "domino", "ë„ë¯¸ë…¸í”¼ì"],
            "í”¼ìí—›": ["í”¼ìí—›", "pizza hut"],
            "ë¯¸ìŠ¤í„°í”¼ì": ["ë¯¸ìŠ¤í„°í”¼ì", "mr pizza"],
            "íŒŒíŒŒì¡´ìŠ¤": ["íŒŒíŒŒì¡´ìŠ¤", "papa johns"],
            
            # ğŸ— ì¹˜í‚¨
            "bbq": ["bbq", "ë¹„ë¹„í"],
            "êµ½ë„¤ì¹˜í‚¨": ["êµ½ë„¤", "êµ½ë„¤ì¹˜í‚¨"],
            "ë„¤ë„¤ì¹˜í‚¨": ["ë„¤ë„¤", "ë„¤ë„¤ì¹˜í‚¨"],
            "êµì´Œì¹˜í‚¨": ["êµì´Œ", "êµì´Œì¹˜í‚¨"],
            "bhc": ["bhc", "ë¹„ì—ì´ì¹˜ì”¨"],
            "ì²˜ê°“ì§‘": ["ì²˜ê°“ì§‘", "ì²˜ê°“ì§‘ì–‘ë…ì¹˜í‚¨"],
            
            # ğŸª í¸ì˜ì 
            "í¸ì˜ì ": ["í¸ì˜ì ", "ì„¸ë¸ì¼ë ˆë¸", "cu", "gs25", "ì´ë§ˆíŠ¸24", "ë¯¸ë‹ˆìŠ¤í†±"],
            "ì„¸ë¸ì¼ë ˆë¸": ["ì„¸ë¸ì¼ë ˆë¸", "7eleven", "711"],
            "cu": ["cu", "ì”¨ìœ "],
            "gs25": ["gs25", "ì§€ì—ìŠ¤25"],
            "ì´ë§ˆíŠ¸24": ["ì´ë§ˆíŠ¸24", "emart24"],
            
            # ğŸœ í•œì‹
            "í•œì‹": ["í•œì‹", "í•œì •ì‹", "ë°±ë°˜", "ì°Œê°œ", "êµ­ë°¥", "korean food"],
            "ê¹€ë°¥": ["ê¹€ë°¥ì²œêµ­", "ê¹€ë°¥", "ë¶„ì‹"],
            "ê³±ì°½": ["ê³±ì°½", "ë§‰ì°½", "ëŒ€ì°½", "ì–‘"],
            "ì‚¼ê²¹ì‚´": ["ì‚¼ê²¹ì‚´", "ê³ ê¸°ì§‘", "êµ¬ì´"],
            "ì¹˜í‚¨ê°ˆë¹„": ["ë‹­ê°ˆë¹„", "ì¹˜í‚¨ê°ˆë¹„", "ì¶˜ì²œë‹­ê°ˆë¹„"],
            
            # ğŸ ì–‘ì‹
            "íŒŒìŠ¤íƒ€": ["íŒŒìŠ¤íƒ€", "ì´íƒˆë¦¬ì•ˆ", "ìŠ¤íŒŒê²Œí‹°"],
            "ìŠ¤í…Œì´í¬": ["ìŠ¤í…Œì´í¬", "ì•„ì›ƒë°±", "outback"],
            "ì–‘ì‹": ["ì–‘ì‹", "ì´íƒˆë¦¬ì•ˆ", "western food"],
            
            # ğŸœ ì¼ì‹
            "ì´ˆë°¥": ["ì´ˆë°¥", "ìŠ¤ì‹œ", "sushi"],
            "ë¼ë©˜": ["ë¼ë©˜", "ramen", "ëˆì½”ì¸ "],
            "ëˆì¹´ì¸ ": ["ëˆì¹´ì¸ ", "ì¹´ì¸ ", "tonkatsu"],
            "ì¼ì‹": ["ì¼ì‹", "japanese food"],
            
            # ğŸ¥Ÿ ì¤‘ì‹
            "ì¤‘ì‹": ["ì¤‘ì‹", "ì¤‘êµ­ì§‘", "ì§œì¥ë©´", "ì§¬ë½•", "íƒ•ìˆ˜ìœ¡"],
            "ë”¤ì„¬": ["ë”¤ì„¬", "ë§Œë‘"],
            
            # ğŸŒ® ê¸°íƒ€ ì„¸ê³„ìŒì‹
            "ë©•ì‹œì¹¸": ["ë©•ì‹œì¹¸", "íƒ€ì½”", "ë¶€ë¦¬ë˜"],
            "íƒœêµ­ìŒì‹": ["íƒœêµ­", "ìŒ€êµ­ìˆ˜", "íŒŸíƒ€ì´"],
            "ì¸ë„ìŒì‹": ["ì¸ë„", "ì»¤ë¦¬", "ë‚œ"],
            
            # ğŸ¥˜ ë¶„ì‹/ê°„ì‹
            "ë¶„ì‹": ["ë¶„ì‹", "ë–¡ë³¶ì´", "ìˆœëŒ€", "íŠ€ê¹€", "ì–´ë¬µ"],
            "ì•„ì´ìŠ¤í¬ë¦¼": ["ë°°ìŠ¤í‚¨ë¼ë¹ˆìŠ¤", "ë¸Œë¼ìš´", "í•˜ê²ë‹¤ì¦ˆ"],
            
            # ğŸ¨ ìˆ™ë°•
            "í˜¸í…”": ["í˜¸í…”", "hotel", "ë¦¬ì¡°íŠ¸", "íœì…˜"],
            "ëª¨í…”": ["ëª¨í…”", "motel"],
            
            # ğŸ¥ ìƒí™œì‹œì„¤
            "ë³‘ì›": ["ë³‘ì›", "ì˜ì›", "clinic", "hospital"],
            "ì•½êµ­": ["ì•½êµ­", "pharmacy"],
            "ì€í–‰": ["ì€í–‰", "bank", "atm"],
            "ë§ˆíŠ¸": ["ë§ˆíŠ¸", "ì´ë§ˆíŠ¸", "í™ˆí”ŒëŸ¬ìŠ¤", "ë¡¯ë°ë§ˆíŠ¸"],
            
            # ğŸ® ì˜¤ë½ì‹œì„¤
            "ë…¸ë˜ë°©": ["ë…¸ë˜ë°©", "karaoke", "ì½”ì¸ë…¸ë˜ë°©"],
            "pcë°©": ["pcë°©", "í”¼ì”¨ë°©", "ê²Œì„ë°©"],
            "ì°œì§ˆë°©": ["ì°œì§ˆë°©", "ì‚¬ìš°ë‚˜", "ëª©ìš•íƒ•"],
            "ë³¼ë§ì¥": ["ë³¼ë§", "ë³¼ë§ì¥"],
            "ë‹¹êµ¬ì¥": ["ë‹¹êµ¬", "ë‹¹êµ¬ì¥", "í¬ì¼“ë³¼"],
            
            # ğŸš— êµí†µ/ì„œë¹„ìŠ¤
            "ì£¼ìœ ì†Œ": ["ì£¼ìœ ì†Œ", "gas station", "sk", "gsì¹¼í…ìŠ¤", "í˜„ëŒ€ì˜¤ì¼ë±…í¬"],
            "ì„¸ì°¨ì¥": ["ì„¸ì°¨", "ì„¸ì°¨ì¥"],
            "ë¯¸ìš©ì‹¤": ["ë¯¸ìš©ì‹¤", "í—¤ì–´ìƒµ", "ë¯¸ìš©ì›"],
            "ë„¤ì¼ìƒµ": ["ë„¤ì¼", "ë„¤ì¼ìƒµ", "nail"],
            
            # ğŸƒ ìš´ë™/ê±´ê°•
            "í—¬ìŠ¤ì¥": ["í—¬ìŠ¤", "í—¬ìŠ¤ì¥", "í”¼íŠ¸ë‹ˆìŠ¤", "gym"],
            "ìš”ê°€": ["ìš”ê°€", "í•„ë¼í…ŒìŠ¤", "yoga"],
            "ê³¨í”„": ["ê³¨í”„", "ê³¨í”„ì¥", "ê³¨í”„ì—°ìŠµì¥"],
            
            # ğŸ¯ ëŒ€í˜• ë¸Œëœë“œ (êµ¬ì²´ì ìœ¼ë¡œ)
            "ì´ë§ˆíŠ¸": ["ì´ë§ˆíŠ¸", "emart"],
            "í™ˆí”ŒëŸ¬ìŠ¤": ["í™ˆí”ŒëŸ¬ìŠ¤", "homeplus"],
            "ì½”ìŠ¤íŠ¸ì½”": ["ì½”ìŠ¤íŠ¸ì½”", "costco"],
            "í˜„ëŒ€ë°±í™”ì ": ["í˜„ëŒ€ë°±í™”ì ", "í˜„ëŒ€"],
            "ë¡¯ë°ë°±í™”ì ": ["ë¡¯ë°ë°±í™”ì ", "ë¡¯ë°"],
            "ì‹ ì„¸ê³„": ["ì‹ ì„¸ê³„ë°±í™”ì ", "ì‹ ì„¸ê³„"],
        }
        force_log(f"ë¸Œëœë“œ í‚¤ì›Œë“œ ì„¤ì •: {len(brand_keywords)}ê°œ ë¸Œëœë“œ")       
        for idx, schedule in enumerate(schedules):
            schedule_name = schedule.get("name", "").lower()
            
            # ë¸Œëœë“œ ë§¤ì¹­ í™•ì¸
            for brand, keywords in brand_keywords.items():
                force_log(f"  {brand}: {keywords}")
                if any(keyword in schedule_name for keyword in keywords):
                    variable_schedules.append({
                        "index": idx,
                        "brand": brand,
                        "original_name": schedule.get("name"),
                        "keywords": keywords
                    })
                    logger.info(f"ğŸ” ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ë°œê²¬: {schedule.get('name')} â†’ {brand}")
                    break
        
        return variable_schedules
    
    async def calculate_intermediate_areas(self, start_coord: Tuple, end_coord: Tuple, 
                                         option_num: int, total_options: int = 5) -> List[Tuple]:
        """ë™ì  ì¤‘ê°„ ì§€ì—­ ì¢Œí‘œ ê³„ì‚° - ë¡œê¹… ì¶”ê°€"""
        
        def force_log(msg):
            print(f"ğŸ—ºï¸ {msg}")
            logger.info(msg)
        
        start_lat, start_lng = start_coord
        end_lat, end_lng = end_coord
        
        force_log(f"ì¤‘ê°„ ì§€ì—­ ê³„ì‚°: ì˜µì…˜ {option_num + 1}")
        force_log(f"  ì‹œì‘ì : ({start_lat:.4f}, {start_lng:.4f})")
        force_log(f"  ì¢…ë£Œì : ({end_lat:.4f}, {end_lng:.4f})")
        
        # ì˜µì…˜ë³„ë¡œ ë‹¤ë¥¸ ì¤‘ê°„ì ë“¤ ê³„ì‚°
        intermediate_coords = []
        
        if option_num == 0:
            ratio = 0.2
            force_log(f"  ì „ëµ: ì¶œë°œì§€ ê·¼ì²˜ (20% ì§€ì )")
        elif option_num == 1:
            ratio = 0.5
            force_log(f"  ì „ëµ: ì¤‘ê°„ ì§€ì  (50% ì§€ì )")
        elif option_num == 2:
            ratio = 0.8
            force_log(f"  ì „ëµ: ëª©ì ì§€ ê·¼ì²˜ (80% ì§€ì )")
        elif option_num == 3:
            ratio = 0.5
            perpendicular_offset = 0.01
            force_log(f"  ì „ëµ: ìš°íšŒ ê²½ë¡œ 1 (ì¤‘ê°„ì  + ìˆ˜ì§ ì˜¤í”„ì…‹)")
        else:
            ratio = 0.3
            perpendicular_offset = -0.01
            force_log(f"  ì „ëµ: ìš°íšŒ ê²½ë¡œ 2 (30% ì§€ì  + ìˆ˜ì§ ì˜¤í”„ì…‹)")
        
        # ê¸°ë³¸ ì¤‘ê°„ì  ê³„ì‚°
        mid_lat = start_lat + (end_lat - start_lat) * ratio
        mid_lng = start_lng + (end_lng - start_lng) * ratio
        
        # ìš°íšŒ ê²½ë¡œ ì˜µì…˜ì¸ ê²½ìš° ì˜¤í”„ì…‹ ì ìš©
        if option_num >= 3:
            if 'perpendicular_offset' in locals():
                mid_lat += perpendicular_offset
                force_log(f"  ìˆ˜ì§ ì˜¤í”„ì…‹ ì ìš©: +{perpendicular_offset}")
        
        intermediate_coords.append((mid_lat, mid_lng))
        force_log(f"  ê³„ì‚°ëœ ì¤‘ê°„ì : ({mid_lat:.4f}, {mid_lng:.4f})")
        
        return intermediate_coords
    
    async def find_optimal_branch(self, brand_name: str, intermediate_areas: List[Tuple], 
                                start_coord: Tuple, end_coord: Tuple, used_locations: Set[str] = None) -> Optional[Dict]:
        """ìµœì ì˜ ë¸Œëœë“œ ì§€ì  ì°¾ê¸° - ì‚¬ìš©ëœ ìœ„ì¹˜ ì œì™¸"""
        
        if used_locations is None:
            used_locations = set()
        
        def force_log(msg):
            print(f"ğŸ” {msg}")
            logger.info(msg)
        
        force_log(f"ìµœì  ë¸Œëœë“œ ì§€ì  ê²€ìƒ‰: '{brand_name}'")
        force_log(f"ê²€ìƒ‰ ì§€ì—­: {len(intermediate_areas)}ê°œ")
        force_log(f"ì œì™¸í•  ìœ„ì¹˜: {len(used_locations)}ê°œ - {list(used_locations)}")
        
        best_location = None
        best_efficiency = 0
        
        for i, coord in enumerate(intermediate_areas):
            force_log(f"ì§€ì—­ {i+1} ê²€ìƒ‰: ì¢Œí‘œ ({coord[0]:.4f}, {coord[1]:.4f})")
            
            # í•´ë‹¹ ì¢Œí‘œ ê·¼ì²˜ì—ì„œ ë¸Œëœë“œ ê²€ìƒ‰
            candidates = await self.search_brand_near_coordinate(brand_name, coord)
            force_log(f"  ê²€ìƒ‰ ê²°ê³¼: {len(candidates)}ê°œ í›„ë³´")
            
            for j, candidate in enumerate(candidates):
                location = candidate.get('address', '')
                force_log(f"    í›„ë³´ {j+1}: {candidate.get('name')} @ {location}")
                
                # ğŸ”¥ ì´ë¯¸ ì‚¬ìš©ëœ ìœ„ì¹˜ì¸ì§€ í™•ì¸
                if location in used_locations:
                    force_log(f"      âŒ ì´ë¯¸ ì‚¬ìš©ëœ ìœ„ì¹˜ë¼ì„œ ì œì™¸")
                    continue
                    
                # ê²½ë¡œ íš¨ìœ¨ì„± ê³„ì‚°
                efficiency = self.calculate_route_efficiency(
                    start_coord, 
                    (candidate["latitude"], candidate["longitude"]), 
                    end_coord
                )
                force_log(f"      íš¨ìœ¨ì„±: {efficiency:.3f}")
                
                if efficiency > best_efficiency:
                    best_efficiency = efficiency
                    best_location = candidate
                    force_log(f"      ğŸ”¥ ìƒˆë¡œìš´ ìµœì  í›„ë³´: {candidate.get('name')} (íš¨ìœ¨ì„±: {efficiency:.3f})")
        
        if best_location:
            force_log(f"âœ… ìµœì¢… ì„ íƒ: {best_location['name']} (íš¨ìœ¨ì„±: {best_efficiency:.3f})")
            # ğŸ”¥ ì‚¬ìš©ëœ ìœ„ì¹˜ ì¶”ê°€
            used_locations.add(best_location['address'])
            force_log(f"ğŸ“ ì‚¬ìš©ëœ ìœ„ì¹˜ì— ì¶”ê°€: {best_location['address']}")
        else:
            force_log(f"âŒ ì ì ˆí•œ ì§€ì ì„ ì°¾ì§€ ëª»í•¨ (ëª¨ë‘ ì‚¬ìš©ëœ ìœ„ì¹˜ì´ê±°ë‚˜ ê²€ìƒ‰ ì‹¤íŒ¨)")
        
        return best_location

    
    async def search_brand_near_coordinate(self, brand_name: str, coord: Tuple, 
                                         radius: int = 3000) -> List[Dict]:
        """íŠ¹ì • ì¢Œí‘œ ê·¼ì²˜ì—ì„œ ë¸Œëœë“œ ê²€ìƒ‰ - ë¡œê¹… ì¶”ê°€"""
        
        def force_log(msg):
            print(f"ğŸ” {msg}")
            logger.info(msg)
        
        lat, lng = coord
        force_log(f"ë¸Œëœë“œ ê²€ìƒ‰: '{brand_name}' @ ({lat:.4f}, {lng:.4f}), ë°˜ê²½: {radius}m")
        
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {self.kakao_api_key}"}
            
            params = {
                "query": brand_name,
                "x": lng,
                "y": lat,
                "radius": radius,
                "size": 10,
                "sort": "distance"
            }
            
            force_log(f"Kakao API í˜¸ì¶œ: query='{brand_name}'")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        candidates = []
                        places = data.get("documents", [])
                        force_log(f"API ì‘ë‹µ: {len(places)}ê°œ ì¥ì†Œ")
                        
                        for i, place in enumerate(places):
                            place_name = place.get("place_name", "")
                            address = place.get("road_address_name") or place.get("address_name", "")
                            distance = place.get("distance", "")
                            
                            force_log(f"  ì¥ì†Œ {i+1}: {place_name} ({distance}m)")
                            force_log(f"    ì£¼ì†Œ: {address}")
                            
                            candidates.append({
                                "name": place_name,
                                "address": address,
                                "latitude": float(place.get("y", 0)),
                                "longitude": float(place.get("x", 0)),
                                "distance": distance
                            })
                        
                        force_log(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(candidates)}ê°œ í›„ë³´ ë°˜í™˜")
                        return candidates
                    else:
                        force_log(f"âŒ API ì˜¤ë¥˜: HTTP {response.status}")
                        
        except Exception as e:
            force_log(f"âŒ ê²€ìƒ‰ ì˜ˆì™¸: {e}")
        
        return []
    
    def calculate_route_efficiency(self, start: Tuple, middle: Tuple, end: Tuple) -> float:
        """ê²½ë¡œ íš¨ìœ¨ì„± ê³„ì‚° - ë¡œê¹… ì¶”ê°€"""
        
        def distance(p1, p2):
            lat1, lng1 = p1
            lat2, lng2 = p2
            return math.sqrt((lat2 - lat1)**2 + (lng2 - lng1)**2)
        
        # ì§ì„  ê±°ë¦¬ vs ì‹¤ì œ ê²½ë¡œ ê±°ë¦¬
        direct_distance = distance(start, end)
        route_distance = distance(start, middle) + distance(middle, end)
        
        if route_distance == 0:
            return 0
        
        efficiency = direct_distance / route_distance
        
        # ìƒì„¸ ë¡œê¹…ì€ ë„ˆë¬´ ë§ì•„ì„œ ìƒëµ
        return efficiency
    
    def remove_duplicate_options(self, options: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ì˜µì…˜ ì œê±° - ë¡œê¹… ì¶”ê°€"""
        
        def force_log(msg):
            print(f"ğŸ”„ {msg}")
            logger.info(msg)
        
        force_log(f"ì¤‘ë³µ ì œê±° ì‹œì‘: {len(options)}ê°œ ì˜µì…˜")
        
        unique_options = []
        seen_signatures = set()
        
        for i, option in enumerate(options):
            # ê° ì˜µì…˜ì˜ ìœ„ì¹˜ ì‹œê·¸ë‹ˆì²˜ ìƒì„±
            signature = self.create_location_signature(option)
            force_log(f"ì˜µì…˜ {i+1} ì‹œê·¸ë‹ˆì²˜: '{signature}'")
            
            if signature not in seen_signatures:
                unique_options.append(option)
                seen_signatures.add(signature)
                force_log(f"  âœ… ê³ ìœ  ì˜µì…˜ìœ¼ë¡œ ì¶”ê°€")
            else:
                force_log(f"  âŒ ì¤‘ë³µ ì˜µì…˜ ì œì™¸")
        
        force_log(f"ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(unique_options)}ê°œ ë‚¨ìŒ")
        return unique_options
    
    def create_location_signature(self, option: Dict) -> str:
        locations = []
        for schedule in option.get("fixedSchedules", []):
            location = schedule.get("location", "")
            # ğŸ”¥ ìŠ¤íƒ€ë²…ìŠ¤ê°™ì€ ë¸Œëœë“œëŠ” ìœ„ì¹˜ë§Œìœ¼ë¡œ êµ¬ë¶„
            if "ìŠ¤íƒ€ë²…ìŠ¤" in schedule.get("name", ""):
                locations.append(f"starbucks@{location}")
            else:
                name = schedule.get("name", "")
                locations.append(f"{name}@{location}")
        return " | ".join(locations)
        
        


class UnicodeJSONResponse(JSONResponse):
    def render(self, content) -> bytes:
        return json.dumps(
            content,
            ensure_ascii=False,  # ğŸ‘ˆ í•µì‹¬! í•œê¸€ì„ ìœ ë‹ˆì½”ë“œ ê·¸ëŒ€ë¡œ ì¶œë ¥
            separators=(',', ':'),
            indent=None
        ).encode('utf-8')  # ğŸ‘ˆ UTF-8ë¡œ ì¸ì½”ë”©
    
class FixedSchedule(BaseModel):
    id: str
    name: str
    type: str = "FIXED"
    duration: int = 60
    priority: float  = 1.0
    location: str = ""
    latitude: float = 37.5665
    longitude: float = 126.9780
    startTime: str
    endTime: str

class FlexibleSchedule(BaseModel):
    id: str
    name: str
    type: str = "FLEXIBLE"
    duration: int = 60
    priority: float  = 3.0
    location: str = ""
    latitude: float = 37.5665
    longitude: float = 126.9780

class ExtractScheduleResponse(BaseModel):
    fixedSchedules: List[FixedSchedule] = []
    flexibleSchedules: List[FlexibleSchedule] = []

class LocationAnalysis(BaseModel):
    place_name: str
    region: str
    district: str
    category: str
    search_keywords: List[str]

class PlaceResult(BaseModel):
    name: str
    address: str
    latitude: float
    longitude: float
    source: str  # foursquare, kakao, google
    rating: Optional[float] = None


def safe_parse_json(json_str):
    """ì•ˆì „í•œ JSON íŒŒì‹± - í•œê¸€ ì§€ì›"""
    try:
        if isinstance(json_str, str):
            # í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
            return json.loads(json_str, strict=False)
        else:
            return json_str
    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ (í•œê¸€ í¬í•¨): {str(e)}")
        return {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }

def normalize_priorities(schedules_data: Dict[str, Any]) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì •ìˆ˜ë¡œ ì •ê·œí™”"""
    logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ìˆ˜ ë³€í™˜ ì‹œì‘")
    
    all_schedules = []
    all_schedules.extend(schedules_data.get("fixedSchedules", []))
    all_schedules.extend(schedules_data.get("flexibleSchedules", []))
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    all_schedules.sort(key=lambda s: s.get("priority", 999))
    
    # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ë¡œ ì¬í• ë‹¹
    for i, schedule in enumerate(all_schedules):
        old_priority = schedule.get("priority", "ì—†ìŒ")
        new_priority = i + 1
        schedule["priority"] = new_priority
        logger.info(f"ìš°ì„ ìˆœìœ„ ì •ê·œí™”: '{schedule.get('name', '')}' {old_priority} â†’ {new_priority}")
    
    # ë‹¤ì‹œ ë¶„ë¥˜
    fixed_schedules = [s for s in all_schedules if s.get("type") == "FIXED" and "startTime" in s]
    flexible_schedules = [s for s in all_schedules if s.get("type") != "FIXED" or "startTime" not in s]
    
    logger.info(f"âœ… ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì™„ë£Œ: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
    
    return {
        "fixedSchedules": fixed_schedules,
        "flexibleSchedules": flexible_schedules
    }
# ----- ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ -----
class AddressQualityChecker:
    """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
    
    @staticmethod
    def is_complete_address(address: str) -> bool:
        """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦"""
        if not address or address.strip() == "":
            return False
        
        # ê¸°ë³¸ ê²€ì¦
        address_lower = address.lower()
        
        # 1. ë„ˆë¬´ ì§§ì€ ì£¼ì†Œ (ë‹¨ì–´ 2ê°œ ì´í•˜)
        words = [word for word in address.split() if len(word) > 1]
        if len(words) <= 2:
            logger.info(f"âŒ ì£¼ì†Œ ë„ˆë¬´ ì§§ìŒ: {address} ({len(words)}ê°œ ë‹¨ì–´)")
            return False
        
        # 2. ëª¨í˜¸í•œ í‘œí˜„ ì²´í¬
        vague_terms = ["ê·¼ì²˜", "ì¸ê·¼", "ì£¼ë³€", "ê·¼ë°©", "ë¶€ê·¼", "ì¼ëŒ€", "ë™ë„¤"]
        if any(term in address for term in vague_terms):
            logger.info(f"âŒ ëª¨í˜¸í•œ ì£¼ì†Œ í‘œí˜„: {address}")
            return False
        
        # 3. í•œêµ­ ì£¼ì†Œ í•„ìˆ˜ ìš”ì†Œ ì²´í¬
        korean_regions = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        has_region = any(region in address for region in korean_regions)
        
        # 4. ìƒì„¸ ì£¼ì†Œ ìš”ì†Œ ì²´í¬ (êµ¬/ì‹œ/êµ° + ë™/ì/ë©´)
        detail_keywords = ["êµ¬", "ì‹œ", "êµ°", "ë™", "ì", "ë©´", "ë¡œ", "ê¸¸", "ê°€"]
        has_detail = any(keyword in address for keyword in detail_keywords)
        
        # 5. ê±´ë¬¼ëª…ì´ë‚˜ ë²ˆì§€ìˆ˜ ì²´í¬
        import re
        has_number = bool(re.search(r'\d+', address))
        
        quality_score = has_region + has_detail + has_number
        is_complete = quality_score >= 2  # 3ì  ë§Œì ì— 2ì  ì´ìƒ
        
        logger.info(f"ğŸ“Š ì£¼ì†Œ í’ˆì§ˆ ì ìˆ˜: {quality_score}/3 - {address}")
        logger.info(f"   ì§€ì—­í¬í•¨: {has_region}, ìƒì„¸ìš”ì†Œ: {has_detail}, ë²ˆì§€í¬í•¨: {has_number}")
        logger.info(f"   ì™„ì „ì„±: {'âœ… ì™„ì „' if is_complete else 'âŒ ë¶ˆì™„ì „'}")
        
        return is_complete
    
    @staticmethod
    def get_category_keywords(place_name: str) -> List[str]:
        """ì¥ì†Œëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        name_lower = place_name.lower()
        keywords = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        category_map = {
            "ì¹´í˜": ["ì¹´í˜", "ì»¤í”¼", "coffee", "dessert", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"],
            "ì‹ë‹¹": ["ì‹ë‹¹", "ë§›ì§‘", "ìŒì‹ì ", "ë ˆìŠ¤í† ë‘", "restaurant", "food"],
            "íšŒì˜": ["íšŒì˜ì‹¤", "ì˜¤í”¼ìŠ¤", "ì‚¬ë¬´ì‹¤", "ì»¨í¼ëŸ°ìŠ¤", "meeting"],
            "íšŒì‹": ["ìˆ ì§‘", "bar", "pub", "í˜¸í”„", "ì´ìì¹´ì•¼", "restaurant"],
            "ì‡¼í•‘": ["ì‡¼í•‘ëª°", "ë°±í™”ì ", "ë§ˆíŠ¸", "ìƒì ", "mall"],
            "ìˆ™ë°•": ["í˜¸í…”", "ëª¨í…”", "íœì…˜", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤", "ë¦¬ì¡°íŠ¸"]
        }
        
        for category, words in category_map.items():
            if any(word in name_lower for word in words):
                keywords.extend(words)
                logger.info(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ '{category}' ê°ì§€: {words}")
                break
        
        # ê¸°ë³¸ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¥ì†Œëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if not keywords:
            keywords = [place_name]
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°
    
class RegionNormalizer:
    """ì§€ì—­ëª… ì •ê·œí™” ë° ë§¤ì¹­ ì—”ì§„"""
    
    def __init__(self):
        self.regions_data = KOREA_REGIONS
        self._build_normalization_maps()
    
    def _build_normalization_maps(self):
        """ì •ê·œí™” ë§µì„ ë™ì ìœ¼ë¡œ êµ¬ì¶•"""
        self.region_aliases = {}
        self.reverse_lookup = {}  # ğŸ”¥ ì¶”ê°€ëœ ë¶€ë¶„
        
        for full_region, districts in self.regions_data.items():
            # í‘œì¤€ ì§€ì—­ëª…ê³¼ ì¶•ì•½í˜• ìƒì„±
            canonical = self._extract_canonical_name(full_region)
            short_name = self._extract_short_name(full_region)
            
            # ëª¨ë“  ë³€í˜•ë“¤ì„ í‘œì¤€ëª…ìœ¼ë¡œ ë§¤í•‘
            aliases = [full_region, canonical, short_name]
            
            # ğŸ”¥ ì—­ë°©í–¥ ë§¤í•‘ë„ ì €ì¥
            self.reverse_lookup[full_region] = aliases
            
            for alias in aliases:
                if alias and alias.strip():
                    self.region_aliases[alias] = full_region
    
    def _extract_canonical_name(self, full_name: str) -> str:
        """í‘œì¤€ ì§€ì—­ëª… ì¶”ì¶œ (ì˜ˆ: ê²½ìƒë‚¨ë„ â†’ ê²½ìƒë‚¨)"""
        suffixes = ['íŠ¹ë³„ì‹œ', 'ê´‘ì—­ì‹œ', 'íŠ¹ë³„ìì¹˜ì‹œ', 'íŠ¹ë³„ìì¹˜ë„', 'ë„']
        result = full_name
        for suffix in suffixes:
            result = result.replace(suffix, '')
        return result
    
    def _extract_short_name(self, full_name: str) -> str:
        """ì¶•ì•½ ì§€ì—­ëª… ì¶”ì¶œ (ì˜ˆ: ê²½ìƒë‚¨ë„ â†’ ê²½ë‚¨)"""
        short_map = {
            'ê²½ìƒë‚¨': 'ê²½ë‚¨', 'ê²½ìƒë¶': 'ê²½ë¶',
            'ì „ë¼ë‚¨': 'ì „ë‚¨', 'ì „ë¼ë¶': 'ì „ë¶', 
            'ì¶©ì²­ë‚¨': 'ì¶©ë‚¨', 'ì¶©ì²­ë¶': 'ì¶©ë¶',
            'ê°•ì›íŠ¹ë³„ìì¹˜': 'ê°•ì›', 'ì œì£¼íŠ¹ë³„ìì¹˜': 'ì œì£¼'
        }
        
        canonical = self._extract_canonical_name(full_name)
        for long_form, short_form in short_map.items():
            if long_form in canonical:
                return short_form
        return canonical
    
    def get_region_variants(self, region_name: str) -> List[str]:  # ğŸ”¥ ì´ ë©”ì„œë“œê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ
        """ì§€ì—­ëª…ì˜ ëª¨ë“  ë³€í˜•ë“¤ì„ ë°˜í™˜"""
        if not region_name:
            return []
        
        # ì§ì ‘ ë§¤í•‘ëœ ë³€í˜•ë“¤ ì°¾ê¸°
        if region_name in self.reverse_lookup:
            return self.reverse_lookup[region_name]
        
        # ì •ê·œí™”í•´ì„œ ì°¾ê¸°
        variants = set([region_name])
        for alias, standard in self.region_aliases.items():
            if standard == region_name or alias == region_name:
                variants.add(alias)
                variants.add(standard)
                if standard in self.reverse_lookup:
                    variants.update(self.reverse_lookup[standard])
        
        return list(variants)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
region_normalizer = RegionNormalizer()

def check_region_match(address: str, reference_region: str) -> Tuple[bool, float]:
    """
    ë³´í¸ì  ì§€ì—­ ë§¤ì¹­ í•¨ìˆ˜
    Returns: (is_match, confidence_score)
    """
    if not address or not reference_region:
        return False, 0.0
    
    # ì°¸ì¡° ì§€ì—­ ì •ê·œí™”
    normalized_ref = region_normalizer.normalize_region(reference_region)
    ref_aliases = region_normalizer.get_all_aliases(normalized_ref)
    
    # ì£¼ì†Œì—ì„œ ì§€ì—­ ì¶”ì¶œ ë° ì •ê·œí™”
    detected_regions = extract_regions_from_text(address)
    
    max_confidence = 0.0
    is_match = False
    
    for detected in detected_regions:
        normalized_detected = region_normalizer.normalize_region(detected)
        
        if normalized_detected == normalized_ref:
            is_match = True
            max_confidence = max(max_confidence, 1.0)  # ì™„ì „ ì¼ì¹˜
        else:
            # ë¶€ë¶„ ì¼ì¹˜ ì ìˆ˜ ê³„ì‚°
            similarity = calculate_region_similarity(normalized_ref, normalized_detected)
            if similarity > 0.7:  # 70% ì´ìƒ ìœ ì‚¬í•˜ë©´ ê°™ì€ ì§€ì—­ìœ¼ë¡œ ê°„ì£¼
                is_match = True
                max_confidence = max(max_confidence, similarity)
    
    return is_match, max_confidence

def extract_regions_from_text(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ëª…ë“¤ì„ ì¶”ì¶œ"""
    import re
    
    # ì§€ì—­ëª… íŒ¨í„´ë“¤
    patterns = [
        r'([ê°€-í£]+(?:íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|íŠ¹ë³„ìì¹˜ì‹œ|íŠ¹ë³„ìì¹˜ë„|ë„))',  # ì‹œ/ë„
        r'([ê°€-í£]+(?:ì‹œ|êµ°|êµ¬))',  # ì‹œ/êµ°/êµ¬
        r'([ê°€-í£]+(?:ë™|ì|ë©´))',  # ë™/ì/ë©´
    ]
    
    regions = []
    for pattern in patterns:
        matches = re.findall(pattern, text)
        regions.extend(matches)
    
    return list(set(regions))  # ì¤‘ë³µ ì œê±°

def calculate_region_similarity(region1: str, region2: str) -> float:
    """ë‘ ì§€ì—­ëª…ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
    if region1 == region2:
        return 1.0
    
    # í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„
    from difflib import SequenceMatcher
    return SequenceMatcher(None, region1, region2).ratio()
class TripleLocationSearchService:
    """Foursquare + Kakao + Google 3ì¤‘ ìœ„ì¹˜ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    # app.pyì˜ TripleLocationSearchService í´ë˜ìŠ¤ ë‚´ë¶€
    @staticmethod
    async def analyze_location_with_gpt(text: str, reference_location: Optional[str] = None, route_context: Optional[str] = None) -> LocationAnalysis:
        """GPTë¡œ ì •í™•í•œ ì§€ì—­ê³¼ ì¥ì†Œ ë¶„ì„ - ê²½ë¡œ ë§¥ë½ê³¼ ì°¸ì¡° ìœ„ì¹˜ ì¶”ê°€"""
        
        # setì„ listë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
        korea_regions_list = {region: list(districts) for region, districts in KOREA_REGIONS.items()}
        regions_text = json.dumps(korea_regions_list, ensure_ascii=False, indent=2)
        
        # ì°¸ì¡° ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
        reference_context = ""
        if reference_location:
            reference_context = f"\nì°¸ì¡° ìœ„ì¹˜ (ì´ì „ ì¼ì •): {reference_location}"
            reference_context += "\n'ê·¼ì²˜', 'ì£¼ë³€' ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ì´ ì°¸ì¡° ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”."
        
        # ğŸ”¥ ê²½ë¡œ ë§¥ë½ ì¶”ê°€ - KOREA_REGIONS í™œìš©í•˜ì—¬ ì „êµ­ ì§€ì›
        route_context_text = ""
        if route_context:
            route_context_text = f"\nê²½ë¡œ ì •ë³´: {route_context}"
            route_context_text += "\n'ì¤‘ê°„ì—' ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ê²½ë¡œìƒì˜ ì¤‘ê°„ ì§€ì ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”."
            
            # ê²½ë¡œì—ì„œ ì§€ì—­ ì¶”ì¶œí•˜ì—¬ ì¤‘ê°„ ì§€ì  ì§€ì—­ ê²°ì •
            import re
            route_pattern = r'(.+?)ì—ì„œ\s*(.+?)ê¹Œì§€'
            match = re.search(route_pattern, route_context)
            if match:
                start_place = match.group(1).strip()
                end_place = match.group(2).strip()
                
                # ğŸ”¥ KOREA_REGIONSë¥¼ í™œìš©í•œ ì „êµ­ ì§€ì—­ ë§¤í•‘
                nationwide_areas = {
                    # ì„œìš¸íŠ¹ë³„ì‹œ
                    "ì„œìš¸íŠ¹ë³„ì‹œ": {
                        "ì‹ ê¸¸ì—­": "ì˜ë“±í¬êµ¬", "ì„œìš¸ì—­": "ì¤‘êµ¬", "ê°•ë‚¨ì—­": "ê°•ë‚¨êµ¬", 
                        "í™ëŒ€": "ë§ˆí¬êµ¬", "ì´íƒœì›": "ìš©ì‚°êµ¬", "ëª…ë™": "ì¤‘êµ¬",
                        "ì ì‹¤": "ì†¡íŒŒêµ¬", "ê°•ë™": "ê°•ë™êµ¬", "ì¢…ë¡œ": "ì¢…ë¡œêµ¬",
                        "ì—¬ì˜ë„": "ì˜ë“±í¬êµ¬", "ì„±ìˆ˜": "ì„±ë™êµ¬", "ê±´ëŒ€": "ê´‘ì§„êµ¬",
                        "ì‹ ì´Œ": "ì„œëŒ€ë¬¸êµ¬", "ì••êµ¬ì •": "ê°•ë‚¨êµ¬", "ì²­ë‹´": "ê°•ë‚¨êµ¬"
                    },
                    
                    # ë¶€ì‚°ê´‘ì—­ì‹œ
                    "ë¶€ì‚°ê´‘ì—­ì‹œ": {
                        "ë¶€ì‚°ì—­": "ë™êµ¬", "ì„œë©´": "ë¶€ì‚°ì§„êµ¬", "í•´ìš´ëŒ€": "í•´ìš´ëŒ€êµ¬",
                        "ê´‘ì•ˆë¦¬": "ìˆ˜ì˜êµ¬", "ë‚¨í¬ë™": "ì¤‘êµ¬", "ì„¼í…€ì‹œí‹°": "í•´ìš´ëŒ€êµ¬",
                        "ë¶€ì‚°ëŒ€": "ê¸ˆì •êµ¬", "ì¥ì „ì—­": "ê¸ˆì •êµ¬", "ì˜¨ì²œì¥": "ë™ë˜êµ¬",
                        "ë¶€ì‚°í„°ë¯¸ë„": "ë™êµ¬", "ì‚¬ìƒ": "ì‚¬ìƒêµ¬", "ê¸°ì¥": "ê¸°ì¥êµ°"
                    },
                    
                    # ëŒ€êµ¬ê´‘ì—­ì‹œ
                    "ëŒ€êµ¬ê´‘ì—­ì‹œ": {
                        "ë™ì„±ë¡œ": "ì¤‘êµ¬", "ìˆ˜ì„±êµ¬ì²­": "ìˆ˜ì„±êµ¬", "ë‹¬ì„œêµ¬ì²­": "ë‹¬ì„œêµ¬",
                        "ë°˜ì›”ë‹¹": "ì¤‘êµ¬", "ë‘ë¥˜": "ë‹¬ì„œêµ¬", "ëŒ€êµ¬ì—­": "ë¶êµ¬",
                        "ë™ëŒ€êµ¬ì—­": "ë™êµ¬", "ì„±ì„œ": "ë‹¬ì„œêµ¬", "ì¹ ê³¡": "ë¶êµ¬"
                    },
                    
                    # ì¸ì²œê´‘ì—­ì‹œ
                    "ì¸ì²œê´‘ì—­ì‹œ": {
                        "ì†¡ë„": "ì—°ìˆ˜êµ¬", "ë¶€í‰": "ë¶€í‰êµ¬", "ì¸ì²œê³µí•­": "ì¤‘êµ¬",
                        "êµ¬ì›”ë™": "ë‚¨ë™êµ¬", "ì¸ì²œì—­": "ì¤‘êµ¬", "ê°„ì„": "ë‚¨ë™êµ¬",
                        "ê³„ì–‘": "ê³„ì–‘êµ¬", "ì„œêµ¬ì²­": "ì„œêµ¬", "ê°•í™”": "ê°•í™”êµ°"
                    },
                    
                    # ê´‘ì£¼ê´‘ì—­ì‹œ
                    "ê´‘ì£¼ê´‘ì—­ì‹œ": {
                        "ìƒë¬´ì§€êµ¬": "ì„œêµ¬", "ì¶©ì¥ë¡œ": "ë™êµ¬", "ê´‘ì²œí„°ë¯¸ë„": "ì„œêµ¬",
                        "ì²¨ë‹¨": "ê´‘ì‚°êµ¬", "ë¶êµ¬ì²­": "ë¶êµ¬", "ë‚¨êµ¬ì²­": "ë‚¨êµ¬"
                    },
                    
                    # ëŒ€ì „ê´‘ì—­ì‹œ
                    "ëŒ€ì „ê´‘ì—­ì‹œ": {
                        "ë‘”ì‚°": "ì„œêµ¬", "ìœ ì„±ì˜¨ì²œ": "ìœ ì„±êµ¬", "ëŒ€ì „ì—­": "ë™êµ¬",
                        "ì„œëŒ€ì „": "ì„œêµ¬", "ì¤‘êµ¬ì²­": "ì¤‘êµ¬", "ëŒ€ë•": "ëŒ€ë•êµ¬"
                    },
                    
                    # ìš¸ì‚°ê´‘ì—­ì‹œ
                    "ìš¸ì‚°ê´‘ì—­ì‹œ": {
                        "íƒœí™”ê°•": "ì¤‘êµ¬", "ìš¸ì‚°ëŒ€í•™êµ": "ìš¸ì£¼êµ°", "í˜„ëŒ€ì¤‘ê³µì—…": "ë™êµ¬",
                        "ë‚¨êµ¬ì²­": "ë‚¨êµ¬", "ë¶êµ¬ì²­": "ë¶êµ¬", "ì–¸ì–‘": "ìš¸ì£¼êµ°"
                    },
                    
                    # ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ
                    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {
                        "ì„¸ì¢…ì‹œì²­": "ì„¸ì¢…ì‹œ", "ì„¸ì¢…í„°ë¯¸ë„": "ì„¸ì¢…ì‹œ", "ì¡°ì¹˜ì›": "ì„¸ì¢…ì‹œ"
                    },
                    
                    # ê²½ê¸°ë„ ì£¼ìš” ì§€ì—­
                    "ê²½ê¸°ë„": {
                        "ìˆ˜ì›ì—­": "ìˆ˜ì›ì‹œ", "ì„±ë‚¨ì‹œì²­": "ì„±ë‚¨ì‹œ", "ì•ˆì–‘": "ì•ˆì–‘ì‹œ",
                        "ë¶€ì²œ": "ë¶€ì²œì‹œ", "ê³ ì–‘": "ê³ ì–‘ì‹œ", "ìš©ì¸": "ìš©ì¸ì‹œ",
                        "ê¹€í¬ê³µí•­": "ê¹€í¬ì‹œ", "ì¼ì‚°": "ê³ ì–‘ì‹œ", "ë¶„ë‹¹": "ì„±ë‚¨ì‹œ",
                        "ê´‘ëª…": "ê´‘ëª…ì‹œ", "ì‹œí¥": "ì‹œí¥ì‹œ", "ì•ˆì‚°": "ì•ˆì‚°ì‹œ",
                        "í‰íƒ": "í‰íƒì‹œ", "í™”ì„±": "í™”ì„±ì‹œ", "íŒŒì£¼": "íŒŒì£¼ì‹œ"
                    },
                    
                    # ê²½ìƒë‚¨ë„ ì£¼ìš” ì§€ì—­ ğŸ”¥ ì–‘ì‚° ì¶”ê°€!
                    "ê²½ìƒë‚¨ë„": {
                        "ì–‘ì‚°ì‹œì²­": "ì–‘ì‚°ì‹œ", "ì–‘ì‚°í„°ë¯¸ë„": "ì–‘ì‚°ì‹œ", "ì–‘ì‚°": "ì–‘ì‚°ì‹œ",
                        "ì°½ì›": "ì°½ì›ì‹œ", "ì§„ì£¼": "ì§„ì£¼ì‹œ", "í†µì˜": "í†µì˜ì‹œ",
                        "ì‚¬ì²œ": "ì‚¬ì²œì‹œ", "ê¹€í•´": "ê¹€í•´ì‹œ", "ë°€ì–‘": "ë°€ì–‘ì‹œ",
                        "ê±°ì œ": "ê±°ì œì‹œ", "ì˜ë ¹": "ì˜ë ¹êµ°", "í•¨ì•ˆ": "í•¨ì•ˆêµ°",
                        "ì°½ë…•": "ì°½ë…•êµ°", "ê³ ì„±": "ê³ ì„±êµ°", "ë‚¨í•´": "ë‚¨í•´êµ°",
                        "í•˜ë™": "í•˜ë™êµ°", "ì‚°ì²­": "ì‚°ì²­êµ°", "í•¨ì–‘": "í•¨ì–‘êµ°",
                        "ê±°ì°½": "ê±°ì°½êµ°", "í•©ì²œ": "í•©ì²œêµ°"
                    }
                    
                    # ë‹¤ë¥¸ ì§€ì—­ë“¤ë„ í•„ìš”ì‹œ ì¶”ê°€...
                }
                
                # ì¶œë°œì§€ì™€ ë„ì°©ì§€ ì§€ì—­ ì°¾ê¸°
                start_region = None
                start_district = None
                end_region = None
                end_district = None
                
                # ğŸ”¥ KOREA_REGIONSì—ì„œ ì „êµ­ ê²€ìƒ‰
                for region_name, districts in KOREA_REGIONS.items():
                    if region_name in nationwide_areas:
                        area_mapping = nationwide_areas[region_name]
                        
                        # ì¶œë°œì§€ ê²€ìƒ‰
                        for place_name, district in area_mapping.items():
                            if place_name in start_place:
                                start_region = region_name
                                start_district = district
                                break
                        
                        # ë„ì°©ì§€ ê²€ìƒ‰
                        for place_name, district in area_mapping.items():
                            if place_name in end_place:
                                end_region = region_name
                                end_district = district
                                break
                
                # ì¤‘ê°„ ì§€ì—­ ê²°ì • ë¡œì§
                if start_region and end_region:
                    if start_region == end_region:
                        # ê°™ì€ ì‹œ/ë„ ë‚´ ì´ë™
                        if start_district and end_district:
                            route_context_text += f"\nì¤‘ê°„ ì§€ì  ì¶”ì²œ ì§€ì—­: {start_district}ê³¼ {end_district} ì‚¬ì´ ({start_region})"
                        else:
                            route_context_text += f"\nì¤‘ê°„ ì§€ì  ì¶”ì²œ ì§€ì—­: {start_region} ë‚´ ì¤‘ê°„ ì§€ì "
                    else:
                        # ë‹¤ë¥¸ ì‹œ/ë„ ê°„ ì´ë™
                        route_context_text += f"\nì¤‘ê°„ ì§€ì  ì¶”ì²œ ì§€ì—­: {start_region}ê³¼ {end_region} ì‚¬ì´ì˜ ì¤‘ê°„ ë„ì‹œ"

        prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ì˜ ì •í™•í•œ ì§€ì—­ ì •ë³´ì™€ ì¥ì†Œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

    í…ìŠ¤íŠ¸: "{text}"{reference_context}{route_context_text}

    í•œêµ­ ì§€ì—­ ì •ë³´:
    {regions_text}

    **ì¤‘ìš” ë¶„ì„ ê·œì¹™**: 
    1. "ê·¼ì²˜", "ì£¼ë³€" ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ì°¸ì¡° ìœ„ì¹˜ì™€ ê°™ì€ ì§€ì—­ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    2. "ì¤‘ê°„ì—" ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ê²½ë¡œìƒì˜ ì¤‘ê°„ ì§€ì  ì§€ì—­ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”.
    3. ëª¨í˜¸í•œ í‘œí˜„("ì¹´í˜", "ì‹ë‹¹")ë„ ì°¸ì¡° ìœ„ì¹˜ë‚˜ ê²½ë¡œ ê·¼ì²˜ì—ì„œ ê²€ìƒ‰í•˜ë„ë¡ ì§€ì—­ì„ ì„¤ì •í•˜ì„¸ìš”.
    4. êµ¬ì²´ì ì¸ ì¥ì†Œëª…(ì˜ˆ: ì–‘ì‚°ì‹œì²­, ìš¸ì‚°ëŒ€í•™êµ, ë¬¸ìˆ˜ì›”ë“œì»µê²½ê¸°ì¥)ì€ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ìš°ì„ í•˜ì„¸ìš”.
    5. ê²½ë¡œ ë§¥ë½ì´ ìˆìœ¼ë©´ ì§€ë¦¬ì ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ì¤‘ê°„ ì§€ì ì„ ì„ íƒí•˜ì„¸ìš”.

    **ì „êµ­ ì§€ë¦¬ì  íš¨ìœ¨ì„± ê³ ë ¤ì‚¬í•­**:
    - ì–‘ì‚°ì‹œ â†’ ë¶€ì‚°ì‹œ: ì¤‘ê°„ì€ ë¶€ì‚° ë¶êµ¬, ì‚¬ìƒêµ¬
    - ì„œìš¸ â†’ ë¶€ì‚°: ì¤‘ê°„ì€ ëŒ€ì „, ëŒ€êµ¬
    - ê°™ì€ ì‹œ/ë„ ë‚´: ì¸ì ‘ êµ¬/ì‹œ/êµ° ê³ ë ¤

    JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
    {{
    "place_name": "ì¶”ì¶œëœ ì¥ì†Œëª… (ë§¥ë½ ê³ ë ¤)",
    "region": "ì‹œ/ë„ (ê²½ë¡œë‚˜ ì°¸ì¡° ìœ„ì¹˜ ê³ ë ¤)",
    "district": "ì‹œ/êµ°/êµ¬ (ê²½ë¡œë‚˜ ì°¸ì¡° ìœ„ì¹˜ ê³ ë ¤)",
    "category": "ì¥ì†Œ ì¹´í…Œê³ ë¦¬",
    "search_keywords": ["ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë“¤", "ì§€ì—­ëª…+ì¥ì†Œëª…", "ì¹´í…Œê³ ë¦¬ëª…"],
    "geographical_context": "ì§€ë¦¬ì  ë§¥ë½ ì„¤ëª…"
    }}
    """

        try:
            response = openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì „êµ­ ì§€ì—­ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê²½ë¡œ ë§¥ë½ê³¼ ì°¸ì¡° ìœ„ì¹˜ë¥¼ ê³ ë ¤í•˜ì—¬ 'ì¤‘ê°„ì—', 'ê·¼ì²˜', 'ì£¼ë³€' í‘œí˜„ì„ ì§€ë¦¬ì ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”. ì „êµ­ì˜ ì‹œ/ë„ì™€ êµ¬/ì‹œ/êµ°ì„ ì •í™•íˆ ë§¤í•‘í•˜ì„¸ìš”."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500,
            )

            content = response.choices[0].message.content.strip()
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(content)
            
            # ì‘ë‹µì— geographical_contextê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
            if "geographical_context" not in data:
                data["geographical_context"] = "ê¸°ë³¸ ë¶„ì„"
            
            logger.info(f"ğŸ§  GPT ì§€ì—­ ë¶„ì„ ì™„ë£Œ: {data.get('region')} {data.get('district')} - {data.get('place_name')}")
            logger.info(f"ğŸ—ºï¸ ì§€ë¦¬ì  ë§¥ë½: {data.get('geographical_context')}")
            
            return LocationAnalysis(**data)
            
        except Exception as e:
            logger.error(f"âŒ GPT ì§€ì—­ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            # ğŸ”¥ ì „êµ­ ê¸°ë³¸ê°’ ì„¤ì • (KOREA_REGIONS í™œìš©)
            default_region = "ì„œìš¸íŠ¹ë³„ì‹œ"
            default_district = "ì¤‘êµ¬"
            
            if reference_location:
                # ğŸ”¥ KOREA_REGIONSì—ì„œ ì§€ì—­ ì¶”ì¶œ
                for region_name in KOREA_REGIONS.keys():
                    region_short = region_name.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                    if region_short in reference_location or region_name in reference_location:
                        default_region = region_name
                        
                        # í•´ë‹¹ ì§€ì—­ì˜ êµ¬/ì‹œ/êµ° ì°¾ê¸°
                        districts = KOREA_REGIONS[region_name]
                        for district in districts:
                            if district in reference_location:
                                default_district = district
                                break
                        break
            
            elif route_context:
                # ê²½ë¡œ ë§¥ë½ì—ì„œ ì§€ì—­ ì¶”ì¶œ (KOREA_REGIONS í™œìš©)
                for region_name in KOREA_REGIONS.keys():
                    region_short = region_name.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    if region_short in route_context:
                        default_region = region_name
                        break
            
            logger.info(f"ğŸ”„ ê¸°ë³¸ê°’ ì‚¬ìš©: {default_region} {default_district}")
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return LocationAnalysis(
                place_name=text,
                region=default_region,
                district=default_district,
                category="ì¥ì†Œ",
                search_keywords=[f"{default_district} {text}", text],
                geographical_context="ê¸°ë³¸ê°’ ì ìš©"
            )

    @staticmethod
    async def search_foursquare(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """3ìˆœìœ„: Foursquare API ê²€ìƒ‰ - ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ê°•í™”"""
        if not FOURSQUARE_API_KEY:
            logger.warning("âŒ Foursquare API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 3ìˆœìœ„ Foursquare ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            # ì§€ì—­ ì¢Œí‘œ (ê¸°ì¡´ê³¼ ë™ì¼)
            region_coords = {
                # íŠ¹ë³„ì‹œÂ·ê´‘ì—­ì‹œ
                "ì„œìš¸íŠ¹ë³„ì‹œ": {"lat": 37.5665, "lng": 126.9780},
                "ë¶€ì‚°ê´‘ì—­ì‹œ": {"lat": 35.1796, "lng": 129.0756},
                "ëŒ€êµ¬ê´‘ì—­ì‹œ": {"lat": 35.8714, "lng": 128.6014},
                "ì¸ì²œê´‘ì—­ì‹œ": {"lat": 37.4563, "lng": 126.7052},
                "ê´‘ì£¼ê´‘ì—­ì‹œ": {"lat": 35.1595, "lng": 126.8526},
                "ëŒ€ì „ê´‘ì—­ì‹œ": {"lat": 36.3504, "lng": 127.3845},
                "ìš¸ì‚°ê´‘ì—­ì‹œ": {"lat": 35.5384, "lng": 129.3114},
                
                # íŠ¹ë³„ìì¹˜ì‹œÂ·íŠ¹ë³„ìì¹˜ë„
                "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {"lat": 36.4800, "lng": 127.2890},
                "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {"lat": 33.4996, "lng": 126.5312},
                
                # ê²½ê¸°ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ê¸°ë„": {"lat": 37.4138, "lng": 127.5183},
                "ê°€í‰êµ°": {"lat": 37.8313, "lng": 127.5109},
                "ê³ ì–‘ì‹œ": {"lat": 37.6584, "lng": 126.8320},
                "ê³¼ì²œì‹œ": {"lat": 37.4292, "lng": 126.9876},
                "ê´‘ëª…ì‹œ": {"lat": 37.4784, "lng": 126.8664},
                "ê´‘ì£¼ì‹œ": {"lat": 37.4297, "lng": 127.2550},
                "êµ¬ë¦¬ì‹œ": {"lat": 37.5943, "lng": 127.1296},
                "êµ°í¬ì‹œ": {"lat": 37.3614, "lng": 126.9350},
                "ê¹€í¬ì‹œ": {"lat": 37.6150, "lng": 126.7158},
                "ë‚¨ì–‘ì£¼ì‹œ": {"lat": 37.6369, "lng": 127.2165},
                "ë™ë‘ì²œì‹œ": {"lat": 37.9036, "lng": 127.0606},
                "ë¶€ì²œì‹œ": {"lat": 37.5036, "lng": 126.7660},
                "ì„±ë‚¨ì‹œ": {"lat": 37.4201, "lng": 127.1262},
                "ìˆ˜ì›ì‹œ": {"lat": 37.2636, "lng": 127.0286},
                "ì‹œí¥ì‹œ": {"lat": 37.3803, "lng": 126.8030},
                "ì•ˆì‚°ì‹œ": {"lat": 37.3236, "lng": 126.8219},
                "ì•ˆì„±ì‹œ": {"lat": 37.0078, "lng": 127.2797},
                "ì•ˆì–‘ì‹œ": {"lat": 37.3943, "lng": 126.9568},
                "ì–‘ì£¼ì‹œ": {"lat": 37.7853, "lng": 127.0456},
                "ì–‘í‰êµ°": {"lat": 37.4916, "lng": 127.4874},
                "ì—¬ì£¼ì‹œ": {"lat": 37.2982, "lng": 127.6376},
                "ì—°ì²œêµ°": {"lat": 38.0960, "lng": 127.0751},
                "ì˜¤ì‚°ì‹œ": {"lat": 37.1499, "lng": 127.0776},
                "ìš©ì¸ì‹œ": {"lat": 37.2411, "lng": 127.1776},
                "ì˜ì™•ì‹œ": {"lat": 37.3448, "lng": 126.9687},
                "ì˜ì •ë¶€ì‹œ": {"lat": 37.7381, "lng": 127.0339},
                "ì´ì²œì‹œ": {"lat": 37.2724, "lng": 127.4349},
                "íŒŒì£¼ì‹œ": {"lat": 37.7598, "lng": 126.7800},
                "í‰íƒì‹œ": {"lat": 36.9921, "lng": 127.1127},
                "í¬ì²œì‹œ": {"lat": 37.8950, "lng": 127.2003},
                "í•˜ë‚¨ì‹œ": {"lat": 37.5394, "lng": 127.2147},
                "í™”ì„±ì‹œ": {"lat": 37.1996, "lng": 126.8310},
                
                # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°  
                "ê°•ì›íŠ¹ë³„ìì¹˜ë„": {"lat": 37.8228, "lng": 128.1555},
                "ê°•ë¦‰ì‹œ": {"lat": 37.7519, "lng": 128.8761},
                "ê³ ì„±êµ°": {"lat": 38.3806, "lng": 128.4678},
                "ë™í•´ì‹œ": {"lat": 37.5244, "lng": 129.1144},
                "ì‚¼ì²™ì‹œ": {"lat": 37.4501, "lng": 129.1649},
                "ì†ì´ˆì‹œ": {"lat": 38.2070, "lng": 128.5918},
                "ì–‘êµ¬êµ°": {"lat": 38.1065, "lng": 127.9897},
                "ì–‘ì–‘êµ°": {"lat": 38.0759, "lng": 128.6190},
                "ì˜ì›”êµ°": {"lat": 37.1839, "lng": 128.4617},
                "ì›ì£¼ì‹œ": {"lat": 37.3422, "lng": 127.9202},
                "ì¸ì œêµ°": {"lat": 38.0695, "lng": 128.1707},
                "ì •ì„ êµ°": {"lat": 37.3801, "lng": 128.6607},
                "ì² ì›êµ°": {"lat": 38.1465, "lng": 127.3134},
                "ì¶˜ì²œì‹œ": {"lat": 37.8813, "lng": 127.7298},
                "íƒœë°±ì‹œ": {"lat": 37.1641, "lng": 128.9856},
                "í‰ì°½êµ°": {"lat": 37.3708, "lng": 128.3897},
                "í™ì²œêµ°": {"lat": 37.6971, "lng": 127.8888},
                "í™”ì²œêµ°": {"lat": 38.1063, "lng": 127.7082},
                "íš¡ì„±êµ°": {"lat": 37.4916, "lng": 127.9856},
                
                # ì¶©ì²­ë¶ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì¶©ì²­ë¶ë„": {"lat": 36.4919, "lng": 127.7417},
                "ê´´ì‚°êµ°": {"lat": 36.8154, "lng": 127.7874},
                "ë‹¨ì–‘êµ°": {"lat": 36.9845, "lng": 128.3659},
                "ë³´ì€êµ°": {"lat": 36.4894, "lng": 127.7293},
                "ì˜ë™êµ°": {"lat": 36.1750, "lng": 127.7764},
                "ì˜¥ì²œêµ°": {"lat": 36.3061, "lng": 127.5721},
                "ìŒì„±êµ°": {"lat": 36.9433, "lng": 127.6864},
                "ì œì²œì‹œ": {"lat": 37.1326, "lng": 128.1909},
                "ì¦í‰êµ°": {"lat": 36.7848, "lng": 127.5814},
                "ì§„ì²œêµ°": {"lat": 36.8565, "lng": 127.4335},
                "ì²­ì£¼ì‹œ": {"lat": 36.4919, "lng": 127.7417},
                "ì¶©ì£¼ì‹œ": {"lat": 36.9910, "lng": 127.9259},
                
                # ì¶©ì²­ë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì¶©ì²­ë‚¨ë„": {"lat": 36.5184, "lng": 126.8000},
                "ê³„ë£¡ì‹œ": {"lat": 36.2742, "lng": 127.2489},
                "ê³µì£¼ì‹œ": {"lat": 36.4464, "lng": 127.1248},
                "ê¸ˆì‚°êµ°": {"lat": 36.1088, "lng": 127.4881},
                "ë…¼ì‚°ì‹œ": {"lat": 36.1872, "lng": 127.0985},
                "ë‹¹ì§„ì‹œ": {"lat": 36.8934, "lng": 126.6292},
                "ë³´ë ¹ì‹œ": {"lat": 36.3334, "lng": 126.6127},
                "ë¶€ì—¬êµ°": {"lat": 36.2756, "lng": 126.9098},
                "ì„œì‚°ì‹œ": {"lat": 36.7848, "lng": 126.4503},
                "ì„œì²œêµ°": {"lat": 36.0805, "lng": 126.6919},
                "ì•„ì‚°ì‹œ": {"lat": 36.7898, "lng": 127.0019},
                "ì˜ˆì‚°êµ°": {"lat": 36.6826, "lng": 126.8503},
                "ì²œì•ˆì‹œ": {"lat": 36.8151, "lng": 127.1139},
                "ì²­ì–‘êµ°": {"lat": 36.4590, "lng": 126.8025},
                "íƒœì•ˆêµ°": {"lat": 36.7456, "lng": 126.2983},
                "í™ì„±êµ°": {"lat": 36.6012, "lng": 126.6608},
                
                # ì „ë¶íŠ¹ë³„ìì¹˜ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì „ë¶íŠ¹ë³„ìì¹˜ë„": {"lat": 35.7175, "lng": 127.1530},
                "ê³ ì°½êµ°": {"lat": 35.4346, "lng": 126.7017},
                "êµ°ì‚°ì‹œ": {"lat": 35.9678, "lng": 126.7368},
                "ê¹€ì œì‹œ": {"lat": 35.8033, "lng": 126.8805},
                "ë‚¨ì›ì‹œ": {"lat": 35.4163, "lng": 127.3906},
                "ë¬´ì£¼êµ°": {"lat": 36.0073, "lng": 127.6610},
                "ë¶€ì•ˆêµ°": {"lat": 35.7318, "lng": 126.7332},
                "ìˆœì°½êµ°": {"lat": 35.3748, "lng": 127.1374},
                "ì™„ì£¼êµ°": {"lat": 35.9058, "lng": 127.1649},
                "ìµì‚°ì‹œ": {"lat": 35.9483, "lng": 126.9575},
                "ì„ì‹¤êµ°": {"lat": 35.6176, "lng": 127.2896},
                "ì¥ìˆ˜êµ°": {"lat": 35.6477, "lng": 127.5217},
                "ì „ì£¼ì‹œ": {"lat": 35.8242, "lng": 127.1480},
                "ì •ìì‹œ": {"lat": 35.5700, "lng": 126.8557},
                "ì§„ì•ˆêµ°": {"lat": 35.7917, "lng": 127.4244},
                
                # ì „ë¼ë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì „ë¼ë‚¨ë„": {"lat": 34.8679, "lng": 126.9910},
                "ê°•ì§„êµ°": {"lat": 34.6417, "lng": 126.7669},
                "ê³ í¥êµ°": {"lat": 34.6111, "lng": 127.2855},
                "ê³¡ì„±êµ°": {"lat": 35.2818, "lng": 127.2914},
                "ê´‘ì–‘ì‹œ": {"lat": 34.9406, "lng": 127.5956},
                "êµ¬ë¡€êµ°": {"lat": 35.2020, "lng": 127.4632},
                "ë‚˜ì£¼ì‹œ": {"lat": 35.0160, "lng": 126.7107},
                "ë‹´ì–‘êµ°": {"lat": 35.3214, "lng": 126.9882},
                "ëª©í¬ì‹œ": {"lat": 34.8118, "lng": 126.3922},
                "ë¬´ì•ˆêµ°": {"lat": 34.9900, "lng": 126.4816},
                "ë³´ì„±êµ°": {"lat": 34.7712, "lng": 127.0800},
                "ìˆœì²œì‹œ": {"lat": 34.9507, "lng": 127.4872},
                "ì‹ ì•ˆêµ°": {"lat": 34.8267, "lng": 126.1063},
                "ì—¬ìˆ˜ì‹œ": {"lat": 34.7604, "lng": 127.6622},
                "ì˜ê´‘êµ°": {"lat": 35.2773, "lng": 126.5120},
                "ì˜ì•”êµ°": {"lat": 34.8000, "lng": 126.6968},
                "ì™„ë„êµ°": {"lat": 34.3105, "lng": 126.7551},
                "ì¥ì„±êµ°": {"lat": 35.3017, "lng": 126.7886},
                "ì¥í¥êµ°": {"lat": 34.6816, "lng": 126.9066},
                "ì§„ë„êµ°": {"lat": 34.4867, "lng": 126.2636},
                "í•¨í‰êµ°": {"lat": 35.0666, "lng": 126.5168},
                "í•´ë‚¨êµ°": {"lat": 34.5736, "lng": 126.5986},
                "í™”ìˆœêµ°": {"lat": 35.0648, "lng": 126.9855},
                
                # ê²½ìƒë¶ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ìƒë¶ë„": {"lat": 36.4919, "lng": 128.8889},
                "ê²½ì‚°ì‹œ": {"lat": 35.8251, "lng": 128.7411},
                "ê²½ì£¼ì‹œ": {"lat": 35.8562, "lng": 129.2247},
                "ê³ ë ¹êµ°": {"lat": 35.7284, "lng": 128.2634},
                "êµ¬ë¯¸ì‹œ": {"lat": 36.1196, "lng": 128.3441},
                "êµ°ìœ„êµ°": {"lat": 36.2393, "lng": 128.5717},
                "ê¹€ì²œì‹œ": {"lat": 36.1395, "lng": 128.1137},
                "ë¬¸ê²½ì‹œ": {"lat": 36.5866, "lng": 128.1866},
                "ë´‰í™”êµ°": {"lat": 36.8932, "lng": 128.7327},
                "ìƒì£¼ì‹œ": {"lat": 36.4107, "lng": 128.1590},
                "ì„±ì£¼êµ°": {"lat": 35.9186, "lng": 128.2829},
                "ì•ˆë™ì‹œ": {"lat": 36.5684, "lng": 128.7294},
                "ì˜ë•êµ°": {"lat": 36.4153, "lng": 129.3655},
                "ì˜ì–‘êµ°": {"lat": 36.6666, "lng": 129.1124},
                "ì˜ì£¼ì‹œ": {"lat": 36.8056, "lng": 128.6239},
                "ì˜ì²œì‹œ": {"lat": 35.9733, "lng": 128.9386},
                "ì˜ˆì²œêµ°": {"lat": 36.6580, "lng": 128.4517},
                "ìš¸ë¦‰êµ°": {"lat": 37.4845, "lng": 130.9058},
                "ìš¸ì§„êµ°": {"lat": 36.9930, "lng": 129.4004},
                "ì˜ì„±êµ°": {"lat": 36.3526, "lng": 128.6974},
                "ì²­ë„êµ°": {"lat": 35.6477, "lng": 128.7363},
                "ì²­ì†¡êµ°": {"lat": 36.4359, "lng": 129.0572},
                "ì¹ ê³¡êµ°": {"lat": 35.9951, "lng": 128.4019},
                "í¬í•­ì‹œ": {"lat": 36.0190, "lng": 129.3435},
                
                # ê²½ìƒë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ìƒë‚¨ë„": {"lat": 35.4606, "lng": 128.2132},
                "ê±°ì œì‹œ": {"lat": 34.8804, "lng": 128.6212},
                "ê±°ì°½êµ°": {"lat": 35.6869, "lng": 127.9095},
                "ê³ ì„±êµ°": {"lat": 34.9735, "lng": 128.3229},
                "ê¹€í•´ì‹œ": {"lat": 35.2342, "lng": 128.8899},
                "ë‚¨í•´êµ°": {"lat": 34.8375, "lng": 127.8926},
                "ë°€ì–‘ì‹œ": {"lat": 35.5040, "lng": 128.7469},
                "ì‚¬ì²œì‹œ": {"lat": 35.0036, "lng": 128.0645},
                "ì‚°ì²­êµ°": {"lat": 35.4150, "lng": 127.8736},
                "ì–‘ì‚°ì‹œ": {"lat": 35.3350, "lng": 129.0371},
                "ì˜ë ¹êµ°": {"lat": 35.3219, "lng": 128.2618},
                "ì§„ì£¼ì‹œ": {"lat": 35.1800, "lng": 128.1076},
                "ì°½ë…•êµ°": {"lat": 35.5444, "lng": 128.4924},
                "ì°½ì›ì‹œ": {"lat": 35.2281, "lng": 128.6811},
                "í†µì˜ì‹œ": {"lat": 34.8544, "lng": 128.4331},
                "í•˜ë™êµ°": {"lat": 35.0675, "lng": 127.7514},
                "í•¨ì•ˆêµ°": {"lat": 35.2730, "lng": 128.4069},
                "í•¨ì–‘êµ°": {"lat": 35.5203, "lng": 127.7252},
                "í•©ì²œêµ°": {"lat": 35.5666, "lng": 128.1655},
            }
                        
            coords = region_coords.get(analysis.region, {"lat": 37.5665, "lng": 126.9780})
            
            url = "https://api.foursquare.com/v3/places/search"
            headers = {
                "Authorization": FOURSQUARE_API_KEY,
                "Accept": "application/json"
            }
            
            # ğŸ”¥ ì¹´í…Œê³ ë¦¬ë³„ ê°•í™”ëœ ê²€ìƒ‰ ì „ëµ
            search_strategies = []
            
            # 1) êµ¬ì²´ì ì¸ ì¥ì†Œëª… (ëŒ€í•™êµ, ê²½ê¸°ì¥ ë“±)
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ', 'ê³µí•­', 'ì—­']):
                search_strategies.append(analysis.place_name)
                
            # 2) ì§€ì—­ëª… + ì¥ì†Œëª…
            region_name = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '')
            search_strategies.append(f"{region_name} {analysis.place_name}")
            
            # 3) ğŸ”¥ ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ê²€ìƒ‰ (ê°•í™”ë¨)
            place_lower = analysis.place_name.lower()
            if any(word in place_lower for word in ["ì‹ë‹¹", "restaurant", "ì‹ì‚¬", "ë°¥", "ì €ë…", "ì ì‹¬"]):
                search_strategies.extend([
                    f"{region_name} restaurant",
                    f"{region_name} ì‹ë‹¹",
                    f"{region_name} food",
                    f"{analysis.district} restaurant"
                ])
                logger.info(f"ğŸ½ï¸ ì‹ì‚¬ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì¶”ê°€")
            elif any(word in place_lower for word in ["ì¹´í˜", "cafe", "ì»¤í”¼"]):
                search_strategies.extend([
                    f"{region_name} cafe",
                    f"{region_name} ì»¤í”¼",
                    f"{region_name} coffee"
                ])
                logger.info(f"â˜• ì¹´í˜ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì¶”ê°€")
            
            logger.info(f"ğŸ” Foursquare ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        "query": strategy,
                        "ll": f"{coords['lat']},{coords['lng']}",
                        "radius": 15000,  # 15km
                        "limit": 20,      # ë” ë§ì€ ê²°ê³¼
                        "sort": "DISTANCE"
                    }
                    
                    # ğŸ”¥ ì‹ì‚¬ ê´€ë ¨ì´ë©´ ì¹´í…Œê³ ë¦¬ í•„í„° ì¶”ê°€
                    if any(word in strategy.lower() for word in ['restaurant', 'ì‹ë‹¹', 'food']):
                        params["categories"] = "13000"  # Food & Dining
                        logger.info(f"ğŸ½ï¸ ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©")
                    elif any(word in strategy.lower() for word in ['cafe', 'coffee', 'ì»¤í”¼']):
                        params["categories"] = "13032,13040"  # Cafe, Coffee Shop
                        logger.info(f"â˜• ì¹´í˜ ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©")
                    
                    logger.info(f"ğŸ” Foursquare ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get("results"):
                                    logger.info(f"âœ… Foursquare ê²°ê³¼ {len(data['results'])}ê°œ ë°œê²¬")
                                    
                                    # ğŸ”¥ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ì ìˆ˜ ê³„ì‚° ê°•í™”
                                    for i, place in enumerate(data["results"]):
                                        location = place.get("geocodes", {}).get("main", {})
                                        address = place.get("location", {}).get("formatted_address", "")
                                        place_name = place.get("name", "")
                                        categories = place.get("categories", [])
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        logger.info(f"     ì¹´í…Œê³ ë¦¬: {[cat.get('name') for cat in categories]}")
                                        
                                        if not (location.get("latitude") and location.get("longitude")):
                                            logger.info(f"     âŒ ì¢Œí‘œ ì •ë³´ ì—†ìŒ")
                                            continue
                                        
                                        # ğŸ”¥ ê°•í™”ëœ í•„í„°ë§
                                        
                                        # 1) ë¶€ì •ì  í‚¤ì›Œë“œ í•„í„° (ëŒ€í­ ê°•í™”)
                                        negative_keywords = [
                                            "í•™ì›", "ë³‘ì›", "ì˜ì›", "ì•½êµ­", "ì€í–‰", "ë¶€ë™ì‚°", 
                                            "ìœ í•™", "í•™íšŒ", "ì»¨ì„¤íŒ…", "ì‚¬ë¬´ì‹¤", "office", 
                                            "academy", "hospital", "clinic", "bank",
                                            "real estate", "study abroad", "immigration",
                                            "consulting", "law firm", "immigration office",
                                            "ì–´í•™ì›", "ì»¨ì„¤í„´íŠ¸", "ì´ë¯¼", "ë²•ë¬´ë²•ì¸"
                                        ]
                                        
                                        is_negative = any(neg in place_name.lower() for neg in negative_keywords)
                                        
                                        if is_negative:
                                            logger.info(f"     âŒ ë¶€ì • í‚¤ì›Œë“œ í•„í„°ë§: {place_name}")
                                            continue
                                        
                                        # 2) ì¹´í…Œê³ ë¦¬ ì í•©ì„± í™•ì¸ (ëŒ€í­ ê°•í™”)
                                        category_match = False
                                        category_score = 0
                                        
                                        if any(word in strategy.lower() for word in ['restaurant', 'ì‹ë‹¹', 'food', 'ì‹ì‚¬', 'ë°¥']):
                                            # ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ í™•ì¸
                                            food_categories = [
                                                "restaurant", "food", "dining", "korean", "chinese", 
                                                "japanese", "italian", "american", "thai", "indian",
                                                "ì‹ë‹¹", "ìŒì‹ì ", "ë ˆìŠ¤í† ë‘", "eatery", "bistro",
                                                "steakhouse", "pizzeria", "noodle", "barbecue"
                                            ]
                                            for cat in categories:
                                                cat_name = cat.get("name", "").lower()
                                                if any(food_cat in cat_name for food_cat in food_categories):
                                                    category_match = True
                                                    category_score += 5
                                                    logger.info(f"     âœ… ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜: {cat_name}")
                                                    break
                                                    
                                        elif any(word in strategy.lower() for word in ['cafe', 'coffee', 'ì»¤í”¼']):
                                            # ì¹´í˜ ì¹´í…Œê³ ë¦¬ í™•ì¸
                                            cafe_categories = ["cafe", "coffee", "bakery", "dessert", "ì¹´í˜", "tea"]
                                            for cat in categories:
                                                cat_name = cat.get("name", "").lower()
                                                if any(cafe_cat in cat_name for cafe_cat in cafe_categories):
                                                    category_match = True
                                                    category_score += 5
                                                    logger.info(f"     âœ… ì¹´í˜ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜: {cat_name}")
                                                    break
                                        else:
                                            category_match = True  # ê¸°íƒ€ ê²€ìƒ‰ì€ ì¹´í…Œê³ ë¦¬ ì œí•œ ì—†ìŒ
                                            category_score += 2
                                        
                                        # 3) ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_score = 0
                                        region_keywords = [
                                            analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', ''),
                                            analysis.district
                                        ]
                                        
                                        for keyword in region_keywords:
                                            if keyword and keyword in address:
                                                region_score += 3
                                                logger.info(f"     âœ… ì§€ì—­ ì¼ì¹˜: {keyword}")
                                        
                                        # 4) ì´ë¦„ ìœ ì‚¬ë„ í™•ì¸
                                        name_score = 0
                                        search_terms = analysis.place_name.lower().split()
                                        place_terms = place_name.lower().split()
                                        
                                        for term in search_terms:
                                            if len(term) > 1:
                                                if any(term in pt for pt in place_terms):
                                                    name_score += 2
                                        
                                        # 5) ì´ì  ê³„ì‚°
                                        total_score = category_score + region_score + name_score
                                        
                                        logger.info(f"     ğŸ“Š ì ìˆ˜: ì¹´í…Œê³ ë¦¬={category_score} + ì§€ì—­={region_score} + ì´ë¦„={name_score} = {total_score}")
                                        
                                        # ğŸ”¥ ì—„ê²©í•œ ê¸°ì¤€ ì ìš© (ì‹ì‚¬/ì¹´í˜ëŠ” ì¹´í…Œê³ ë¦¬ í•„ìˆ˜)
                                        min_score = 5 if any(word in strategy.lower() for word in ['restaurant', 'ì‹ë‹¹', 'cafe']) else 3
                                        
                                        if category_match and total_score >= min_score:
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=location["latitude"],
                                                longitude=location["longitude"],
                                                source="foursquare",
                                                rating=place.get("rating")
                                            )
                                            
                                            logger.info(f"ğŸ‰ Foursquare í•„í„°ë§ ê²€ìƒ‰ ì„±ê³µ!")
                                            logger.info(f"   ğŸª ì¥ì†Œ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            logger.info(f"   ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {[cat.get('name') for cat in categories]}")
                                            return result
                                        else:
                                            logger.info(f"     âŒ ê¸°ì¤€ ë¯¸ë‹¬: ì¹´í…Œê³ ë¦¬ë§¤ì¹˜={category_match}, ì ìˆ˜={total_score} < {min_score}")
                                    
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê²°ê³¼ ì—†ìŒ")
                            else:
                                logger.warning(f"âš ï¸ Foursquare API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Foursquare ì „ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Foursquare ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def enhanced_search_with_quality_check(place_text: str) -> Optional[PlaceResult]:
        """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ê³¼ ì¬ê²€ìƒ‰ì„ í¬í•¨í•œ í–¥ìƒëœ ê²€ìƒ‰"""
        logger.info(f"ğŸ” í–¥ìƒëœ í’ˆì§ˆ ê²€ì¦ ê²€ìƒ‰ ì‹œì‘: {place_text}")
        
        # 1ë‹¨ê³„: ê¸°ë³¸ 3ì¤‘ API ê²€ìƒ‰
        result = await TripleLocationSearchService.search_triple_api(place_text)
        
        # 2ë‹¨ê³„: ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦
        if result and AddressQualityChecker.is_complete_address(result.address):
            logger.info(f"âœ… 1ì°¨ ê²€ìƒ‰ ì„±ê³µ (ì™„ì „í•œ ì£¼ì†Œ): {result.address}")
            return result
        
        logger.warning(f"âš ï¸ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ ë¶ˆì™„ì „: {result.address if result else 'None'}")
        
        # 3ë‹¨ê³„: ì¬ê²€ìƒ‰ ì „ëµ
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_text)
        category_keywords = AddressQualityChecker.get_category_keywords(place_text)
        
        logger.info(f"ğŸ”„ ì¬ê²€ìƒ‰ ì‹œì‘ - ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ: {category_keywords}")
        
        # 4ë‹¨ê³„: í™•ì¥ ê²€ìƒ‰ (ë°˜ê²½ í™•ëŒ€ + ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ)
        for radius in [1000, 2000, 5000, 10000]:  # 1km â†’ 10kmê¹Œì§€ í™•ëŒ€
            logger.info(f"ğŸ” í™•ì¥ ê²€ìƒ‰ (ë°˜ê²½ {radius}m)")
            
            for keyword in category_keywords:
                enhanced_query = f"{analysis.region} {analysis.district} {keyword}"
                
                # Kakao í™•ì¥ ê²€ìƒ‰
                kakao_result = await TripleLocationSearchService.search_kakao_enhanced(
                    analysis, enhanced_query, radius
                )
                
                if kakao_result and AddressQualityChecker.is_complete_address(kakao_result.address):
                    logger.info(f"âœ… Kakao í™•ì¥ ê²€ìƒ‰ ì„±ê³µ: {kakao_result.address}")
                    return kakao_result
                
                # Google í™•ì¥ ê²€ìƒ‰
                google_result = await TripleLocationSearchService.search_google_enhanced(
                    analysis, enhanced_query
                )
                
                if google_result and AddressQualityChecker.is_complete_address(google_result.address):
                    logger.info(f"âœ… Google í™•ì¥ ê²€ìƒ‰ ì„±ê³µ: {google_result.address}")
                    return google_result
        
        # 5ë‹¨ê³„: ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì£¼ì†Œê°€ ì™„ì „í•˜ì§€ ì•Šë”ë¼ë„)
        if result:
            logger.warning(f"âš ï¸ í™•ì¥ ê²€ìƒ‰ ì‹¤íŒ¨, 1ì°¨ ê²°ê³¼ ì‚¬ìš©: {result.address}")
            return result
        
        logger.error(f"âŒ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {place_text}")
        return None

    @staticmethod
    async def search_kakao_enhanced(analysis: LocationAnalysis, query: str, radius: int) -> Optional[PlaceResult]:
        """Kakao API í™•ì¥ ê²€ìƒ‰"""
        if not KAKAO_REST_API_KEY:
            return None
            
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
            
            params = {
                "query": query,
                "size": 10,  # ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                "radius": radius
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get("documents"):
                            # ê°€ì¥ ì™„ì „í•œ ì£¼ì†Œë¥¼ ê°€ì§„ ê²°ê³¼ ì„ íƒ
                            for place in data["documents"]:
                                address = place.get("road_address_name") or place.get("address_name", "")
                                
                                if AddressQualityChecker.is_complete_address(address):
                                    return PlaceResult(
                                        name=place.get("place_name", analysis.place_name),
                                        address=address,
                                        latitude=float(place.get("y", 0)),
                                        longitude=float(place.get("x", 0)),
                                        source="kakao_enhanced"
                                    )
                                    
        except Exception as e:
            logger.error(f"âŒ Kakao í™•ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None

    @staticmethod
    async def search_google_enhanced(analysis: LocationAnalysis, query: str) -> Optional[PlaceResult]:
        """Google Places API í™•ì¥ ê²€ìƒ‰ - ìˆ˜ì •ëœ ë²„ì „"""
        if not GOOGLE_MAPS_API_KEY:
            return None
            
        try:
            url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
            
            # ì§€ì—­ ì œí•œ ê°•í™”
            region_query = f"{analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '')} {analysis.district} {query}"
            
            params = {
                'input': region_query,
                'inputtype': 'textquery',
                'fields': 'name,formatted_address,geometry,rating',
                'language': 'ko',
                'region': 'kr',
                'key': GOOGLE_MAPS_API_KEY
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get('status') == 'OK' and data.get('candidates'):
                            for place in data['candidates']:
                                address = place.get('formatted_address', '')
                                
                                # ì§€ì—­ ì¼ì¹˜ í™•ì¸ ê°•í™”
                                region_match = any(region_name in address for region_name in 
                                                 [analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', ''), 
                                                  analysis.district])
                                
                                if AddressQualityChecker.is_complete_address(address) and region_match:
                                    location = place['geometry']['location']
                                    return PlaceResult(
                                        name=place.get('name', analysis.place_name),
                                        address=address,
                                        latitude=location['lat'],
                                        longitude=location['lng'],
                                        source="google_enhanced",
                                        rating=place.get('rating')
                                    )
                                    
        except Exception as e:
            logger.error(f"âŒ Google í™•ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None


# app.pyì˜ search_kakao í•¨ìˆ˜ ìˆ˜ì • - KOREA_REGIONS í™œìš©

    @staticmethod
    async def search_kakao(analysis: LocationAnalysis, reference_schedules: List[Dict] = None) -> Optional[PlaceResult]:
        """1ìˆœìœ„: Kakao API ê²€ìƒ‰ - ì§€ì—­ ë§¤ì¹­ ë¡œì§ ê°œì„  (ë™ëª…ì´ì¸ ë°©ì§€)"""
        if not KAKAO_REST_API_KEY:
            logger.warning("âŒ Kakao API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 1ìˆœìœ„ Kakao ê²€ìƒ‰: {analysis.place_name}")
        
        # ğŸ”¥ KOREA_REGIONSì—ì„œ ì „êµ­ êµ¬/ì‹œ/êµ° ì •ë³´ ì¶”ì¶œ
        all_districts = []
        for region, districts in KOREA_REGIONS.items():
            all_districts.extend(list(districts))
        
        logger.info(f"ğŸ“ ì „êµ­ êµ¬/ì‹œ/êµ° {len(all_districts)}ê°œ ì§€ì—­ ëŒ€ì‘")
        
        # ğŸ”¥ ì°¸ì¡° ìœ„ì¹˜ì—ì„œ ì •í™•í•œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ (ì‹œ/ë„ + êµ¬/ì‹œ/êµ°)
        reference_region = None
        reference_district = None
        reference_dong = None
        
        if reference_schedules:
            for ref_schedule in reference_schedules:
                ref_location = ref_schedule.get("location", "")
                if ref_location:
                    logger.info(f"ğŸ“ ì°¸ì¡° ìœ„ì¹˜ ë¶„ì„: {ref_location}")
                    
                    # ì‹œ/ë„ ì •ë³´ ì¶”ì¶œ (ë” ì •í™•í•˜ê²Œ)
                    for region_key, districts in KOREA_REGIONS.items():
                        region_short = region_key.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                        if region_short in ref_location or region_key in ref_location:
                            reference_region = region_key
                            logger.info(f"   ğŸ“ ì°¸ì¡° ì‹œ/ë„: {region_key}")
                            
                            # í•´ë‹¹ ì‹œ/ë„ì˜ êµ¬/ì‹œ/êµ°ë§Œ í™•ì¸
                            for district in districts:
                                if district in ref_location:
                                    reference_district = district
                                    logger.info(f"   ğŸ“ ì°¸ì¡° êµ¬/ì‹œ/êµ°: {district}")
                                    break
                            break
                    
                    # ë™ ì •ë³´ë„ ì¶”ì¶œ ì‹œë„
                    import re
                    dong_match = re.search(r'(\w+ë™)', ref_location)
                    if dong_match:
                        reference_dong = dong_match.group(1)
                        logger.info(f"   ğŸ“ ì°¸ì¡° ë™: {reference_dong}")
                    
                    break

        # ğŸ†• ê°œì„ ëœ ë§¤ì¹­ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€)
        def check_region_match_improved(address: str, reference_region: str, reference_region_short: str) -> bool:
            """ê°œì„ ëœ ì§€ì—­ ë§¤ì¹­ (ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€)"""
            if not address or not reference_region:
                return False
            
            # ëª¨ë“  ì§€ì—­ ë³€í˜•ë“¤ ê°€ì ¸ì˜¤ê¸°
            region_variants = region_normalizer.get_region_variants(reference_region)
            
            # ê¸°ì¡´ ë³€ìˆ˜ë“¤ë„ í¬í•¨
            all_variants = region_variants + [reference_region_short, reference_region]
            all_variants = list(set(all_variants))  # ì¤‘ë³µ ì œê±°
            
            # ë§¤ì¹­ í™•ì¸
            for variant in all_variants:
                if variant and variant in address:
                    return True
            
            return False

        def check_district_match_improved(address: str, reference_district: str) -> bool:
            """ê°œì„ ëœ êµ¬/ì‹œ/êµ° ë§¤ì¹­"""
            if not address or not reference_district:
                return False
            
            # ì •í™•í•œ ë§¤ì¹­
            if reference_district in address:
                return True
            
            # ë¶€ë¶„ ë§¤ì¹­ (ì˜ˆ: "ì–‘ì‚°ì‹œì²­" â†’ "ì–‘ì‚°ì‹œ")
            if reference_district.endswith(('ì‹œ', 'êµ°', 'êµ¬')):
                base_name = reference_district[:-1]  # 'ì‹œ', 'êµ°', 'êµ¬' ì œê±°
                if base_name in address:
                    return True
            
            return False

        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
            
            # ğŸ”¥ ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì „ëµ
            search_strategies = []
            
            # 1) êµ¬ì²´ì  ì¥ì†Œëª… (ì—­, ëŒ€í•™êµ ë“±)ì€ ì§€ì—­ ì œí•œ ì—†ì´
            if any(keyword in analysis.place_name.lower() for keyword in ['ì—­', 'ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ê³µí•­', 'ë³‘ì›', 'ë§ˆíŠ¸', 'í„°ë¯¸ë„']):
                search_strategies.append(analysis.place_name)
                if reference_district and reference_region:
                    # ì‹œ/ë„ + êµ¬/ì‹œ/êµ° í•¨ê»˜ ê²€ìƒ‰
                    region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    search_strategies.append(f"{region_short} {reference_district} {analysis.place_name}")
                search_strategies.append(f"{analysis.district} {analysis.place_name}")
            
            # 2) ğŸ”¥ ì‹ì‚¬/ì¹´í˜ëŠ” ë°˜ë“œì‹œ ì •í™•í•œ ì§€ì—­ìœ¼ë¡œ ê²€ìƒ‰ (ì‹œ/ë„ + êµ¬/ì‹œ/êµ°)
            elif any(word in analysis.place_name.lower() for word in ['ì‹ì‚¬', 'ì‹ë‹¹', 'ë°¥', 'ì¹´í˜', 'ì»¤í”¼', 'ë§›ì§‘']):
                
                if reference_district and reference_region:
                    reference_region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                    
                    # A) ë™ ë‹¨ìœ„ ê²€ìƒ‰ (ì‹œ/ë„ + êµ¬/ì‹œ/êµ° + ë™)
                    if reference_dong:
                        search_strategies.extend([
                            f"{reference_region_short} {reference_district} {reference_dong} ë§›ì§‘",
                            f"{reference_region_short} {reference_district} {reference_dong} ì‹ë‹¹",
                            f"{reference_district} {reference_dong} ë§›ì§‘"
                        ])
                    
                    # B) êµ¬/ì‹œ/êµ° + ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ (ì‹œ/ë„ í¬í•¨)
                    search_strategies.extend([
                        f"{reference_region_short} {reference_district} ë§›ì§‘",
                        f"{reference_region_short} {reference_district} ì‹ë‹¹",
                        f"{reference_region_short} {reference_district} ì¹´í˜",
                        f"{reference_region} {reference_district} ë§›ì§‘"  # ì „ì²´ ì‹œ/ë„ëª…ë„ ì‹œë„
                    ])
                    
                    logger.info(f"ğŸ¯ ì°¸ì¡° ì§€ì—­ '{reference_region_short} {reference_district}' ê¸°ì¤€ ê²€ìƒ‰")
                    
                else:
                    # ì°¸ì¡° ì—†ìœ¼ë©´ analysis ì •ë³´ í™œìš©
                    analysis_region_short = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    search_strategies.extend([
                        f"{analysis_region_short} {analysis.district} ë§›ì§‘",
                        f"{analysis_region_short} {analysis.district} ì‹ë‹¹",
                        f"{analysis.region} {analysis.district} ë§›ì§‘"
                    ])
            
            # 3) ê¸°íƒ€ ì¼ë°˜ ê²€ìƒ‰
            else:
                if reference_district and reference_region:
                    region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    search_strategies.extend([
                        f"{region_short} {reference_district} {analysis.place_name}",
                        f"{analysis.place_name}"
                    ])
                else:
                    search_strategies.extend([
                        f"{analysis.district} {analysis.place_name}",
                        f"{analysis.place_name}"
                    ])
            
            # ì¤‘ë³µ ì œê±°
            search_strategies = list(dict.fromkeys(search_strategies))
            
            logger.info(f"ğŸ” ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì „ëµ ({len(search_strategies)}ê°œ):")
            for i, strategy in enumerate(search_strategies):
                logger.info(f"   {i+1}. {strategy}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        "query": strategy,
                        "size": 15,  # ë” ë§ì€ ê²°ê³¼
                        "sort": "accuracy"
                    }
                    
                    logger.info(f"ğŸ” Kakao ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get("documents"):
                                    logger.info(f"âœ… Kakao ê²°ê³¼ {len(data['documents'])}ê°œ ë°œê²¬")
                                    
                                    for i, place in enumerate(data["documents"]):
                                        place_name = place.get("place_name", "")
                                        address = place.get("road_address_name") or place.get("address_name", "")
                                        category = place.get("category_name", "")
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        
                                        if not address.strip():
                                            continue
                                        
                                        # ğŸ”¥ ê°œì„ ëœ ì§€ì—­ ë§¤ì¹­ ì ìˆ˜ (ë™ëª…ì´ì¸ ë°©ì§€)
                                        location_score = 0
                                        
                                        if reference_district and reference_region:
                                            # ğŸ“ ì°¸ì¡° ì§€ì—­ì´ ìˆì„ ë•Œ: ì‹œ/ë„ + êµ¬/ì‹œ/êµ° ëª¨ë‘ í™•ì¸
                                            reference_region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                                            
                                            # ğŸ†• ê°œì„ ëœ ë§¤ì¹­ ë¡œì§ ì ìš©
                                            address_has_region = check_region_match_improved(address, reference_region, reference_region_short)
                                            address_has_district = check_district_match_improved(address, reference_district)
                                            
                                            if address_has_region and address_has_district:
                                                location_score += 10  # ğŸ”¥ ì‹œ/ë„ + êµ¬/ì‹œ/êµ° ëª¨ë‘ ì¼ì¹˜ (ìµœê³ ì )
                                                logger.info(f"     âœ… ì™„ì „ ì§€ì—­ ì¼ì¹˜ ({reference_region_short} {reference_district})")
                                            elif address_has_district and not address_has_region:
                                                # ğŸ”¥ ê°™ì€ êµ¬ëª…ì´ì§€ë§Œ ë‹¤ë¥¸ ì‹œ/ë„ (ì˜ˆ: ë¶€ì‚° ë™êµ¬ vs ëŒ€êµ¬ ë™êµ¬)
                                                location_score -= 20  # ëŒ€í­ ê°ì 
                                                logger.warning(f"     âŒ ë™ëª…ì´ì¸ ì§€ì—­! {reference_district}ì´ì§€ë§Œ ë‹¤ë¥¸ ì‹œ/ë„ ({address})")
                                            elif address_has_region and not address_has_district:
                                                # ê°™ì€ ì‹œ/ë„ ë‚´ ë‹¤ë¥¸ êµ¬/ì‹œ/êµ°
                                                found_district = None
                                                if reference_region in KOREA_REGIONS:
                                                    region_districts = KOREA_REGIONS[reference_region]
                                                    for district in region_districts:
                                                        if district in address:
                                                            found_district = district
                                                            break
                                                
                                                if found_district:
                                                    location_score += 5  # ê°™ì€ ì‹œ/ë„ ë‚´
                                                    logger.info(f"     âœ… ê°™ì€ ì‹œ/ë„ ë‚´ ({reference_region_short} {found_district})")
                                                else:
                                                    location_score += 2  # ê°™ì€ ì‹œ/ë„ì´ì§€ë§Œ êµ¬ ë¶ˆë¶„ëª…
                                                    logger.info(f"     âœ… ê°™ì€ ì‹œ/ë„ ({reference_region_short})")
                                            else:
                                                location_score += 1  # ê¸°íƒ€ ì§€ì—­
                                                
                                        elif reference_district:
                                            # ì°¸ì¡° êµ¬/ì‹œ/êµ°ë§Œ ìˆì„ ë•Œ (ì‹œ/ë„ ì •ë³´ ì—†ìŒ)
                                            address_has_district = check_district_match_improved(address, reference_district)
                                            
                                            if address_has_district:
                                                # ğŸ”¥ êµ¬ëª…ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš° ì¶”ê°€ ê²€ì¦ í•„ìš”
                                                # í•œêµ­ì—ì„œ ë™ëª…ì´ì¸ ê°€ëŠ¥ì„± ë†’ì€ êµ¬ëª…ë“¤
                                                common_district_names = ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬"]
                                                
                                                if reference_district in common_district_names:
                                                    # ë™ëª…ì´ì¸ ê°€ëŠ¥ì„± ë†’ìŒ - ë‚®ì€ ì ìˆ˜
                                                    location_score += 2
                                                    logger.warning(f"     âš ï¸ ë™ëª…ì´ì¸ ê°€ëŠ¥ ì§€ì—­: {reference_district}")
                                                else:
                                                    # ê³ ìœ í•œ êµ¬ëª… (ì˜ˆ: "ì˜ë“±í¬êµ¬", "ê¸ˆì •êµ¬")
                                                    location_score += 6
                                                    logger.info(f"     âœ… ê³ ìœ  êµ¬ëª… ì¼ì¹˜ ({reference_district})")
                                            else:
                                                location_score += 1  # ê¸°íƒ€
                                                
                                        else:
                                            # ì°¸ì¡° ì§€ì—­ ì—†ìœ¼ë©´ analysis ì§€ì—­ê³¼ ë¹„êµ
                                            analysis_region_short = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                                            
                                            # ğŸ†• ê°œì„ ëœ ë§¤ì¹­ ë¡œì§ ì ìš©
                                            address_has_analysis_region = check_region_match_improved(address, analysis.region, analysis_region_short)
                                            address_has_analysis_district = check_district_match_improved(address, analysis.district)
                                            
                                            if address_has_analysis_district and address_has_analysis_region:
                                                location_score += 8  # ë¶„ì„ ì§€ì—­ ì™„ì „ ì¼ì¹˜
                                                logger.info(f"     âœ… ë¶„ì„ ì§€ì—­ ì™„ì „ ì¼ì¹˜ ({analysis_region_short} {analysis.district})")
                                            elif address_has_analysis_district:
                                                # êµ¬ëª…ë§Œ ì¼ì¹˜ - ë™ëª…ì´ì¸ ì²´í¬
                                                common_district_names = ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬"]
                                                if analysis.district in common_district_names:
                                                    location_score += 2  # ë™ëª…ì´ì¸ ê°€ëŠ¥ì„±ìœ¼ë¡œ ë‚®ì€ ì ìˆ˜
                                                    logger.warning(f"     âš ï¸ ë™ëª…ì´ì¸ ê°€ëŠ¥: {analysis.district}")
                                                else:
                                                    location_score += 5  # ê³ ìœ  êµ¬ëª…
                                            elif address_has_analysis_region:
                                                location_score += 3  # ì‹œ/ë„ë§Œ ì¼ì¹˜
                                                logger.info(f"     âœ… ì‹œ/ë„ ì¼ì¹˜ ({analysis_region_short})")
                                            else:
                                                location_score += 1  # ê¸°íƒ€
                                        
                                        # ì¹´í…Œê³ ë¦¬ ì ìˆ˜
                                        category_score = 0
                                        if any(word in strategy.lower() for word in ["ë§›ì§‘", "ì‹ë‹¹", "ë°¥"]):
                                            if any(cat in category for cat in ["ìŒì‹ì ", "ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹"]):
                                                category_score += 3
                                                logger.info(f"     âœ… ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜")
                                        elif "ì¹´í˜" in strategy.lower():
                                            if any(cat in category for cat in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸"]):
                                                category_score += 3
                                                logger.info(f"     âœ… ì¹´í˜ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜")
                                        
                                        # ë¶€ì • í‚¤ì›Œë“œ (ì‹ë‹¹ì´ ì•„ë‹Œ ê²ƒë“¤ í•„í„°ë§)
                                        negative_score = 0
                                        negative_keywords = ["í•™ì›", "ë³‘ì›", "ì˜ì›", "ì•½êµ­", "ì€í–‰", "ë¶€ë™ì‚°", "ìœ í•™", "í•™íšŒ", "ì»¨ì„¤íŒ…"]
                                        if any(neg in place_name.lower() for neg in negative_keywords):
                                            negative_score -= 10
                                            logger.info(f"     âŒ ë¶€ì • í‚¤ì›Œë“œ ({place_name})")
                                        
                                        # ì´ì  ê³„ì‚°
                                        total_score = location_score + category_score + negative_score
                                        
                                        logger.info(f"     ğŸ“Š ì ìˆ˜: ì§€ì—­={location_score} + ì¹´í…Œê³ ë¦¬={category_score} + ë¶€ì •={negative_score} = {total_score}")
                                        
                                        # ğŸ”¥ ë†’ì€ ì ìˆ˜ ê¸°ì¤€ (ë™ëª…ì´ì¸ ë°©ì§€)
                                        min_score = 8 if reference_region and reference_district else 6
                                        
                                        if total_score >= min_score:
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=float(place.get("y", 0)),
                                                longitude=float(place.get("x", 0)),
                                                source="kakao"
                                            )
                                            
                                            logger.info(f"ğŸ‰ Kakao ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì„±ê³µ!")
                                            logger.info(f"   ğŸª ì¥ì†Œ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            logger.info(f"   ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {category}")
                                            logger.info(f"   ğŸ¯ ê²€ìƒ‰ì–´: {strategy}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê¸°ì¤€ ë¯¸ë‹¬ (ìµœê³ ì : {max([total_score for _ in range(1)] or [0])})")
                                else:
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê²°ê³¼ ì—†ìŒ")
                            else:
                                logger.warning(f"âš ï¸ Kakao API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Kakao ì „ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Kakao ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def search_google(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """2ìˆœìœ„: Google Places API ê²€ìƒ‰ - ê°•í™”ëœ ë²„ì „"""
        if not GOOGLE_MAPS_API_KEY:
            logger.warning("âŒ Google API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 2ìˆœìœ„ Google ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
            
            # ê²€ìƒ‰ ì „ëµ
            region_name = analysis.region.replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ì‹œ', '')
            search_strategies = []
            
            # êµ¬ì²´ì  ì¥ì†Œëª…
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ']):
                search_strategies.extend([
                    f"{region_name} {analysis.place_name}",
                    analysis.place_name
                ])
            
            # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
            place_lower = analysis.place_name.lower()
            if any(word in place_lower for word in ['ì‹ë‹¹', 'restaurant']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} restaurant",
                    f"{region_name} ë§›ì§‘"
                ])
            elif any(word in place_lower for word in ['ì¹´í˜', 'cafe']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} cafe",
                    f"{region_name} ì¹´í˜"
                ])
            
            logger.info(f"ğŸ” Google ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        'input': strategy,
                        'inputtype': 'textquery',
                        'fields': 'name,formatted_address,geometry,rating,types',
                        'language': 'ko',
                        'region': 'kr',
                        'key': GOOGLE_MAPS_API_KEY
                    }
                    
                    logger.info(f"ğŸ” Google ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get('status') == 'OK' and data.get('candidates'):
                                    logger.info(f"âœ… Google ê²°ê³¼ {len(data['candidates'])}ê°œ ë°œê²¬")
                                    
                                    for i, place in enumerate(data['candidates']):
                                        place_name = place.get('name', '')
                                        address = place.get('formatted_address', '')
                                        types = place.get('types', [])
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        logger.info(f"     íƒ€ì…: {types}")
                                        
                                        # ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_keywords = [region_name, analysis.district]
                                        region_match = any(keyword in address for keyword in region_keywords if keyword)
                                        
                                        # íƒ€ì… ì í•©ì„± í™•ì¸
                                        type_match = False
                                        if "ì‹ë‹¹" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["restaurant", "food", "meal_takeaway"])
                                        elif "ì¹´í˜" in analysis.place_name.lower():  
                                            type_match = any(t in types for t in ["cafe", "bakery"])
                                        elif "ëŒ€í•™êµ" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["university", "school"])
                                        elif "ê²½ê¸°ì¥" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["stadium", "gym"])
                                        else:
                                            type_match = True
                                        
                                        score = (1 if region_match else 0) + (1 if type_match else 0)
                                        logger.info(f"     ì§€ì—­ì¼ì¹˜: {region_match}, íƒ€ì…ì í•©: {type_match}, ì ìˆ˜: {score}")
                                        
                                        if score >= 1:
                                            location = place['geometry']['location']
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=location['lat'],
                                                longitude=location['lng'],
                                                source="google",
                                                rating=place.get('rating')
                                            )
                                            
                                            logger.info(f"âœ… Google ê²€ìƒ‰ ì„±ê³µ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ Google ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ Google API ì‘ë‹µ: {data.get('status', 'UNKNOWN')}")
                            else:
                                logger.warning(f"âš ï¸ Google API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ Google ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Google ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Google ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def search_triple_api(place_text: str) -> Optional[PlaceResult]:
        """3ì¤‘ API ìˆœì°¨ ê²€ìƒ‰ - ì¹´ì¹´ì˜¤ ìš°ì„ ìœ¼ë¡œ ë³€ê²½"""
        logger.info(f"ğŸ¯ 3ì¤‘ API ê²€ìƒ‰ ì‹œì‘: {place_text}")
        
        # 1ë‹¨ê³„: GPTë¡œ ì§€ì—­ ë¶„ì„
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_text)
        logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {analysis.region} {analysis.district} - {analysis.place_name}")
        
        # 2ë‹¨ê³„: ê²€ìƒ‰ ìˆœì„œ ê²°ì • - ì¹´ì¹´ì˜¤ ìš°ì„ !
        search_methods = [
            ("Kakao (1ìˆœìœ„)", TripleLocationSearchService.search_kakao),
            ("Google (2ìˆœìœ„)", TripleLocationSearchService.search_google),
            ("Foursquare (3ìˆœìœ„)", TripleLocationSearchService.search_foursquare)
        ]
        
        for api_name, search_method in search_methods:
            try:
                result = await asyncio.wait_for(search_method(analysis), timeout=10)
                if result and result.address and result.address.strip():
                    logger.info(f"ğŸ‰ {api_name}ì—ì„œ ê²€ìƒ‰ ì„±ê³µ!")
                    return result
                else:
                    logger.info(f"âš ï¸ {api_name} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, ë‹¤ìŒ API ì‹œë„...")
            except asyncio.TimeoutError:
                logger.warning(f"â° {api_name} ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ")
            except Exception as e:
                logger.error(f"âŒ {api_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # ëª¨ë“  API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¢Œí‘œ ë°˜í™˜
        logger.warning(f"âš ï¸ ëª¨ë“  API ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ì¢Œí‘œ ì‚¬ìš©: {place_text}")
        return None

# ----- ë¹„ë™ê¸° ìœ„ì¹˜ ì •ë³´ ë³´ê°• -----
async def enhance_locations_with_triple_api(schedule_data: Dict) -> Dict:
    """3ì¤‘ APIë¡œ ìœ„ì¹˜ ì •ë³´ ë³´ê°• - ì°¸ì¡° ìœ„ì¹˜ í™œìš©"""
    logger.info("ğŸš€ 3ì¤‘ API ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹œì‘")
    
    try:
        enhanced_data = json.loads(json.dumps(schedule_data))
        
        # ëª¨ë“  ì¼ì • ìˆ˜ì§‘ (ìˆœì„œëŒ€ë¡œ)
        all_schedules = []
        all_schedules.extend(enhanced_data.get("fixedSchedules", []))
        all_schedules.extend(enhanced_data.get("flexibleSchedules", []))
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì´ì „ ì¼ì •ì˜ ìœ„ì¹˜ë¥¼ ì°¸ì¡°ë¡œ í™œìš©
        processed_schedules = []
        
        for i, schedule in enumerate(all_schedules):
            # ì´ì „ ì²˜ë¦¬ëœ ì¼ì •ë“¤ì„ ì°¸ì¡°ë¡œ ì „ë‹¬
            enhanced_schedule = await enhance_single_schedule_triple(schedule, processed_schedules)
            processed_schedules.append(enhanced_schedule)
        
        logger.info(f"âœ… 3ì¤‘ API ìœ„ì¹˜ ë³´ê°• ì™„ë£Œ: {len(processed_schedules)}ê°œ ì²˜ë¦¬")
        
        return enhanced_data
        
    except Exception as e:
        logger.error(f"âŒ 3ì¤‘ API ìœ„ì¹˜ ë³´ê°• ì‹¤íŒ¨: {e}")
        return schedule_data

def _is_reasonable_distance(address1: str, address2: str) -> bool:
    """ë‘ ì£¼ì†Œê°€ í•©ë¦¬ì ì¸ ê±°ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
    try:
        # ì‹œ/ë„ ë‹¨ìœ„ ë¹„êµ
        regions1 = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        
        region1 = None
        region2 = None
        
        for region in regions1:
            if region in address1:
                region1 = region
            if region in address2:
                region2 = region
        
        # ê°™ì€ ê´‘ì—­ì‹œ/ë„ë©´ OK
        if region1 == region2:
            return True
        
        # ì¸ì ‘ ì§€ì—­ í—ˆìš© (ì˜ˆ: ì„œìš¸-ê²½ê¸°, ë¶€ì‚°-ê²½ë‚¨ ë“±)
        adjacent_regions = {
            "ì„œìš¸": ["ê²½ê¸°"],
            "ê²½ê¸°": ["ì„œìš¸", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨"],
            "ë¶€ì‚°": ["ê²½ë‚¨"],
            "ê²½ë‚¨": ["ë¶€ì‚°", "ê²½ë¶"],
            "ìš¸ì‚°": ["ê²½ë‚¨", "ê²½ë¶"],
            "ëŒ€êµ¬": ["ê²½ë¶", "ê²½ë‚¨"]
        }
        
        if region1 in adjacent_regions and region2 in adjacent_regions[region1]:
            return True
        if region2 in adjacent_regions and region1 in adjacent_regions[region2]:
            return True
            
        # ê·¸ ì™¸ëŠ” ë„ˆë¬´ ë©€ë‹¤ê³  íŒë‹¨
        logger.info(f"ğŸ“ ê±°ë¦¬ ì²´í¬: {region1} vs {region2} - ë„ˆë¬´ ë©€ìŒ")
        return False
        
    except Exception:
        return True  # ì˜¤ë¥˜ ì‹œ í—ˆìš©
    
async def enhance_single_schedule_triple(schedule: Dict, reference_schedules: List[Dict] = None):
    """ë‹¨ì¼ ì¼ì •ì˜ 3ì¤‘ API + í’ˆì§ˆ ê²€ì¦ ìœ„ì¹˜ ê²€ìƒ‰ - ì¹´ì¹´ì˜¤ ìš°ì„ """
    place_name = schedule.get("name", "")
    if not place_name:
        return schedule
    
    logger.info(f"ğŸ¯ í’ˆì§ˆ ê²€ì¦ ìœ„ì¹˜ ê²€ìƒ‰: {place_name}")
    
    # ì°¸ì¡° ìœ„ì¹˜ ì°¾ê¸°
    reference_location = None
    if reference_schedules:
        for ref_schedule in reference_schedules:
            if ref_schedule.get("location") and ref_schedule["location"].strip():
                reference_location = ref_schedule["location"]
                logger.info(f"ğŸ“ ì°¸ì¡° ìœ„ì¹˜ ì„¤ì •: {reference_location}")
                break
    
    try:
        # ì°¸ì¡° ìœ„ì¹˜ë¥¼ ê³ ë ¤í•œ ë¶„ì„
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_name, reference_location)
        
        # ì¹´ì¹´ì˜¤ ìš°ì„  ê²€ìƒ‰ ìˆœì„œ
        search_methods = [
            ("Kakao", TripleLocationSearchService.search_kakao),
            ("Google", TripleLocationSearchService.search_google),
            ("Foursquare", TripleLocationSearchService.search_foursquare)
        ]
        
        for api_name, search_method in search_methods:
            try:
                result = await asyncio.wait_for(search_method(analysis), timeout=10)
                if result and result.address and result.address.strip():
                    # ì°¸ì¡° ìœ„ì¹˜ì™€ì˜ ê±°ë¦¬ ì²´í¬
                    if reference_location and not _is_reasonable_distance(reference_location, result.address):
                        logger.warning(f"âš ï¸ {api_name} ê²°ê³¼ê°€ ì°¸ì¡° ìœ„ì¹˜ì™€ ë„ˆë¬´ ë©€ì–´ì„œ ì œì™¸: {result.address}")
                        continue
                    
                    schedule["location"] = result.address
                    schedule["latitude"] = result.latitude
                    schedule["longitude"] = result.longitude
                    
                    logger.info(f"âœ… {api_name} ìœ„ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {place_name}")
                    logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                    return schedule
                    
            except Exception as e:
                logger.error(f"âŒ {api_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ ëª¨ë“  API ê²€ìƒ‰ ì‹¤íŒ¨: {place_name}")
            
    except Exception as e:
        logger.error(f"âŒ ìœ„ì¹˜ ê²€ìƒ‰ ì˜¤ë¥˜: {place_name}, {e}")
    
    return schedule

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ -----
async def run_in_executor(func, *args, **kwargs):
    """ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor(max_workers=4) as executor:
        return await loop.run_in_executor(executor, func, *args, **kwargs)

def safe_parse_json(json_str):
    """ì•ˆì „í•œ JSON íŒŒì‹±"""
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }

# app.pyì˜ create_schedule_chain() í•¨ìˆ˜ ê°œì„ 

def create_schedule_chain(voice_input: str):
    """ë™ì  í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ëŠ” LangChain ì²´ì¸ ìƒì„±"""
    logger.info("ğŸ”— ë™ì  LangChain ì²´ì¸ ìƒì„± ì‹œì‘")
    
    current_time = int(datetime.datetime.now().timestamp() * 1000)
    today = datetime.datetime.now()
    current_hour = today.hour
    
    # í˜„ì¬ ì‹œê°„ëŒ€ ì„¤ëª…
    if 6 <= current_hour < 12:
        current_time_desc = "ì˜¤ì „"
    elif 12 <= current_hour < 18:
        current_time_desc = "ì˜¤í›„"
    elif 18 <= current_hour < 22:
        current_time_desc = "ì €ë…"
    else:
        current_time_desc = "ë°¤"
    
    # ğŸ”¥ ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í•‘ ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    template = f"""ë‹¤ìŒ ìŒì„± ë©”ì‹œì§€ì—ì„œ **ê° ì¥ì†Œë¥¼ ê°œë³„ ì¼ì •ìœ¼ë¡œ** ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ìŒì„± ë©”ì‹œì§€: {{input}}

í˜„ì¬ ì‹œê°„: {current_hour}ì‹œ ({current_time_desc})
í˜„ì¬ ë‚ ì§œ: {today.strftime('%Y-%m-%d')}

**ğŸ”¥ ì¤‘ìš”í•œ ë¶„ë¦¬ ê·œì¹™**:
1. "Aì—ì„œ Bê¹Œì§€" â†’ Aì™€ Bë¥¼ **ë°˜ë“œì‹œ ê°ê° ë³„ë„ ì¼ì •**ìœ¼ë¡œ ì¶”ì¶œ
2. "ì¤‘ê°„ì— C" â†’ Cë¥¼ **ë°˜ë“œì‹œ ë³„ë„ ì¼ì •**ìœ¼ë¡œ ì¶”ì¶œ  
3. ì ˆëŒ€ë¡œ "Aì—ì„œ B ì´ë™" ê°™ì€ í†µí•© ì´ë¦„ ì‚¬ìš© ê¸ˆì§€
4. ê° ì¥ì†ŒëŠ” ë…ë¦½ì ì¸ ì¼ì •ìœ¼ë¡œ ì²˜ë¦¬

**ì˜¬ë°”ë¥¸ ì˜ˆì‹œ**:
ì…ë ¥: "ë¶€ì‚°ì—­ì—ì„œ ì¥ì „ì—­ê¹Œì§€ ê°€ëŠ”ë°, ì¤‘ê°„ì— ì €ë…ë¨¹ê³ ì‹¶ì–´"
â†’ ë°˜ë“œì‹œ 3ê°œ ì¼ì •: 
1) "ë¶€ì‚°ì—­" (17:00-17:30)
2) "ì €ë… ì‹ì‚¬" (18:00-20:00) 
3) "ì¥ì „ì—­" (20:30-21:00)

**ì‹œê°„ ê·œì¹™**:
- "ì €ë…" â†’ 18:00~20:00
- "ì ì‹¬" â†’ 12:00~14:00  
- "ì•„ì¹¨" â†’ 08:00~10:00
- ìˆœì„œëŒ€ë¡œ ë°°ì¹˜ (ì´ë™ì‹œê°„ 30ë¶„ ê³ ë ¤)

JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
{{{{
  "fixedSchedules": [
    {{{{
      "id": "{current_time}_1",
      "name": "ë¶€ì‚°ì—­",
      "type": "FIXED",
      "duration": 30,
      "priority": 1,
      "location": "",
      "latitude": 35.1156,
      "longitude": 129.0419,
      "startTime": "{today.strftime('%Y-%m-%d')}T17:00:00",
      "endTime": "{today.strftime('%Y-%m-%d')}T17:30:00"
    }}}},
    {{{{
      "id": "{current_time}_2", 
      "name": "ì €ë… ì‹ì‚¬",
      "type": "FIXED",
      "duration": 120,
      "priority": 2,
      "location": "",
      "latitude": 35.2,
      "longitude": 129.1,
      "startTime": "{today.strftime('%Y-%m-%d')}T18:00:00",
      "endTime": "{today.strftime('%Y-%m-%d')}T20:00:00"
    }}}},
    {{{{
      "id": "{current_time}_3",
      "name": "ì¥ì „ì—­",
      "type": "FIXED",
      "duration": 30,
      "priority": 3,
      "location": "",
      "latitude": 35.2311,
      "longitude": 129.0839,
      "startTime": "{today.strftime('%Y-%m-%d')}T20:30:00",
      "endTime": "{today.strftime('%Y-%m-%d')}T21:00:00"
    }}}}
  ],
  "flexibleSchedules": []
}}}}

**ì£¼ì˜ì‚¬í•­**:
1. **ê° ì¥ì†Œë¥¼ ê°œë³„ ì¼ì •ìœ¼ë¡œ ë°˜ë“œì‹œ ë¶„ë¦¬**
2. **nameì€ ë‹¨ìˆœí•œ ì¥ì†Œëª…/í™œë™ëª…ë§Œ ì‚¬ìš©**
3. **JSONë§Œ ë°˜í™˜**, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€
"""
    
    # ğŸ”¥ LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    prompt = PromptTemplate(
        template=template,
        input_variables=["input"]  # inputë§Œ ë³€ìˆ˜ë¡œ ì‚¬ìš©
    )
    
    # LLM ì´ˆê¸°í™”
    logger.info("ğŸ¤– OpenAI LLM ì´ˆê¸°í™” ì¤‘...")
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model_name="gpt-3.5-turbo",
        temperature=0,
        max_tokens=1500
    )
    logger.info("âœ… OpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
    
    # JSON íŒŒì„œ
    parser = JsonOutputParser()
    
    # ì²´ì¸ ì¡°í•©
    logger.info("ğŸ”— ì²´ì¸ ì¡°í•© ì¤‘...")
    chain = prompt | llm | parser
    logger.info("âœ… LangChain ì²´ì¸ ìƒì„± ì™„ë£Œ")
    
    return chain

# ----- ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ -----
@app.get("/")
async def root():
    return {"message": "3ì¤‘ API (Foursquare+Kakao+Google) ì •í™•í•œ ì£¼ì†Œ ê²€ìƒ‰ ì¼ì • ì¶”ì¶œ API v3.0", "status": "running"}

# app.pyì—ì„œ AddressQualityChecker í´ë˜ìŠ¤ ë’¤ì— ì¶”ê°€ (í´ë˜ìŠ¤ ë°–ì—!)

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ -----
def normalize_priorities(schedules_data: Dict[str, Any]) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì •ìˆ˜ë¡œ ì •ê·œí™”"""
    logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ìˆ˜ ë³€í™˜ ì‹œì‘")
    
    all_schedules = []
    all_schedules.extend(schedules_data.get("fixedSchedules", []))
    all_schedules.extend(schedules_data.get("flexibleSchedules", []))
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    all_schedules.sort(key=lambda s: s.get("priority", 999))
    
    # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ë¡œ ì¬í• ë‹¹
    for i, schedule in enumerate(all_schedules):
        old_priority = schedule.get("priority", "ì—†ìŒ")
        new_priority = i + 1
        schedule["priority"] = new_priority
        logger.info(f"ìš°ì„ ìˆœìœ„ ì •ê·œí™”: '{schedule.get('name', '')}' {old_priority} â†’ {new_priority}")
    
    # ë‹¤ì‹œ ë¶„ë¥˜
    fixed_schedules = [s for s in all_schedules if s.get("type") == "FIXED" and "startTime" in s]
    flexible_schedules = [s for s in all_schedules if s.get("type") != "FIXED" or "startTime" not in s]
    
    logger.info(f"âœ… ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì™„ë£Œ: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
    
    return {
        "fixedSchedules": fixed_schedules,
        "flexibleSchedules": flexible_schedules
    }



 # 1. ì§€ë¦¬ì  ì¤‘ê°„ì  ìë™ ê³„ì‚°
def calculate_geographic_midpoint(start_coords: tuple, end_coords: tuple, buffer_radius: float = 0.01) -> Dict:
    """ë‘ ì§€ì ì˜ ì§€ë¦¬ì  ì¤‘ê°„ì ê³¼ ê²€ìƒ‰ ë°˜ê²½ ìë™ ê³„ì‚°"""
    start_lat, start_lng = start_coords
    end_lat, end_lng = end_coords
    
    # ì¤‘ê°„ì  ê³„ì‚°
    mid_lat = (start_lat + end_lat) / 2
    mid_lng = (start_lng + end_lng) / 2
    
    # ë‘ ì§€ì  ê°„ ê±°ë¦¬ë¡œ ê²€ìƒ‰ ë°˜ê²½ ë™ì  ê³„ì‚°
    import math
    distance = math.sqrt((end_lat - start_lat)**2 + (end_lng - start_lng)**2)
    search_radius = min(distance / 3, buffer_radius)  # ì „ì²´ ê±°ë¦¬ì˜ 1/3 ë˜ëŠ” ìµœëŒ€ buffer_radius
    
    return {
        "center": (mid_lat, mid_lng),
        "search_radius": search_radius,
        "total_distance": distance
    }

# 2. ë™ì  ê²€ìƒ‰ ì „ëµ ìƒì„±
def generate_dynamic_search_strategies(start_location: str, end_location: str, place_type: str = "ì‹ì‚¬") -> List[str]:
    """ì¶œë°œì§€ì™€ ë„ì°©ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ê²€ìƒ‰ ì „ëµ ìƒì„±"""
    
    # ì§€ì—­ëª… ì¶”ì¶œ
    def extract_location_info(location: str) -> Dict:
        """ìœ„ì¹˜ì—ì„œ ì‹œ/êµ¬/ë™ ì •ë³´ ì¶”ì¶œ"""
        import re
        
        # ì‹œ/êµ¬ íŒ¨í„´
        city_pattern = r'(ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°)\s*(íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ)?'
        district_pattern = r'(\w+êµ¬|\w+ì‹œ|\w+êµ°)'
        dong_pattern = r'(\w+ë™|\w+ì|\w+ë©´)'
        
        city = re.search(city_pattern, location)
        district = re.search(district_pattern, location)
        dong = re.search(dong_pattern, location)
        
        return {
            "city": city.group(1) if city else "ì„œìš¸",
            "district": district.group(1) if district else "",
            "dong": dong.group(1) if dong else "",
            "full_location": location
        }
    
    start_info = extract_location_info(start_location) if start_location else {}
    end_info = extract_location_info(end_location) if end_location else {}
    
    search_strategies = []
    
    # 1) ì¶œë°œì§€ ê·¼ì²˜ ê²€ìƒ‰
    if start_info.get("district"):
        search_strategies.append(f"{start_info['city']} {start_info['district']} {place_type}")
        if start_info.get("dong"):
            search_strategies.append(f"{start_info['city']} {start_info['district']} {start_info['dong']} {place_type}")
    
    # 2) ëª©ì ì§€ ê·¼ì²˜ ê²€ìƒ‰
    if end_info.get("district") and end_info.get("district") != start_info.get("district"):
        search_strategies.append(f"{end_info['city']} {end_info['district']} {place_type}")
        if end_info.get("dong"):
            search_strategies.append(f"{end_info['city']} {end_info['district']} {end_info['dong']} {place_type}")
    
    # 3) ì¤‘ê°„ ì§€ì—­ ê²€ìƒ‰ (GPT í™œìš©)
    middle_search = f"{start_location}ì—ì„œ {end_location} ì¤‘ê°„ {place_type}"
    search_strategies.append(middle_search)
    
    # 4) ì¼ë°˜ ê²€ìƒ‰ (í´ë°±)
    city = start_info.get("city", "ì„œìš¸")
    search_strategies.append(f"{city} {place_type}")
    
    logger.info(f"ğŸ¯ ë™ì  ê²€ìƒ‰ ì „ëµ ìƒì„±: {len(search_strategies)}ê°œ")
    for i, strategy in enumerate(search_strategies):
        logger.info(f"   {i+1}. {strategy}")
    
    return search_strategies

# 3. ê²½ë¡œ íš¨ìœ¨ì„± ìë™ ê²€ì¦
def calculate_route_efficiency(start_coords: tuple, middle_coords: tuple, end_coords: tuple) -> Dict:
    """ê²½ë¡œ íš¨ìœ¨ì„± ìë™ ê³„ì‚°"""
    import math
    
    def distance(p1, p2):
        return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
    
    # ì§ì„  ê±°ë¦¬ vs ì‹¤ì œ ê²½ë¡œ ê±°ë¦¬
    direct_distance = distance(start_coords, end_coords)
    route_distance = distance(start_coords, middle_coords) + distance(middle_coords, end_coords)
    
    # íš¨ìœ¨ì„± ê³„ì‚° (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ íš¨ìœ¨ì )
    efficiency = direct_distance / route_distance if route_distance > 0 else 0
    detour_ratio = (route_distance - direct_distance) / direct_distance if direct_distance > 0 else 0
    
    # íš¨ìœ¨ì„± ë“±ê¸‰
    if efficiency >= 0.8:
        grade = "A"  # ë§¤ìš° íš¨ìœ¨ì 
    elif efficiency >= 0.6:
        grade = "B"  # íš¨ìœ¨ì 
    elif efficiency >= 0.4:
        grade = "C"  # ë³´í†µ
    else:
        grade = "D"  # ë¹„íš¨ìœ¨ì 
    
    return {
        "efficiency": efficiency,
        "detour_ratio": detour_ratio,
        "grade": grade,
        "direct_distance": direct_distance,
        "route_distance": route_distance,
        "is_efficient": efficiency >= 0.6  # Bë“±ê¸‰ ì´ìƒ
    }

# 4. ì§€ëŠ¥í˜• ìœ„ì¹˜ ê²€ìƒ‰ (GPT + ë™ì  ì „ëµ)
async def smart_location_search(schedule: Dict, start_location: str = None, end_location: str = None) -> Dict:
    """ê¸°ì¡´ smart_location_search í•¨ìˆ˜ - API í˜¸ì¶œ ë°©ì‹ ìˆ˜ì •"""
    place_name = schedule.get("name", "")
    if not place_name:
        return schedule
    
    logger.info(f"ğŸ§  ìŠ¤ë§ˆíŠ¸ ìœ„ì¹˜ ê²€ìƒ‰: {place_name}")
    logger.info(f"   ì¶œë°œì§€: {start_location}")
    logger.info(f"   ë„ì°©ì§€: {end_location}")
    
    try:
        # GPTë¡œ ê²€ìƒ‰ì–´ ìƒì„±
        search_queries = await generate_search_queries_with_gpt(start_location, end_location, place_name)
        
        best_results = []
        
        for query in search_queries:
            try:
                logger.info(f"ğŸ” ê²€ìƒ‰ì–´: '{query}'")
                
                # GPTë¡œ ì§€ì—­ ë¶„ì„
                analysis = await TripleLocationSearchService.analyze_location_with_gpt(
                    query,
                    reference_location=start_location,
                    route_context=f"{start_location}ì—ì„œ {end_location}ê¹Œì§€ì˜ ê²½ë¡œ" if start_location and end_location else None
                )
                
                # ì°¸ì¡° ì¼ì • ì •ë³´ êµ¬ì„±
                reference_schedules = []
                if start_location:
                    reference_schedules.append({"location": start_location})
                
                # ğŸ”¥ ì˜¬ë°”ë¥¸ API í˜¸ì¶œ ë°©ì‹
                search_results = []
                
                # Kakao ê²€ìƒ‰ (2ê°œ ì¸ì)
                try:
                    kakao_result = await TripleLocationSearchService.search_kakao(analysis, reference_schedules)
                    if kakao_result and kakao_result.address:
                        search_results.append(("Kakao", kakao_result))
                        logger.info(f"âœ… Kakao ê²°ê³¼: {kakao_result.name}")
                except Exception as e:
                    logger.error(f"âŒ Kakao ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # Google ê²€ìƒ‰ (1ê°œ ì¸ì)
                try:
                    google_result = await TripleLocationSearchService.search_google(analysis)
                    if google_result and google_result.address:
                        search_results.append(("Google", google_result))
                        logger.info(f"âœ… Google ê²°ê³¼: {google_result.name}")
                except Exception as e:
                    logger.error(f"âŒ Google ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # Foursquare ê²€ìƒ‰ (1ê°œ ì¸ì)
                try:
                    foursquare_result = await TripleLocationSearchService.search_foursquare(analysis)
                    if foursquare_result and foursquare_result.address:
                        search_results.append(("Foursquare", foursquare_result))
                        logger.info(f"âœ… Foursquare ê²°ê³¼: {foursquare_result.name}")
                except Exception as e:
                    logger.error(f"âŒ Foursquare ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # ê²°ê³¼ ì²˜ë¦¬ ë° ì ìˆ˜ ê³„ì‚°
                for api_name, result in search_results:
                    if result and result.address:
                        score = calculate_simple_score(result, query)
                        best_results.append({
                            "result": result,
                            "query": query,
                            "api": api_name,
                            "score": score
                        })
                        logger.info(f"   ì ìˆ˜: {score}")
                
            except Exception as e:
                logger.error(f"âŒ ê²€ìƒ‰ì–´ '{query}' ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        # ìµœì  ê²°ê³¼ ì„ íƒ
        if best_results:
            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            best_results.sort(key=lambda x: x["score"], reverse=True)
            best = best_results[0]
            
            result = best["result"]
            schedule["location"] = clean_address(result.address)
            schedule["latitude"] = result.latitude
            schedule["longitude"] = result.longitude
            
            logger.info(f"ğŸ¯ ìµœì  ê²°ê³¼: {result.name}")
            logger.info(f"   ğŸ“ ì£¼ì†Œ: {schedule['location']}")
            logger.info(f"   ğŸ”Œ API: {best['api']}")
            logger.info(f"   ğŸ“Š ì ìˆ˜: {best['score']}")
            
            return schedule
        
        logger.warning(f"âš ï¸ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {place_name}")
        
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {place_name}, {e}")
    
    return schedule

def calculate_simple_score(result, query: str) -> float:
    """ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚°"""
    score = 0.0
    
    # í‰ì  ì ìˆ˜
    if hasattr(result, 'rating') and result.rating:
        score += result.rating * 2  # ìµœëŒ€ 10ì 
    else:
        score += 5  # ê¸°ë³¸ 5ì 
    
    # ì´ë¦„ ê´€ë ¨ì„± ì ìˆ˜
    query_words = query.lower().split()
    name_words = result.name.lower().split() if hasattr(result, 'name') else []
    
    common_words = set(query_words) & set(name_words)
    score += len(common_words) * 2  # ê³µí†µ ë‹¨ì–´ë‹¹ 2ì 
    
    # ì£¼ì†Œ ì™„ì „ì„± ì ìˆ˜
    if hasattr(result, 'address') and result.address:
        if len(result.address) > 10:
            score += 3
        if "êµ¬" in result.address:
            score += 2
        if "ë¡œ" in result.address or "ê¸¸" in result.address:
            score += 1
    
    return score

# 2. GPT ê¸°ë°˜ ê²€ìƒ‰ì–´ ìƒì„± í•¨ìˆ˜
async def generate_search_queries_with_gpt(start_location: str, end_location: str, place_type: str) -> List[str]:
    """GPTë¡œ ê²€ìƒ‰ì–´ ë™ì  ìƒì„± - í•˜ë“œì½”ë”© ì—†ìŒ"""
    
    try:
        prompt = f"""
ì‚¬ìš©ìê°€ "{place_type}"ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.

ì¶œë°œì§€: {start_location}
ë„ì°©ì§€: {end_location}

ìœ„ ë‘ ì§€ì  ì‚¬ì´ì—ì„œ "{place_type}"ë¥¼ ì°¾ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ê²€ìƒ‰ì–´ 5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì‹¤ì œ ì§€ë„ ê²€ìƒ‰ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì¡°ê±´:
1. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì§€ì—­ëª… + ì¹´í…Œê³ ë¦¬ í˜•íƒœ
2. ì§€ë¦¬ì ìœ¼ë¡œ í•©ë¦¬ì ì¸ ìœ„ì¹˜ë“¤
3. ë‹¤ì–‘í•œ ì˜µì…˜ ì œê³µ

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
  "search_queries": [
    "ê²€ìƒ‰ì–´1",
    "ê²€ìƒ‰ì–´2", 
    "ê²€ìƒ‰ì–´3",
    "ê²€ìƒ‰ì–´4",
    "ê²€ìƒ‰ì–´5"
  ],
  "reasoning": "ê²€ìƒ‰ì–´ ì„ íƒ ì´ìœ "
}}
"""
        
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ í•œêµ­ ì§€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ìš©ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥í•œ ì§€ì—­ëª…ì„ ì œê³µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=400
        )
        
        content = response.choices[0].message.content.strip()
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        
        data = json.loads(content)
        queries = data.get("search_queries", [])
        reasoning = data.get("reasoning", "")
        
        logger.info(f"ğŸ¯ GPT ìƒì„± ê²€ìƒ‰ì–´ {len(queries)}ê°œ:")
        for i, query in enumerate(queries):
            logger.info(f"   {i+1}. {query}")
        logger.info(f"ğŸ“ ì„ íƒ ì´ìœ : {reasoning}")
        
        return queries
        
    except Exception as e:
        logger.error(f"âŒ GPT ê²€ìƒ‰ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê°„ë‹¨í•œ ê¸°ë³¸ ê²€ìƒ‰ì–´
        if "ì‹ì‚¬" in place_type or "ë°¥" in place_type:
            return ["ë§›ì§‘", "ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "í•œì‹", "ë¶„ì‹"]
        elif "ì¹´í˜" in place_type:
            return ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì°¨"]
        else:
            return ["ë§›ì§‘", "ì‹ë‹¹", "ì¹´í˜", "ë ˆìŠ¤í† ë‘", "ìŒì‹ì "]

# 3. ê¸°ì¡´ create_simple_multiple_options ëŒ€ì‹  GPT ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •
async def create_multiple_options(enhanced_data: Dict, voice_input: str) -> Dict:
    """DynamicRouteOptimizerë¥¼ ì‚¬ìš©í•œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±"""
    print("ğŸ”¥ğŸ”¥ğŸ”¥ create_multiple_options í•¨ìˆ˜ í˜¸ì¶œë¨!")
    logger.info("ğŸ”¥ğŸ”¥ğŸ”¥ create_multiple_options í•¨ìˆ˜ í˜¸ì¶œë¨!")
    
    print(f"ğŸ”¥ voice_input: {voice_input}")
    print(f"ğŸ”¥ KAKAO_REST_API_KEY ì¡´ì¬: {bool(KAKAO_REST_API_KEY)}")
    
    optimizer = DynamicRouteOptimizer(KAKAO_REST_API_KEY)
    print("ğŸ”¥ DynamicRouteOptimizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ë¨")    
    optimizer = DynamicRouteOptimizer(KAKAO_REST_API_KEY)
    
    try:
        result = await optimizer.create_multiple_options(enhanced_data, voice_input)
        return result
    except Exception as e:
        logger.error(f"âŒ ë™ì  ì˜µì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ë‹¨ì¼ ì˜µì…˜
        return {"options": [enhanced_data]}

# 4. GPT ê¸°ë°˜ ì˜µì…˜ ì „ëµ ìƒì„± (í•˜ë“œì½”ë”© ì™„ì „ ì œê±°)
async def generate_option_strategies_dynamic(start_location: str, end_location: str, voice_input: str) -> List[str]:
    """GPTë¡œ ì˜µì…˜ë³„ ë‹¤ë¥¸ ì „ëµ ë™ì  ìƒì„±"""
    
    try:
        prompt = f"""
ì‚¬ìš©ì ìš”ì²­: "{voice_input}"
ì¶œë°œì§€: {start_location}  
ë„ì°©ì§€: {end_location}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ì‚¬ ì¥ì†Œì— ëŒ€í•œ 5ê°€ì§€ ë‹¤ë¥¸ ì˜µì…˜ ì „ëµì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ê° ì˜µì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ ì§€ì—­ì´ë‚˜ ì»¨ì…‰ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ì¡°ê±´:
1. ì§€ë¦¬ì ìœ¼ë¡œ í•©ë¦¬ì ì¸ ìœ„ì¹˜
2. ì„œë¡œ ë‹¤ë¥¸ íŠ¹ìƒ‰ì´ ìˆëŠ” ì˜µì…˜ë“¤
3. ì‹¤ì œ ê²€ìƒ‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
  "strategies": [
    "ì „ëµ1 ê²€ìƒ‰ì–´",
    "ì „ëµ2 ê²€ìƒ‰ì–´", 
    "ì „ëµ3 ê²€ìƒ‰ì–´",
    "ì „ëµ4 ê²€ìƒ‰ì–´",
    "ì „ëµ5 ê²€ìƒ‰ì–´"
  ]
}}
"""
        
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ ë§›ì§‘ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì–‘í•˜ê³  ì‹¤ìš©ì ì¸ ì‹ì‚¬ ì˜µì…˜ì„ ì œê³µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,  # ì•½ê°„ì˜ ì°½ì˜ì„±
            max_tokens=300
        )
        
        content = response.choices[0].message.content.strip()
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        
        data = json.loads(content)
        strategies = data.get("strategies", [])
        
        logger.info(f"ğŸ¨ GPT ìƒì„± ì „ëµ {len(strategies)}ê°œ:")
        for i, strategy in enumerate(strategies):
            logger.info(f"   {i+1}. {strategy}")
        
        return strategies
        
    except Exception as e:
        logger.error(f"âŒ GPT ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ ê²€ìƒ‰ì–´ë“¤
        return ["ë§›ì§‘", "ê³ ê¸‰ ë ˆìŠ¤í† ë‘", "ê°€ì„±ë¹„ ì‹ë‹¹", "ì¹´í˜", "ë¶„ì‹"]



async def get_coordinates_from_address(address: str) -> tuple:
    """ì£¼ì†Œì—ì„œ ì¢Œí‘œ ì¶”ì¶œ (ê°„ë‹¨í•œ ì§€ì˜¤ì½”ë”©)"""
    try:
        # ê¸°ì¡´ ì¹´ì¹´ì˜¤ ì§€ì˜¤ì½”ë”© í™œìš©
        if not KAKAO_REST_API_KEY:
            return None
        
        url = "https://dapi.kakao.com/v2/local/search/address.json"
        headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
        params = {"query": address}
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers, params=params, timeout=5) as response:
                if response.status == 200:
                    data = await response.json()
                    documents = data.get("documents", [])
                    if documents:
                        result = documents[0]
                        return (float(result.get("y", 0)), float(result.get("x", 0)))
        
        return None
        
    except Exception as e:
        logger.error(f"ì£¼ì†Œ ì¢Œí‘œ ë³€í™˜ ì˜¤ë¥˜: {e}")
        return None
def clean_address(address: str) -> str:
            """ì£¼ì†Œ ì •ì œ í•¨ìˆ˜"""
            if not address:
                return ""
            
            import re
            
            # 1. ì¤‘ë³µëœ ì§€ì—­ëª… ì œê±°
            address = re.sub(r'ë¶€ì‚°ê´‘ì—­ì‹œ,?\s*ë¶€ì‚°ê´‘ì—­ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', address)
            address = re.sub(r'ì„œìš¸íŠ¹ë³„ì‹œ,?\s*ì„œìš¸íŠ¹ë³„ì‹œ', 'ì„œìš¸íŠ¹ë³„ì‹œ', address)
            address = re.sub(r'ëŒ€êµ¬ê´‘ì—­ì‹œ,?\s*ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', address)
            
            # 2. ìš°í¸ë²ˆí˜¸ ì œê±° (5ìë¦¬ ìˆ«ì, 3-3 í˜•íƒœ)
            address = re.sub(r',?\s*\d{3}-\d{3}', '', address)
            address = re.sub(r',?\s*\d{5}', '', address)
            
            # 3. ë¶ˆí•„ìš”í•œ ì‰¼í‘œì™€ ê³µë°± ì •ë¦¬
            address = re.sub(r',+', ',', address)  # ì—°ì† ì‰¼í‘œ ì œê±°
            address = re.sub(r',\s*$', '', address)  # ëë¶€ë¶„ ì‰¼í‘œ ì œê±°
            address = re.sub(r'^\s*,', '', address)  # ì‹œì‘ë¶€ë¶„ ì‰¼í‘œ ì œê±°
            address = re.sub(r'\s+', ' ', address)  # ì—°ì† ê³µë°± ì œê±°
            
            # 4. ì•ë’¤ ê³µë°± ì œê±°
            address = address.strip()
            
            return address
# 5. ì§€ëŠ¥í˜• ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±
async def create_smart_multiple_options(enhanced_data: Dict, voice_input: str) -> Dict:
    """ì§€ëŠ¥í˜• ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± - í•˜ë“œì½”ë”© ì—†ì´"""
    
    def force_log(msg):
        print(f"ğŸ§  {msg}")
        logger.info(msg)
    
    force_log("ì§€ëŠ¥í˜• ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œì‘")
    
    try:
        # ê²½ë¡œ ì •ë³´ ìë™ ì¶”ì¶œ
        fixed_schedules = enhanced_data.get("fixedSchedules", [])
        start_schedule = fixed_schedules[0] if len(fixed_schedules) > 0 else None
        end_schedule = fixed_schedules[-1] if len(fixed_schedules) > 1 else None
        
        start_location = start_schedule.get("location") if start_schedule else None
        end_location = end_schedule.get("location") if end_schedule else None
        
        force_log(f"ìë™ ì¶”ì¶œëœ ê²½ë¡œ: {start_location} â†’ {end_location}")
        
        # ğŸ”¥ ë‹¤ì–‘í•œ ì˜µì…˜ ìƒì„± ì „ëµ (ë™ì )
        option_strategies = [
            {"focus": "start_area", "description": "ì¶œë°œì§€ ê·¼ì²˜ ì¤‘ì‹¬"},
            {"focus": "end_area", "description": "ëª©ì ì§€ ê·¼ì²˜ ì¤‘ì‹¬"},
            {"focus": "midway", "description": "ì¤‘ê°„ ì§€ì  ì¤‘ì‹¬"},
            {"focus": "efficient", "description": "ìµœë‹¨ ê²½ë¡œ ì¤‘ì‹¬"},
            {"focus": "diverse", "description": "ë‹¤ì–‘í•œ ì§€ì—­ íƒìƒ‰"}
        ]
        
        options = []
        used_locations = set()  # ì¤‘ë³µ ë°©ì§€
        
        for option_num, strategy in enumerate(option_strategies):
            force_log(f"ì˜µì…˜ {option_num + 1} ìƒì„±: {strategy['description']}")
            
            option_data = copy.deepcopy(enhanced_data)
            
            # ì‹ì‚¬ ì¼ì • ì°¾ê¸° ë° ì¬ê²€ìƒ‰
            for schedule in option_data.get("fixedSchedules", []):
                if "ì‹ì‚¬" in schedule.get("name", ""):
                    force_log(f"   ì‹ì‚¬ ì¼ì • ì¬ê²€ìƒ‰: {strategy['focus']} ì „ëµ")
                    
                    # ğŸ”¥ ì „ëµë³„ ë™ì  ê²€ìƒ‰
                    if strategy["focus"] == "start_area":
                        # ì¶œë°œì§€ ê·¼ì²˜ ìš°ì„ 
                        search_context = f"{start_location} ê·¼ì²˜"
                    elif strategy["focus"] == "end_area":
                        # ëª©ì ì§€ ê·¼ì²˜ ìš°ì„ 
                        search_context = f"{end_location} ê·¼ì²˜"
                    elif strategy["focus"] == "midway":
                        # ì¤‘ê°„ ì§€ì  ìš°ì„ 
                        search_context = f"{start_location}ì—ì„œ {end_location} ì¤‘ê°„"
                    elif strategy["focus"] == "efficient":
                        # ìµœë‹¨ ê²½ë¡œ ìš°ì„ 
                        search_context = f"{start_location}ì—ì„œ {end_location} ìµœë‹¨ê²½ë¡œ"
                    else:  # diverse
                        # ë‹¤ì–‘í•œ ì§€ì—­ íƒìƒ‰
                        search_context = f"{voice_input} ë‹¤ì–‘í•œ ì˜µì…˜"
                    
                    # ì§€ëŠ¥í˜• ê²€ìƒ‰ ìˆ˜í–‰
                    original_name = schedule.get("name", "")
                    temp_schedule = copy.deepcopy(schedule)
                    temp_schedule["name"] = search_context
                    
                    enhanced_schedule = await smart_location_search(
                        temp_schedule, 
                        start_location, 
                        end_location
                    )
                    
                    # ê²°ê³¼ ì ìš© (ì¤‘ë³µ ì²´í¬)
                    new_location = enhanced_schedule.get("location", "")
                    if new_location and new_location not in used_locations:
                        schedule["location"] = new_location
                        schedule["latitude"] = enhanced_schedule.get("latitude", schedule.get("latitude"))
                        schedule["longitude"] = enhanced_schedule.get("longitude", schedule.get("longitude"))
                        schedule["name"] = f"ì˜µì…˜{option_num + 1} ì‹ì‚¬"  # ì˜µì…˜ë³„ êµ¬ë¶„
                        
                        used_locations.add(new_location)
                        force_log(f"   âœ… ìƒˆë¡œìš´ ìœ„ì¹˜: {new_location}")
                    else:
                        force_log(f"   âš ï¸ ì¤‘ë³µ ë˜ëŠ” ì‹¤íŒ¨, ì›ë³¸ ìœ ì§€")
            
            # ê³ ìœ  ID ë¶€ì—¬
            for schedule_type in ["fixedSchedules", "flexibleSchedules"]:
                for j, schedule in enumerate(option_data.get(schedule_type, [])):
                    schedule["id"] = f"{int(time.time() * 1000)}_{option_num + 1}_{j + 1}"
            
            option = {
                "optionId": option_num + 1,
                "fixedSchedules": option_data.get("fixedSchedules", []),
                "flexibleSchedules": option_data.get("flexibleSchedules", [])
            }
            
            options.append(option)
            force_log(f"âœ… ì˜µì…˜ {option_num + 1} ì™„ì„±")
        
        final_result = {"options": options}
        force_log(f"ğŸ‰ ì§€ëŠ¥í˜• ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ: {len(options)}ê°œ")
        
        # ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
        for i, option in enumerate(options):
            for schedule in option.get("fixedSchedules", []):
                if "ì‹ì‚¬" in schedule.get("name", ""):
                    location = schedule.get("location", "")
                    force_log(f"   ì˜µì…˜ {i+1} ê²€ì¦: {location}")
        
        return final_result
        
    except Exception as e:
        force_log(f"âŒ ì§€ëŠ¥í˜• ì˜µì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"options": []}

def should_use_dynamic_system(enhanced_data: Dict, voice_input: str) -> bool:
    """ì‚¬ìš©í•  ì‹œìŠ¤í…œ ìë™ ê²°ì •"""
    
    fixed_schedules = enhanced_data.get("fixedSchedules", [])
    
    # 1. ë¸Œëœë“œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë™ì  ì‹œìŠ¤í…œ
    brand_keywords = [
    # â˜• ì»¤í”¼ ì „ë¬¸ì 
    "ìŠ¤íƒ€ë²…ìŠ¤", "starbucks",
    "ì»¤í”¼ë¹ˆ", "coffee bean", "coffeebean",
    "í• ë¦¬ìŠ¤", "hollys", "í• ë¦¬ìŠ¤ì»¤í”¼",
    "íˆ¬ì¸í”Œë ˆì´ìŠ¤", "twosome", "íˆ¬ì¸",
    "ì´ë””ì•¼", "ediya", "ì´ë””ì•¼ì»¤í”¼",
    "í´ë°”ì…‹", "paul bassett",
    "íƒì•¤íƒìŠ¤", "tom n toms", "íƒíƒ",
    "ì—”ì ¤ë¦¬ë„ˆìŠ¤", "angelinus",
    "ë©”ê°€ì»¤í”¼", "mega coffee", "ë©”ê°€mgcì»¤í”¼",
    "ì»´í¬ì¦ˆì»¤í”¼", "compose coffee", "ì»´í¬ì¦ˆ",
    "ë¹½ë‹¤ë°©", "paik's coffee", "ë¹½", "ë¹½ì»¤í”¼",
    "ì¹´í˜ë² ë„¤", "cafe bene",
    "ë“œë¡­íƒ‘", "droptop",
    "ë”ë²¤í‹°", "the venti",
    "ë¸”ë£¨ë³´í‹€", "blue bottle",
    "ìŠ¤íƒ€ë²…ìŠ¤ë¦¬ì €ë¸Œ", "reserve",
    
    # ğŸª í¸ì˜ì 
    "í¸ì˜ì ",
    "ì„¸ë¸ì¼ë ˆë¸", "7eleven", "711", "ì„¸ë¸",
    "cu", "ì”¨ìœ ",
    "gs25", "ì§€ì—ìŠ¤25", "gs",
    "ì´ë§ˆíŠ¸24", "emart24", "ì´ë§ˆíŠ¸",
    "ë¯¸ë‹ˆìŠ¤í†±", "ministop",
    
    # ğŸ” íŒ¨ìŠ¤íŠ¸í‘¸ë“œ
    "ë§¥ë„ë‚ ë“œ", "mcdonald", "ë§¥ë”œ", "ë§¥ë‚ ",
    "ë²„ê±°í‚¹", "burger king", "ë²„í‚¹",
    "ë¡¯ë°ë¦¬ì•„", "lotteria",
    "kfc", "ì¼€ì´ì—í”„ì”¨", "ì¹˜í‚¨",
    "ì„œë¸Œì›¨ì´", "subway",
    "ë„ë¯¸ë…¸í”¼ì", "domino", "ë„ë¯¸ë…¸",
    "í”¼ìí—›", "pizza hut", "í”¼í—›",
    "ë¯¸ìŠ¤í„°í”¼ì", "mr pizza", "ë¯¸í”¼",
    "íŒŒíŒŒì¡´ìŠ¤", "papa johns",
    "ë§˜ìŠ¤í„°ì¹˜", "mom's touch",
    "í¬ë¼ì œë²„ê±°", "kraze burger",
    "ì‰ì´í¬ì‰‘", "shake shack",
    "íŒŒì´ë¸Œê°€ì´ì¦ˆ", "five guys",
    
    # ğŸ— ì¹˜í‚¨
    "bbq", "ë¹„ë¹„í",
    "êµ½ë„¤ì¹˜í‚¨", "êµ½ë„¤",
    "ë„¤ë„¤ì¹˜í‚¨", "ë„¤ë„¤",
    "êµì´Œì¹˜í‚¨", "êµì´Œ",
    "bhc", "ë¹„ì—ì´ì¹˜ì”¨",
    "ì²˜ê°“ì§‘", "ì²˜ê°“ì§‘ì–‘ë…ì¹˜í‚¨",
    "ì˜ë‹­", "ì˜ë‹­ì¹˜í‚¨",
    "í˜¸ì‹ì´ë‘ë§ˆë¦¬ì¹˜í‚¨", "í˜¸ì‹ì´",
    "ë§¥ì‹œì¹¸ì¹˜í‚¨", "ë§¥ì‹œì¹¸",
    "í˜ë¦¬ì¹´ë‚˜", "pelicana",
    "í‘¸ë¼ë‹­", "puradak",
    "ì§€ì½”ë°”", "zikoba",
    
    # ğŸ• í”¼ì (ì¶”ê°€)
    "í”¼ììŠ¤ì¿¨", "pizza school",
    "í”¼ìë§ˆë£¨", "pizza maru",
    "ë°˜ì˜¬ë¦¼í”¼ì", "round table pizza",
    "ì²­ë…„í”¼ì", "young pizza",
    
    # ğŸ° ë² ì´ì»¤ë¦¬/ë””ì €íŠ¸
    "íŒŒë¦¬ë°”ê²Œëœ¨", "paris baguette", "íŒŒë°”",
    "ëšœë ˆì¥¬ë¥´", "tous les jours", "ëšœë ˆ",
    "ë˜í‚¨ë„ë„›", "dunkin donuts", "ë˜í‚¨",
    "í¬ë¦¬ìŠ¤í”¼í¬ë¦¼", "krispy kreme",
    "ë² ìŠ¤í‚¨ë¼ë¹ˆìŠ¤", "baskin robbins", "ë°°ë¼",
    "ë¸Œë¼ìš´", "brown",
    "í•˜ê²ë‹¤ì¦ˆ", "haagen dazs",
    "ë‚˜ëšœë£¨", "natuur",
    "ì„¤ë¹™", "sulbing",
    "ë¹™ê·¸ë ˆ", "binggrae",
    
    # ğŸœ íŒ¨ë°€ë¦¬ ë ˆìŠ¤í† ë‘
    "ì•„ì›ƒë°±", "outback",
    "í‹°ì§€ì•„ì´í”„ë¼ì´ë°ì´", "tgi friday",
    "ë² ë‹ˆê±´ìŠ¤", "bennigans",
    "ì• ìŠë¦¬", "ashley",
    "ë¹•ìŠ¤", "vips",
    "ì˜¨ë”ë³´ë”", "on the border",
    "ë§ˆë¥´ì‰", "marche",
    "í† ë‹ˆë¡œë§ˆìŠ¤", "tony roma",
    
    # ğŸ¥˜ í•œì‹ í”„ëœì°¨ì´ì¦ˆ
    "ê¹€ë°¥ì²œêµ­",
    "ë°±ë°˜ì§‘",
    "í•œì†¥ë„ì‹œë½", "í•œì†¥",
    "ë³¸ì£½", "ë³¸ì£½&ë¹„ë¹”ë°¥",
    "ë†€ë¶€ë¶€ëŒ€ì°Œê°œ", "ë†€ë¶€",
    "ì²­ë…„ë‹¤ë°©",
    "ë§˜í„°ì¹˜", "mom touch",
    "ì›í• ë¨¸ë‹ˆë³´ìŒˆ", "ì›í• ë¨¸ë‹ˆ",
    "ë‘ë¼ë–¡ë³¶ì´", "ë‘ë¼",
    "ì£ ìŠ¤ë–¡ë³¶ì´", "ì£ ìŠ¤",
    "ì—½ê¸°ë–¡ë³¶ì´", "ì—½ë–¡",
    
    # ğŸœ ì¼ì‹
    "ìš”ì‹œë…¸ì•¼", "yoshinoya",
    "ìŠ¤í‚¤ì•¼", "sukiya",
    "ë§ˆë£¨ê°€ë©”ì œë©´", "marugame",
    "ì½”ì½”ì´ì°Œë°©ì•¼", "coco",
    "í•˜ë‚˜ë¡œì´ˆë°¥", "hanaro",
    "ìŠ¤ì‹œë¡œ", "sushiro",
    "ì˜¨ê¸°ë¼ì¿ ", "ongiraku",
    
    # ğŸ¥Ÿ ì¤‘ì‹
    "í™ì½©ë°˜ì ", "í™ì½©ë°˜ì 0410",
    "ìœ ê°€ë„¤ë‹­ê°ˆë¹„", "ìœ ê°€ë„¤",
    "ì§„ì£¼ëƒ‰ë©´", "ì§„ì£¼í•¨í¥ëƒ‰ë©´",
    
    # ğŸ›’ ëŒ€í˜•ë§ˆíŠ¸/ë§ˆíŠ¸
    "ì´ë§ˆíŠ¸", "emart",
    "í™ˆí”ŒëŸ¬ìŠ¤", "homeplus",
    "ë¡¯ë°ë§ˆíŠ¸", "lotte mart",
    "ì½”ìŠ¤íŠ¸ì½”", "costco",
    "í•˜ë‚˜ë¡œë§ˆíŠ¸", "hanaro mart",
    "ë†í˜‘", "nhë§ˆíŠ¸",
    "ë©”ê°€ë§ˆíŠ¸", "mega mart",
    
    # ğŸ¬ ë°±í™”ì 
    "í˜„ëŒ€ë°±í™”ì ", "í˜„ëŒ€",
    "ë¡¯ë°ë°±í™”ì ", "ë¡¯ë°",
    "ì‹ ì„¸ê³„ë°±í™”ì ", "ì‹ ì„¸ê³„",
    "ê°¤ëŸ¬ë¦¬ì•„", "galleria",
    "ë™í™”ë©´ì„¸ì ", "ë™í™”",
    "ì•„ì›ƒë ›", "outlet",
    "í”„ë¦¬ë¯¸ì—„ì•„ì›ƒë ›",
    
    # ğŸ¥ ìƒí™œì‹œì„¤
    "ì•½êµ­", "pharmacy",
    "ì˜¨ëˆ„ë¦¬ì•½êµ­", "ì˜¨ëˆ„ë¦¬",
    "ì‚¼ì„±ì•½êµ­", "ì‚¼ì„±",
    "24ì‹œê°„ì•½êµ­",
    "ë³‘ì›", "ì˜ì›", "clinic", "hospital",
    "ì€í–‰", "bank",
    "ìš°ë¦¬ì€í–‰", "ìš°ë¦¬",
    "êµ­ë¯¼ì€í–‰", "kb",
    "ì‹ í•œì€í–‰", "ì‹ í•œ",
    "í•˜ë‚˜ì€í–‰", "í•˜ë‚˜",
    "ê¸°ì—…ì€í–‰", "ibk",
    "ë†í˜‘ì€í–‰", "nh",
    "ì¹´ì¹´ì˜¤ë±…í¬", "kakao bank",
    "í† ìŠ¤ë±…í¬", "toss bank",
    
    # â›½ ì£¼ìœ ì†Œ
    "ì£¼ìœ ì†Œ", "gas station",
    "skì—ë„ˆì§€", "sk", "skì£¼ìœ ì†Œ",
    "gsì¹¼í…ìŠ¤", "gs", "gsì£¼ìœ ì†Œ",
    "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "í˜„ëŒ€", "oilbank",
    "s-oil", "ì—ì“°ì˜¤ì¼",
    "ì•Œëœ°ì£¼ìœ ì†Œ",
    
    # ğŸ® ì˜¤ë½ì‹œì„¤
    "ë…¸ë˜ë°©", "karaoke", "ì½”ì¸ë…¸ë˜ë°©",
    "pcë°©", "í”¼ì”¨ë°©", "ê²Œì„ë°©",
    "ì°œì§ˆë°©", "ì‚¬ìš°ë‚˜", "ëª©ìš•íƒ•",
    "ë³¼ë§ì¥", "ë³¼ë§",
    "ë‹¹êµ¬ì¥", "ë‹¹êµ¬", "í¬ì¼“ë³¼",
    "ìŠ¤í¬ë¦°ê³¨í”„", "ê³¨í”„ì—°ìŠµì¥",
    "vr", "vrì²´í—˜ê´€",
    "ë°©íƒˆì¶œ", "ë°©íƒˆì¶œì¹´í˜",
    
    # ğŸ‹ï¸ ìš´ë™/í—¬ìŠ¤
    "í—¬ìŠ¤ì¥", "í—¬ìŠ¤", "í”¼íŠ¸ë‹ˆìŠ¤", "gym",
    "ìš”ê°€", "í•„ë¼í…ŒìŠ¤", "yoga",
    "ê³¨í”„", "ê³¨í”„ì¥", "ê³¨í”„ì—°ìŠµì¥",
    "ìˆ˜ì˜ì¥", "swimming pool",
    "íƒœê¶Œë„", "ìœ ë„", "ë³µì‹±",
    "í´ë¼ì´ë°", "ì•”ë²½ë“±ë°˜",
    "ìŠ¤ì¿¼ì‹œ", "ë°°ë“œë¯¼í„´", "í…Œë‹ˆìŠ¤",
    
    # ğŸ’„ ë·°í‹°/ë¯¸ìš©
    "ë¯¸ìš©ì‹¤", "í—¤ì–´ìƒµ", "ë¯¸ìš©ì›", "salon",
    "ë„¤ì¼ìƒµ", "ë„¤ì¼", "nail",
    "ë§ˆì‚¬ì§€", "massage", "ìŠ¤íŒŒ", "spa",
    "í”¼ë¶€ê³¼", "ì„±í˜•ì™¸ê³¼", "í”¼ë¶€ê´€ë¦¬",
    "ì•„ì´ë¸Œë¡œìš°", "ëˆˆì¹",
    "ì™ì‹±", "waxing",
    
    # ğŸš— ìë™ì°¨
    "ì„¸ì°¨ì¥", "ì„¸ì°¨", "car wash",
    "ì •ë¹„ì†Œ", "ìë™ì°¨ì •ë¹„",
    "íƒ€ì´ì–´", "tire",
    "ì¹´ì„¼í„°", "car center",
    "ì£¼ì°¨ì¥", "parking",
    
    # ğŸ¨ ìˆ™ë°•
    "í˜¸í…”", "hotel",
    "ëª¨í…”", "motel",
    "ë¦¬ì¡°íŠ¸", "resort",
    "íœì…˜", "pension",
    "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤", "guesthouse",
    "ì—ì–´ë¹„ì•¤ë¹„", "airbnb",
    "ì°œì§ˆë°©", "ì°œë°©",
    
    # ğŸª ê¸°íƒ€ ì„œë¹„ìŠ¤
    "ì„¸íƒì†Œ", "laundry",
    "íƒë°°", "delivery",
    "í¬í† ìƒµ", "ì‚¬ì§„ê´€",
    "ë¬¸êµ¬ì ", "stationery",
    "ê½ƒì§‘", "flower shop",
    "ë°˜ë ¤ë™ë¬¼", "í«ìƒµ", "pet shop",
    "ë™ë¬¼ë³‘ì›", "vet",
    "í•™ì›", "academy", "êµìœ¡",
    "ë„ì„œê´€", "library",
    "ì˜í™”ê´€", "cgv", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ë©”ê°€ë°•ìŠ¤",
]
    voice_lower = voice_input.lower()
    
    for keyword in brand_keywords:
        if keyword in voice_lower:
            logger.info(f"ğŸ¤– ë¸Œëœë“œ '{keyword}' ê°ì§€ â†’ ë™ì  ì‹œìŠ¤í…œ ì‚¬ìš©")
            return True
    
    # 2. ì¼ì •ì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ë™ì  ì‹œìŠ¤í…œ
    for schedule in fixed_schedules:
        schedule_name = schedule.get("name", "").lower()
        for keyword in brand_keywords:
            if keyword in schedule_name:
                logger.info(f"ğŸ¤– ì¼ì •ì— ë¸Œëœë“œ '{keyword}' ê°ì§€ â†’ ë™ì  ì‹œìŠ¤í…œ ì‚¬ìš©")
                return True
    
    # 3. ì‹ì‚¬ ê´€ë ¨ì€ ê¸°ì¡´ ì‹œìŠ¤í…œ (ë” ì•ˆì •ì )
    meal_keywords = ["ì‹ì‚¬", "ì €ë…", "ì ì‹¬", "ì•„ì¹¨", "ë°¥", "ë§›ì§‘"]
    for keyword in meal_keywords:
        if keyword in voice_lower:
            logger.info(f"ğŸ“‹ ì‹ì‚¬ í‚¤ì›Œë“œ '{keyword}' ê°ì§€ â†’ ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš©")
            return False
            
    for schedule in fixed_schedules:
        schedule_name = schedule.get("name", "").lower()
        for keyword in meal_keywords:
            if keyword in schedule_name:
                logger.info(f"ğŸ“‹ ì¼ì •ì— ì‹ì‚¬ í‚¤ì›Œë“œ '{keyword}' ê°ì§€ â†’ ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš©")
                return False
    
    # 4. ê¸°ë³¸ê°’: ê¸°ì¡´ ì‹œìŠ¤í…œ (ì•ˆì „)
    logger.info("ğŸ“‹ ê¸°ë³¸ ì„¤ì • â†’ ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš©")
    return False

async def create_multiple_options(self, enhanced_data: Dict, voice_input: str) -> Dict:
    """ì™„ì „ ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± - ìœ„ì¹˜ ì¤‘ë³µ ë°©ì§€ ê°•í™”"""
    
    def force_log(msg):
        print(f"ğŸ¯ {msg}")
        logger.info(msg)
    
    force_log("ğŸ†• ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œì‘ (ìœ„ì¹˜ ì¤‘ë³µ ë°©ì§€)")
    force_log(f"ì…ë ¥ ë°ì´í„°: voice_input='{voice_input}'")
    
    # ì…ë ¥ ë°ì´í„° ìƒì„¸ ë¡œê¹…
    fixed_schedules = enhanced_data.get("fixedSchedules", [])
    force_log(f"ê³ ì • ì¼ì • ìˆ˜: {len(fixed_schedules)}ê°œ")
    for i, schedule in enumerate(fixed_schedules):
        force_log(f"  ê³ ì • ì¼ì • {i+1}: '{schedule.get('name', 'N/A')}' (ID: {schedule.get('id', 'N/A')})")
    
    if len(fixed_schedules) < 2:
        force_log("âš ï¸ ê²½ë¡œ ë¶„ì„ì— í•„ìš”í•œ ìµœì†Œ ì¼ì • ë¶€ì¡± (2ê°œ ë¯¸ë§Œ)")
        return {"options": [enhanced_data]}  # ë‹¨ì¼ ì˜µì…˜ ë°˜í™˜
    
    # 1. ê²½ë¡œ ì •ë³´ ìë™ ì¶”ì¶œ
    start_schedule = fixed_schedules[0]
    end_schedule = fixed_schedules[-1]
    
    start_coord = (start_schedule.get("latitude"), start_schedule.get("longitude"))
    end_coord = (end_schedule.get("latitude"), end_schedule.get("longitude"))
    
    force_log(f"ğŸ“ ê²½ë¡œ ë¶„ì„:")
    force_log(f"  ì‹œì‘: {start_schedule.get('name')} ({start_coord})")
    force_log(f"  ì¢…ë£Œ: {end_schedule.get('name')} ({end_coord})")
    
    # 2. ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ìë™ ì‹ë³„ (ë¡œê¹… ê°•í™”)
    variable_schedules = self.identify_variable_schedules(fixed_schedules, voice_input)
    
    force_log(f"ğŸ” ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì • ì‹ë³„ ê²°ê³¼: {len(variable_schedules)}ê°œ")
    for i, var_info in enumerate(variable_schedules):
        force_log(f"  ë³€ê²½ ê°€ëŠ¥ {i+1}: ì¸ë±ìŠ¤={var_info['index']}, ë¸Œëœë“œ='{var_info['brand']}', ì›ë³¸ëª…='{var_info['original_name']}'")
    
    if not variable_schedules:
        force_log("âš ï¸ ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì •ì´ ì—†ìŒ â†’ ë‹¨ì¼ ì˜µì…˜ ë°˜í™˜")
        return {"options": [enhanced_data]}
    
    # ğŸ”¥ ì „ì—­ ìœ„ì¹˜ ì¶”ì 
    used_locations = set()
    
    # 3. ê° ë³€ê²½ ê°€ëŠ¥í•œ ì¼ì •ì— ëŒ€í•´ ë™ì  ì˜µì…˜ ìƒì„±
    options = []
    for option_num in range(5):
        force_log(f"ğŸ”„ ì˜µì…˜ {option_num + 1} ë™ì  ìƒì„± ì‹œì‘")
        
        option_data = copy.deepcopy(enhanced_data)
        option_modified = False
        
        for var_info in variable_schedules:
            schedule_idx = var_info["index"]
            schedule = option_data["fixedSchedules"][schedule_idx]
            brand_name = var_info["brand"]
            
            force_log(f"  ğŸ“ ì¼ì • ìˆ˜ì •: ì¸ë±ìŠ¤={schedule_idx}, ë¸Œëœë“œ='{brand_name}'")
            force_log(f"    í˜„ì¬ ì´ë¦„: '{schedule.get('name')}'")
            force_log(f"    í˜„ì¬ ìœ„ì¹˜: '{schedule.get('location')}'")
            
            # ğŸ”¥ í˜„ì¬ ìœ„ì¹˜ë¥¼ ì‚¬ìš©ëœ ìœ„ì¹˜ì— ì¶”ê°€ (ì²« ë²ˆì§¸ ì˜µì…˜ìš©)
            current_location = schedule.get("location", "")
            if option_num == 0 and current_location:
                used_locations.add(current_location)
                force_log(f"    ğŸ“ ì›ë³¸ ìœ„ì¹˜ ì¶”ê°€: {current_location}")
            
            # 4. ë™ì  ì¤‘ê°„ ì§€ì—­ ê³„ì‚°
            force_log(f"  ğŸ—ºï¸ ì¤‘ê°„ ì§€ì—­ ê³„ì‚° (ì˜µì…˜ {option_num + 1})")
            intermediate_areas = await self.calculate_intermediate_areas(
                start_coord, end_coord, option_num, total_options=5
            )
            force_log(f"    ê³„ì‚°ëœ ì¤‘ê°„ ì§€ì—­: {intermediate_areas}")
            
            # 5. í•´ë‹¹ ì§€ì—­ì—ì„œ ë¸Œëœë“œ ê²€ìƒ‰ (ì‚¬ìš©ëœ ìœ„ì¹˜ ì œì™¸)
            force_log(f"  ğŸ” ë¸Œëœë“œ ê²€ìƒ‰: '{brand_name}' (ì œì™¸: {len(used_locations)}ê°œ ìœ„ì¹˜)")
            best_location = await self.find_optimal_branch(
                brand_name, intermediate_areas, start_coord, end_coord, used_locations
            )
            
            if best_location:
                force_log(f"    âœ… ê²€ìƒ‰ ì„±ê³µ: {best_location.get('name')}")
                force_log(f"      ì£¼ì†Œ: {best_location.get('address')}")
                
                if best_location.get("address") != schedule.get("location"):
                    # ìœ„ì¹˜ ì—…ë°ì´íŠ¸
                    old_location = schedule.get("location")
                    schedule["location"] = best_location["address"]
                    schedule["latitude"] = best_location["latitude"]
                    schedule["longitude"] = best_location["longitude"]
                    schedule["name"] = best_location["name"]
                    
                    option_modified = True
                    force_log(f"    ğŸ”„ ìœ„ì¹˜ ë³€ê²½:")
                    force_log(f"      ì´ì „: {old_location}")
                    force_log(f"      ì´í›„: {best_location['address']}")
                else:
                    force_log(f"    âš ï¸ ë™ì¼í•œ ìœ„ì¹˜ë¼ì„œ ë³€ê²½ ì—†ìŒ")
            else:
                force_log(f"    âŒ ê²€ìƒ‰ ì‹¤íŒ¨: ìƒˆë¡œìš´ ìœ„ì¹˜ ì—†ìŒ")
                # ğŸ”¥ ì›ë³¸ ìœ„ì¹˜ë„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì²« ë²ˆì§¸ ì˜µì…˜ ì œì™¸)
                if option_num > 0:
                    force_log(f"    â­ï¸ ì´ ì˜µì…˜ ê±´ë„ˆë›°ê¸° (ìƒˆë¡œìš´ ìœ„ì¹˜ ì—†ìŒ)")
                    break
        
        # 6. ìˆ˜ì •ëœ ì˜µì…˜ë§Œ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
        if option_modified or option_num == 0:  # ì²« ë²ˆì§¸ëŠ” ì›ë³¸ ìœ ì§€
            # ê³ ìœ  ID ë¶€ì—¬
            for j, schedule in enumerate(option_data["fixedSchedules"]):
                old_id = schedule.get("id")
                new_id = f"{int(time.time() * 1000)}_{option_num + 1}_{j + 1}"
                schedule["id"] = new_id
                force_log(f"    ğŸ†” ID ì—…ë°ì´íŠ¸: {old_id} â†’ {new_id}")
            
            options.append({
                "optionId": option_num + 1,
                "fixedSchedules": option_data["fixedSchedules"],
                "flexibleSchedules": option_data.get("flexibleSchedules", [])
            })
            
            force_log(f"  âœ… ì˜µì…˜ {option_num + 1} ìƒì„± ì™„ë£Œ (ìˆ˜ì •ë¨: {option_modified})")
        else:
            force_log(f"  âŒ ì˜µì…˜ {option_num + 1} ê±´ë„ˆë›°ê¸° (ì¤‘ë³µ ìœ„ì¹˜)")
    
    # 7. ì¤‘ë³µ ì œê±°
    unique_options = self.remove_duplicate_options(options)
    force_log(f"ğŸ”„ ì¤‘ë³µ ì œê±° ê²°ê³¼: {len(options)}ê°œ â†’ {len(unique_options)}ê°œ")
    
    # 8. ìµœì¢… ê²°ê³¼
    force_log(f"ğŸ‰ ë™ì  ì˜µì…˜ ìƒì„± ì™„ë£Œ: {len(unique_options)}ê°œ")
    force_log(f"ğŸ“Š ìµœì¢… ì‚¬ìš©ëœ ìœ„ì¹˜: {len(used_locations)}ê°œ")
    for i, location in enumerate(used_locations):
        force_log(f"  ìœ„ì¹˜ {i+1}: {location}")
    
    # ìƒì„±ëœ ì˜µì…˜ë“¤ ìƒì„¸ ë¡œê¹…
    for i, option in enumerate(unique_options):
        force_log(f"ğŸ“‹ ìµœì¢… ì˜µì…˜ {i+1}:")
        for j, schedule in enumerate(option.get("fixedSchedules", [])):
            force_log(f"  ì¼ì • {j+1}: '{schedule.get('name')}' @ {schedule.get('location')}")
    
    return {"options": unique_options}


async def find_optimal_branch(self, brand_name: str, intermediate_areas: List[Tuple], 
                            start_coord: Tuple, end_coord: Tuple, used_locations: Set[str] = None) -> Optional[Dict]:
    """ìµœì ì˜ ë¸Œëœë“œ ì§€ì  ì°¾ê¸° - ì‚¬ìš©ëœ ìœ„ì¹˜ ì œì™¸"""
    
    if used_locations is None:
        used_locations = set()
    
    def force_log(msg):
        print(f"ğŸ” {msg}")
        logger.info(msg)
    
    force_log(f"ìµœì  ë¸Œëœë“œ ì§€ì  ê²€ìƒ‰: '{brand_name}'")
    force_log(f"ê²€ìƒ‰ ì§€ì—­: {len(intermediate_areas)}ê°œ")
    force_log(f"ì œì™¸í•  ìœ„ì¹˜: {len(used_locations)}ê°œ - {list(used_locations)}")
    
    best_location = None
    best_efficiency = 0
    
    for i, coord in enumerate(intermediate_areas):
        force_log(f"ì§€ì—­ {i+1} ê²€ìƒ‰: ì¢Œí‘œ ({coord[0]:.4f}, {coord[1]:.4f})")
        
        # í•´ë‹¹ ì¢Œí‘œ ê·¼ì²˜ì—ì„œ ë¸Œëœë“œ ê²€ìƒ‰
        candidates = await self.search_brand_near_coordinate(brand_name, coord)
        force_log(f"  ê²€ìƒ‰ ê²°ê³¼: {len(candidates)}ê°œ í›„ë³´")
        
        for j, candidate in enumerate(candidates):
            location = candidate.get('address', '')
            force_log(f"    í›„ë³´ {j+1}: {candidate.get('name')} @ {location}")
            
            # ğŸ”¥ ì´ë¯¸ ì‚¬ìš©ëœ ìœ„ì¹˜ì¸ì§€ í™•ì¸
            if location in used_locations:
                force_log(f"      âŒ ì´ë¯¸ ì‚¬ìš©ëœ ìœ„ì¹˜ë¼ì„œ ì œì™¸")
                continue
                
            # ê²½ë¡œ íš¨ìœ¨ì„± ê³„ì‚°
            efficiency = self.calculate_route_efficiency(
                start_coord, 
                (candidate["latitude"], candidate["longitude"]), 
                end_coord
            )
            force_log(f"      íš¨ìœ¨ì„±: {efficiency:.3f}")
            
            if efficiency > best_efficiency:
                best_efficiency = efficiency
                best_location = candidate
                force_log(f"      ğŸ”¥ ìƒˆë¡œìš´ ìµœì  í›„ë³´: {candidate.get('name')} (íš¨ìœ¨ì„±: {efficiency:.3f})")
    
    if best_location:
        force_log(f"âœ… ìµœì¢… ì„ íƒ: {best_location['name']} (íš¨ìœ¨ì„±: {best_efficiency:.3f})")
        # ğŸ”¥ ì‚¬ìš©ëœ ìœ„ì¹˜ ì¶”ê°€
        used_locations.add(best_location['address'])
        force_log(f"ğŸ“ ì‚¬ìš©ëœ ìœ„ì¹˜ì— ì¶”ê°€: {best_location['address']}")
    else:
        force_log(f"âŒ ì ì ˆí•œ ì§€ì ì„ ì°¾ì§€ ëª»í•¨ (ëª¨ë‘ ì‚¬ìš©ëœ ìœ„ì¹˜ì´ê±°ë‚˜ ê²€ìƒ‰ ì‹¤íŒ¨)")
    
    return best_location




def get_diversified_search_strategy(option_num: int, region: str, district: str) -> List[str]:
    """ì˜µì…˜ë³„ë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ ì „ëµ ë™ì  ìƒì„±"""
    
    if not district:
        district = region  # êµ¬/ì‹œ/êµ° ì •ë³´ê°€ ì—†ìœ¼ë©´ ì‹œ/ë„ ì •ë³´ ì‚¬ìš©
    
    # ğŸ”¥ ì˜µì…˜ë³„ ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘í™” (ì§€ì—­ ì •ë³´ëŠ” ë™ì )
    category_strategies = {
        0: ["ë§›ì§‘", "ì‹ë‹¹", "ìŒì‹ì "],                    # ì˜µì…˜ 1: ì¼ë°˜ ë§›ì§‘
        1: ["í•œì‹", "ê°ˆë¹„", "ì‚¼ê²¹ì‚´", "êµ­ë°¥"],            # ì˜µì…˜ 2: í•œì‹ ì „ë¬¸
        2: ["ë¶„ì‹", "ê¹€ë°¥", "ë–¡ë³¶ì´", "ìˆœëŒ€"],            # ì˜µì…˜ 3: ë¶„ì‹/ê°„ë‹¨ì‹ì‚¬
        3: ["ì¹˜í‚¨", "í–„ë²„ê±°", "í”¼ì", "íŒ¨ìŠ¤íŠ¸í‘¸ë“œ"],        # ì˜µì…˜ 4: ì¹˜í‚¨/íŒ¨ìŠ¤íŠ¸í‘¸ë“œ
        4: ["ì¹´í˜", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬", "ì»¤í”¼"]          # ì˜µì…˜ 5: ì¹´í˜/ë””ì €íŠ¸
    }
    
    categories = category_strategies.get(option_num, ["ë§›ì§‘", "ì‹ë‹¹"])
    
    # ğŸ”¥ ë™ì ìœ¼ë¡œ ê²€ìƒ‰ì–´ ì¡°í•© ìƒì„±
    search_strategies = []
    
    for category in categories:
        # êµ¬/ì‹œ/êµ° + ì¹´í…Œê³ ë¦¬
        if district:
            search_strategies.append(f"{district} {category}")
        
        # ì‹œ/ë„ + ì¹´í…Œê³ ë¦¬ (ë°±ì—…)
        if region and region != district:
            search_strategies.append(f"{region} {category}")
    
    logger.info(f"ğŸ¯ ì˜µì…˜ {option_num + 1} ê²€ìƒ‰ ì „ëµ: {search_strategies}")
    return search_strategies


def extract_region_info(location: str) -> Dict[str, str]:
    """ìœ„ì¹˜ ë¬¸ìì—´ì—ì„œ ì§€ì—­ ì •ë³´ ë™ì  ì¶”ì¶œ"""
    
    region_info = {
        "region": "",
        "district": "",
        "full_region": ""
    }
    
    if not location:
        return region_info
    
    # KOREA_REGIONS ë°ì´í„° í™œìš©í•´ì„œ ë™ì  ë§¤ì¹­
    for full_region, districts in KOREA_REGIONS.items():
        # ì‹œ/ë„ ë§¤ì¹­
        region_variants = region_normalizer.get_region_variants(full_region)
        
        for variant in region_variants:
            if variant in location:
                region_info["full_region"] = full_region
                region_info["region"] = variant
                
                # í•´ë‹¹ ì‹œ/ë„ì˜ êµ¬/ì‹œ/êµ° ì°¾ê¸°
                for district in districts:
                    if district in location:
                        region_info["district"] = district
                        break
                
                # ì°¾ì•˜ìœ¼ë©´ ë” ì´ìƒ ê²€ìƒ‰í•˜ì§€ ì•ŠìŒ
                if region_info["district"]:
                    return region_info
    
    logger.info(f"ğŸ—ºï¸ ì¶”ì¶œëœ ì§€ì—­ ì •ë³´: {region_info}")
    return region_info
async def create_traditional_options(enhanced_data: Dict, voice_input: str, exclude_locations: Set[str] = None) -> Dict:
    """ì™„ì „ ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± - í•˜ë“œì½”ë”© ì œê±°"""
    
    if exclude_locations is None:
        exclude_locations = set()
    
    try:
        options = []
        fixed_schedules = enhanced_data.get("fixedSchedules", [])
        start_location = fixed_schedules[0].get("location", "") if fixed_schedules else ""
        
        # ğŸ”¥ ë™ì  ì§€ì—­ ì •ë³´ ì¶”ì¶œ
        region_info = extract_region_info(start_location)
        logger.info(f"ğŸ—ºï¸ ì¶”ì¶œëœ ì§€ì—­ ì •ë³´: {region_info}")
        
        # ğŸ”¥ ì „ì—­ ì¤‘ë³µ ë°©ì§€
        global_used_restaurants = set()
        global_used_locations = set()
        
        for option_num in range(5):
            logger.info(f"ğŸ”„ ì˜µì…˜ {option_num + 1} ìƒì„± (ë™ì  ì „ëµ)")
            
            option_data = copy.deepcopy(enhanced_data)
            option_modified = False
            
            for schedule_idx, schedule in enumerate(option_data.get("fixedSchedules", [])):
                schedule_name = schedule.get("name", "").lower()
                
                if any(word in schedule_name for word in ["ì‹ì‚¬", "ì‹ë‹¹", "ë°¥", "ë§›ì§‘", "ë¨¹ê¸°", "í–„ë²„ê±°"]):
                    
                    # ğŸ”¥ ì™„ì „ ë™ì  ê²€ìƒ‰ ì „ëµ ìƒì„±
                    search_strategies = get_diversified_search_strategy(
                        option_num, 
                        region_info["region"], 
                        region_info["district"]
                    )
                    
                    restaurant_result = None
                    
                    for strategy in search_strategies:
                        logger.info(f"   ğŸ” ì˜µì…˜ {option_num + 1} ê²€ìƒ‰: {strategy}")
                        
                        try:
                            # GPT ë¶„ì„ (ë™ì )
                            analysis = await TripleLocationSearchService.analyze_location_with_gpt(
                                strategy, reference_location=start_location
                            )
                            
                            # ğŸ”¥ Kakao ê²€ìƒ‰ (ê²°ê³¼ ë‹¤ì–‘í™”)
                            reference_schedules = [{"location": start_location}] if start_location else []
                            kakao_result = await TripleLocationSearchService.search_kakao(analysis, reference_schedules)
                            
                            if kakao_result and kakao_result.name:
                                candidate_name = kakao_result.name
                                candidate_location = clean_address(kakao_result.address)
                                
                                # ğŸ”¥ ì „ì—­ ì¤‘ë³µ ì²´í¬
                                if (candidate_name in global_used_restaurants or 
                                    candidate_location in global_used_locations):
                                    logger.info(f"     âŒ ì¤‘ë³µ ì œì™¸: {candidate_name}")
                                    continue
                                
                                # ìƒˆë¡œìš´ ì‹ë‹¹ ë°œê²¬
                                restaurant_result = kakao_result
                                global_used_restaurants.add(candidate_name)
                                global_used_locations.add(candidate_location)
                                logger.info(f"     âœ… ìƒˆë¡œìš´ ì‹ë‹¹: {candidate_name}")
                                break
                                
                        except Exception as e:
                            logger.error(f"     âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                            continue
                    
                    # ê²°ê³¼ ì ìš©
                    if restaurant_result:
                        schedule["name"] = restaurant_result.name
                        schedule["location"] = clean_address(restaurant_result.address)
                        schedule["latitude"] = restaurant_result.latitude
                        schedule["longitude"] = restaurant_result.longitude
                        option_modified = True
                        logger.info(f"   ğŸ¯ ì‹ë‹¹ ì ìš©: {restaurant_result.name}")
                    else:
                        logger.info(f"   âš ï¸ ìƒˆë¡œìš´ ì‹ë‹¹ ì°¾ê¸° ì‹¤íŒ¨, ì›ë³¸ ìœ ì§€")
            
            # ğŸ”¥ ê³ ìœ  ID ì„¤ì •
            current_time = int(time.time() * 1000)
            for schedule_type in ["fixedSchedules", "flexibleSchedules"]:
                for j, schedule in enumerate(option_data.get(schedule_type, [])):
                    schedule["id"] = f"{current_time}_{option_num + 1}_{j + 1}"
            
            option = {
                "optionId": option_num + 1,  # ğŸ”¥ 1, 2, 3, 4, 5
                "fixedSchedules": option_data.get("fixedSchedules", []),
                "flexibleSchedules": option_data.get("flexibleSchedules", [])
            }
            
            options.append(option)
            logger.info(f"âœ… ì˜µì…˜ {option_num + 1} ì™„ì„± (ìˆ˜ì •ë¨: {option_modified})")
        
        logger.info(f"ğŸ‰ ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ: {len(options)}ê°œ")
        logger.info(f"ğŸ“Š ì‚¬ìš©ëœ ì‹ë‹¹: {global_used_restaurants}")
        
        return {"options": options}
        
    except Exception as e:
        logger.error(f"âŒ ë™ì  ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ ë‹¤ì¤‘ ì˜µì…˜
        options = []
        current_time = int(time.time() * 1000)
        
        for i in range(5):
            option_data = copy.deepcopy(enhanced_data)
            
            for schedule_type in ["fixedSchedules", "flexibleSchedules"]:
                for j, schedule in enumerate(option_data.get(schedule_type, [])):
                    schedule["id"] = f"{current_time}_{i + 1}_{j + 1}"
            
            options.append({
                "optionId": i + 1,
                "fixedSchedules": option_data.get("fixedSchedules", []),
                "flexibleSchedules": option_data.get("flexibleSchedules", [])
            })
        
        return {"options": options}

def apply_name_cleaning(schedule_data: Dict) -> Dict:
    """ëª¨ë“  ì¼ì •ì˜ name ì •ì œ ì ìš©"""
    import re
    
    for schedule_type in ["fixedSchedules", "flexibleSchedules"]:
        schedule_list = schedule_data.get(schedule_type, [])
        
        for i, schedule in enumerate(schedule_list):
            if schedule.get("name"):
                old_name = schedule["name"]
                
                # 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ì œ
                cleaned_name = clean_korean_text(schedule["name"])
                
                # 2. ì´ë™ í‘œí˜„ ì œê±°
                cleaned_name = re.sub(r'ì—ì„œ\s*.*?ê¹Œì§€', '', cleaned_name)
                cleaned_name = re.sub(r'.*?ì—ì„œ\s*', '', cleaned_name)
                cleaned_name = re.sub(r'\s*ì´ë™$', '', cleaned_name)
                cleaned_name = re.sub(r'^ì´ë™\s*', '', cleaned_name)
                
                # 3. íŠ¹ì • ì¥ì†Œ ë‹¨ìˆœí™”
                if "ë¶€ì‚°ì—­" in cleaned_name:
                    cleaned_name = "ë¶€ì‚°ì—­"
                elif "ì¥ì „ì—­" in cleaned_name:
                    cleaned_name = "ì¥ì „ì—­"
                elif any(word in cleaned_name for word in ["ì €ë…", "ì‹ì‚¬"]):
                    if "ì €ë…" in cleaned_name:
                        cleaned_name = "ì €ë… ì‹ì‚¬"
                    elif "ì ì‹¬" in cleaned_name:
                        cleaned_name = "ì ì‹¬ ì‹ì‚¬"
                    else:
                        cleaned_name = "ì‹ì‚¬"
                
                schedule["name"] = cleaned_name.strip()
                
                if old_name != schedule["name"]:
                    logger.info(f"ì´ë¦„ ì •ì œ: '{old_name}' â†’ '{schedule['name']}'")
    
    return schedule_data
@app.post("/extract-schedule")
async def extract_schedule(request: ScheduleRequest):
    """ğŸ”¥ LangChain ê¸°ë°˜ ë‹¤ì¤‘ ì˜µì…˜ ì¼ì • ì¶”ì¶œ API"""
    import datetime as dt
    import time
    import copy
    
    # ê°•ì œ ë¡œê¹… í•¨ìˆ˜
    def force_log(message):
        timestamp = dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        output = f"ğŸ”¥ {timestamp} - {message}"
        print(output)
        logger.info(message)
        return output
    
    force_log("=== LangChain ê¸°ë°˜ ì¼ì • ì¶”ì¶œ ì‹œì‘ ===")
    force_log(f"ì…ë ¥ í…ìŠ¤íŠ¸: {request.voice_input}")
    force_log(f"ì…ë ¥ ê¸¸ì´: {len(request.voice_input)}ì")
    
    start_time = time.time()
    
    try:
        # Step 1: ğŸ”¥ LangChain ì²´ì¸ ìƒì„± ë° í˜¸ì¶œ
        force_log("Step 1: LangChain ì²´ì¸ ìƒì„± ë° í˜¸ì¶œ")
        
        try:
            # ğŸ”¥ LangChain ì²´ì¸ ìƒì„±
            force_log("ğŸ”— LangChain ì²´ì¸ ìƒì„± ì¤‘...")
            chain = create_schedule_chain(request.voice_input)
            force_log("âœ… LangChain ì²´ì¸ ìƒì„± ì™„ë£Œ")
            
            # ğŸ”¥ LangChain ì²´ì¸ í˜¸ì¶œ
            force_log("ğŸš€ LangChain ì²´ì¸ í˜¸ì¶œ ì‹œì‘")
            force_log(f"ğŸ“ ì…ë ¥ ë°ì´í„°: {request.voice_input[:100]}...")
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            schedule_data = await asyncio.wait_for(
                run_in_executor(lambda: chain.invoke({"input": request.voice_input})),
                timeout=30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            
            force_log("ğŸ“© LangChain ì²´ì¸ ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ")
            force_log(f"ğŸ“Š ì‘ë‹µ íƒ€ì…: {type(schedule_data)}")
            
            # ì‘ë‹µ ê²€ì¦
            if isinstance(schedule_data, dict):
                fixed_count = len(schedule_data.get('fixedSchedules', []))
                flexible_count = len(schedule_data.get('flexibleSchedules', []))
                force_log(f"âœ… JSON íŒŒì‹± ì„±ê³µ: ê³ ì •={fixed_count}ê°œ, ìœ ì—°={flexible_count}ê°œ")
            else:
                force_log(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ íƒ€ì…: {type(schedule_data)}")
                # ë¬¸ìì—´ì¸ ê²½ìš° JSON íŒŒì‹± ì‹œë„
                if isinstance(schedule_data, str):
                    schedule_data = safe_parse_json(schedule_data)
            
        except asyncio.TimeoutError:
            force_log("âŒ LangChain ì²´ì¸ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (30ì´ˆ)")
            raise Exception("LangChain ì²´ì¸ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
            
        except Exception as e:
            force_log(f"âŒ LangChain ì²´ì¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ìˆ˜ë™ìœ¼ë¡œ ì¼ì • ìƒì„±
            force_log("ğŸ”„ í´ë°±: ìˆ˜ë™ ë¶„ë¦¬ ì¼ì • ìƒì„±")
            
            voice_text = request.voice_input.lower()
            schedules = []
            current_time = int(dt.datetime.now().timestamp() * 1000)
            today = dt.datetime.now()
            
            # ğŸ”¥ ë¶„ë¦¬ëœ ì¼ì •ìœ¼ë¡œ ìƒì„±
            if "ë¶€ì‚°ì—­" in voice_text:
                schedules.append({
                    "id": f"{current_time}_1",
                    "name": "ë¶€ì‚°ì—­",
                    "type": "FIXED",
                    "duration": 30,
                    "priority": 1,
                    "location": "",
                    "latitude": 35.1151,
                    "longitude": 129.0425,
                    "startTime": f"{today.strftime('%Y-%m-%d')}T17:00:00",
                    "endTime": f"{today.strftime('%Y-%m-%d')}T17:30:00"
                })
            
            if "ì €ë…" in voice_text or "ì‹ì‚¬" in voice_text:
                schedules.append({
                    "id": f"{current_time}_2",
                    "name": "ì €ë… ì‹ì‚¬",
                    "type": "FIXED",
                    "duration": 120,
                    "priority": 2,
                    "location": "",
                    "latitude": 35.2,
                    "longitude": 129.1,
                    "startTime": f"{today.strftime('%Y-%m-%d')}T18:00:00",
                    "endTime": f"{today.strftime('%Y-%m-%d')}T20:00:00"
                })
            
            if "ì¥ì „ì—­" in voice_text:
                schedules.append({
                    "id": f"{current_time}_3",
                    "name": "ì¥ì „ì—­",
                    "type": "FIXED",
                    "duration": 30,
                    "priority": 3,
                    "location": "",
                    "latitude": 35.2311,
                    "longitude": 129.0839,
                    "startTime": f"{today.strftime('%Y-%m-%d')}T20:30:00",
                    "endTime": f"{today.strftime('%Y-%m-%d')}T21:00:00"
                })
            
            schedule_data = {
                "fixedSchedules": schedules,
                "flexibleSchedules": []
            }
            
            force_log(f"âœ… ìˆ˜ë™ ë¶„ë¦¬ ì¼ì • ìƒì„± ì™„ë£Œ: {len(schedules)}ê°œ")
        
        # Step 2: Name ì •ì œ ì ìš© (ê¸°ì¡´ê³¼ ë™ì¼)
        force_log("Step 2: Name ì •ì œ ì ìš©")
        schedule_data = apply_name_cleaning(schedule_data)
        force_log("âœ… Name ì •ì œ ì™„ë£Œ")
        
        # Step 3: ìœ„ì¹˜ ì •ë³´ ë³´ê°• (ê¸°ì¡´ê³¼ ë™ì¼)
        force_log("Step 3: ìœ„ì¹˜ ì •ë³´ ë³´ê°• ë° ì£¼ì†Œ ì •ì œ")
        
        try:
            enhanced_data = await asyncio.wait_for(
                enhance_locations_with_triple_api(schedule_data),
                timeout=30
            )
            force_log("âœ… ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì™„ë£Œ")
            schedule_data = enhanced_data
            
        except Exception as e:
            force_log(f"âš ï¸ ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹¤íŒ¨: {e}")
            enhanced_data = schedule_data
        
        # Step 4: ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
        force_log("Step 4: ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±")
        
        try:
            use_dynamic_system = should_use_dynamic_system(enhanced_data, request.voice_input)
            
            if use_dynamic_system:
                force_log("ğŸ¤– DynamicRouteOptimizer ì‚¬ìš© (ë¸Œëœë“œ ê¸°ë°˜)")
                optimizer = DynamicRouteOptimizer(KAKAO_REST_API_KEY)
                final_result = await optimizer.create_multiple_options(enhanced_data, request.voice_input)
                
                if len(final_result.get("options", [])) >= 1:
                    force_log(f"âœ… ë™ì  ì‹œìŠ¤í…œ ì„±ê³µ: {len(final_result.get('options', []))}ê°œ ì˜µì…˜")
                else:
                    force_log("âŒ ë™ì  ì‹œìŠ¤í…œ ì™„ì „ ì‹¤íŒ¨, ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±")
                    final_result = await create_traditional_options(enhanced_data, request.voice_input)
            else:
                force_log("ğŸ“‹ ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš© (ì‹ì‚¬ ê´€ë ¨)")
                final_result = await create_traditional_options(enhanced_data, request.voice_input)
                
        except Exception as e:
            force_log(f"âŒ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            final_result = await create_traditional_options(enhanced_data, request.voice_input)
        
        # Step 5: ìµœì¢… ì‘ë‹µ
        total_time = time.time() - start_time
        force_log(f"Step 5: ìµœì¢… ì™„ë£Œ - ì´ {total_time:.2f}ì´ˆ")
        
        option_count = len(final_result.get('options', []))
        force_log(f"ìµœì¢… ì˜µì…˜ ìˆ˜: {option_count}ê°œ")
        
        force_log("=== LangChain ê¸°ë°˜ ì¼ì • ì¶”ì¶œ ì™„ë£Œ ===")
        
        return UnicodeJSONResponse(content=final_result, status_code=200)
    
    except Exception as e:
        force_log(f"âŒ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
        
        # ìµœì¢… í´ë°± (ê¸°ì¡´ê³¼ ë™ì¼)
        # ... í´ë°± ì½”ë“œ ...

# ===== ê¸°ì¡´ ì‹œìŠ¤í…œ ì™„ì „ ì¬í™œìš© + ê°•í™”ëœ ì‹ì‚¬ ê°ì§€ =====

async def search_restaurants_directly(search_query: str, used_restaurants: Set[str]) -> Optional[Dict[str, Any]]:
    """ì§ì ‘ Kakao APIë¡œ ì‹ë‹¹ ê²€ìƒ‰"""
    
    if not KAKAO_REST_API_KEY:
        return None
    
    try:
        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
        
        params = {
            "query": search_query,
            "size": 15,
            "sort": "accuracy"
        }
        
        print(f"ğŸ” ì§ì ‘ ê²€ìƒ‰: '{search_query}'")
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    if data.get("documents"):
                        for place in data["documents"]:
                            place_name = place.get("place_name", "")
                            address = place.get("road_address_name") or place.get("address_name", "")
                            category = place.get("category_name", "")
                            
                            # ì´ë¯¸ ì‚¬ìš©ëœ ì‹ë‹¹ ì œì™¸
                            if place_name in used_restaurants:
                                continue
                            
                            # ë¶€ì •ì  í‚¤ì›Œë“œ í•„í„°ë§
                            negative_keywords = ["í•™ì›", "ë³‘ì›", "ì•½êµ­", "ì€í–‰", "ë¶€ë™ì‚°"]
                            if any(neg in place_name.lower() for neg in negative_keywords):
                                continue
                            
                            print(f"   âœ… ë°œê²¬: {place_name} @ {address}")
                            
                            return {
                                "name": place_name,
                                "address": clean_address(address),
                                "latitude": float(place.get("y", 0)),
                                "longitude": float(place.get("x", 0)),
                                "category": category
                            }
                    
                    print(f"   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {search_query}")
                else:
                    print(f"   âŒ API ì˜¤ë¥˜: {response.status}")
        
        return None
        
    except Exception as e:
        print(f"   âŒ ê²€ìƒ‰ ì˜ˆì™¸: {e}")
        return None

# ===== ê¸°ì¡´ ì‹œìŠ¤í…œ ì™„ì „ ì¬í™œìš© + ê°•í™”ëœ ì‹ì‚¬ ê°ì§€ =====

class ScheduleExpansionRequest(BaseModel):
    """ì¼ì • í™•ì¥ ìš”ì²­ ëª¨ë¸"""
    schedules: List[Dict[str, Any]]

def enhanced_has_meal_schedules(schedules: List[Dict[str, Any]]) -> bool:
    """ê°•í™”ëœ ì‹ì‚¬ ê´€ë ¨ ì¼ì • ê°ì§€"""
    
    # ğŸ”¥ ë” í¬ê´„ì ì¸ ì‹ì‚¬ í‚¤ì›Œë“œ
    meal_keywords = [
        # ê¸°ë³¸ ì‹ì‚¬
        "ì‹ì‚¬", "ë°¥", "ì €ë…", "ì ì‹¬", "ì•„ì¹¨", "ë§›ì§‘", "ë¨¹ê¸°", "ì‹ë‹¹",
        # ì¹´í˜/ìŒë£Œ
        "ì¹´í˜", "ì»¤í”¼", "coffee", "cafe", "ë¸ŒëŸ°ì¹˜", "brunch", "ë””ì €íŠ¸", "dessert",
        # êµ¬ì²´ì  ìŒì‹
        "ì¹˜í‚¨", "í”¼ì", "í–„ë²„ê±°", "íŒŒìŠ¤íƒ€", "ë¼ë©´", "êµ­ë°¥", "ê°ˆë¹„", "ì‚¼ê²¹ì‚´",
        # ì‹ì‚¬ ì‹œê°„
        "íƒ€ì„", "time", "ëŸ°ì¹˜", "lunch", "dinner", "breakfast",
        # ì‹ì‚¬ ê´€ë ¨ í™œë™
        "íšŒì‹", "ìˆ ", "ë§¥ì£¼", "ì†Œì£¼", "ì™€ì¸", "bar", "pub"
    ]
    
    for schedule in schedules:
        name = schedule.get("name", "").lower()
        for keyword in meal_keywords:
            if keyword in name:
                print(f"ğŸ½ï¸ ì‹ì‚¬ í‚¤ì›Œë“œ '{keyword}' ë°œê²¬ in '{name}'")
                return True
    
    return False

def create_enhanced_voice_input(schedules: List[Dict[str, Any]]) -> str:
    """ì¼ì •ë“¤ì„ ë¶„ì„í•˜ì—¬ ë” êµ¬ì²´ì ì¸ ê°€ì§œ ìŒì„± ì…ë ¥ ìƒì„±"""
    
    meal_items = []
    locations = []
    
    for schedule in schedules:
        name = schedule.get("name", "").lower()
        location = schedule.get("location", "")
        
        # ì‹ì‚¬ ê´€ë ¨ ì¼ì • ìˆ˜ì§‘
        if any(word in name for word in ["ì‹ì‚¬", "ë¸ŒëŸ°ì¹˜", "ì ì‹¬", "ì €ë…", "ì¹´í˜", "ì»¤í”¼", "íƒ€ì„"]):
            meal_items.append(name)
        
        # ì§€ì—­ ì •ë³´ ìˆ˜ì§‘
        if location:
            if "ì„œìš¸" in location:
                locations.append("ì„œìš¸")
            elif "ë¶€ì‚°" in location:
                locations.append("ë¶€ì‚°")
            # ê¸°íƒ€ ì§€ì—­ë„ ì¶”ê°€ ê°€ëŠ¥
    
    # ë” êµ¬ì²´ì ì¸ ìŒì„± ì…ë ¥ ìƒì„±
    if meal_items and locations:
        location_str = locations[0] if locations else "ì„œìš¸"
        meal_str = ", ".join(meal_items)
        
        voice_input = f"{location_str}ì—ì„œ {meal_str} ë‹¤ì–‘í•œ ì˜µì…˜ì„ ì›í•©ë‹ˆë‹¤. ê°ê° ë‹¤ë¥¸ ì‹ë‹¹ë“¤ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    else:
        voice_input = "ì„œìš¸ì—ì„œ ë‹¤ì–‘í•œ ì‹ì‚¬ ì˜µì…˜ì„ ì›í•©ë‹ˆë‹¤. ë¸ŒëŸ°ì¹˜, ì¹´í˜, ì‹ë‹¹ ë“± ê°ê° ë‹¤ë¥¸ ê³³ë“¤ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    
    print(f"ğŸ¤ ìƒì„±ëœ ìŒì„± ì…ë ¥: '{voice_input}'")
    return voice_input

@app.post("/expand-schedule-options")
async def expand_schedule_options(request: ScheduleExpansionRequest):
    """ğŸ”¥ ê¸°ì¡´ ì‹œìŠ¤í…œ ì™„ì „ ì¬í™œìš© + ê°•í™”ëœ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±"""
    
    def force_log(msg):
        print(f"ğŸ”„ {msg}")
        logger.info(msg)
    
    force_log("=== ê°•í™”ëœ ë‹¤ì¤‘ ì˜µì…˜ ì‹œìŠ¤í…œ ì‹œì‘ ===")
    force_log(f"ì…ë ¥ ì¼ì • ìˆ˜: {len(request.schedules)}ê°œ")
    
    # ì…ë ¥ ì¼ì • ìƒì„¸ ë¡œê¹…
    for i, schedule in enumerate(request.schedules):
        force_log(f"  ì¼ì • {i+1}: '{schedule.get('name', 'N/A')}' @ '{schedule.get('location', 'N/A')}'")
    
    try:
        # Step 1: ê°•í™”ëœ ì‹ì‚¬ ì¼ì • ê°ì§€
        force_log("Step 1: ê°•í™”ëœ ì‹ì‚¬ ì¼ì • ê°ì§€")
        
        if not enhanced_has_meal_schedules(request.schedules):
            force_log("   ì‹ì‚¬ ì¼ì •ì´ ì—†ì–´ì„œ ì›ë³¸ë§Œ ë°˜í™˜")
            return UnicodeJSONResponse(content={
                "options": [{
                    "optionId": 1,
                    "fixedSchedules": request.schedules,
                    "flexibleSchedules": []
                }]
            })
        
        force_log("   âœ… ì‹ì‚¬ ê´€ë ¨ ì¼ì • ê°ì§€ë¨")
        
        # Step 2: ê¸°ì¡´ extract-schedule í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        force_log("Step 2: ê¸°ì¡´ schedule_data í˜•ì‹ìœ¼ë¡œ ë³€í™˜")
        
        schedule_data = {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }
        
        # ëª¨ë“  ì¼ì •ì„ fixedSchedulesë¡œ ë³€í™˜
        for schedule in request.schedules:
            fixed_schedule = {
                "id": schedule.get("id", f"expand_{int(time.time() * 1000)}_{len(schedule_data['fixedSchedules'])}"),
                "name": schedule.get("name", "ì¼ì •"),
                "type": "FIXED",
                "duration": schedule.get("duration", 60),
                "priority": schedule.get("priority", len(schedule_data['fixedSchedules']) + 1),
                "location": schedule.get("location", ""),
                "latitude": schedule.get("latitude", 37.5665),
                "longitude": schedule.get("longitude", 126.9780),
                "startTime": schedule.get("startTime", ""),
                "endTime": schedule.get("endTime", "")
            }
            
            schedule_data["fixedSchedules"].append(fixed_schedule)
        
        force_log(f"âœ… ë³€í™˜ ì™„ë£Œ: ê³ ì • ì¼ì • {len(schedule_data['fixedSchedules'])}ê°œ")
        
        # Step 3: ğŸ”¥ ì—­/ê³µí•­ ë“± íŠ¹í™”ëœ ìœ„ì¹˜ ë³´ê°• ì‹œìŠ¤í…œ í˜¸ì¶œ
        force_log("Step 3: ì—­/ê³µí•­ íŠ¹í™” ìœ„ì¹˜ ë³´ê°• + ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸ì¶œ")
        
        try:
            # ğŸ”¥ Step 3-1: ì—­/ê³µí•­ ë“± êµ¬ì²´ì  ì¥ì†Œì— ëŒ€í•œ íŠ¹í™” ê²€ìƒ‰
            for i, schedule in enumerate(schedule_data["fixedSchedules"]):
                name = schedule.get("name", "").lower()
                current_location = schedule.get("location", "")
                
                # ì—­, ê³µí•­, í„°ë¯¸ë„ ë“± êµ¬ì²´ì  ì¥ì†Œ ê°ì§€
                if any(keyword in name for keyword in ['ì—­', 'station', 'ê³µí•­', 'airport', 'í„°ë¯¸ë„', 'terminal', 'ëŒ€í•™êµ', 'university']):
                    force_log(f"  ğŸš‰ êµ¬ì²´ì  ì¥ì†Œ ê°ì§€: '{schedule.get('name')}'")
                    
                    # í˜„ì¬ ìœ„ì¹˜ê°€ ë¶€ì •í™•í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ ì¬ê²€ìƒ‰
                    if not current_location or len(current_location) < 10:
                        force_log(f"    ğŸ” '{schedule.get('name')}' ì •í™•í•œ ìœ„ì¹˜ ì¬ê²€ìƒ‰")
                        
                        # ğŸ”¥ Kakao ìš°ì„  ê²€ìƒ‰ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)
                        reference_schedules = []
                        if i > 0:  # ì´ì „ ì¼ì •ì´ ìˆìœ¼ë©´ ì°¸ì¡°ë¡œ í™œìš©
                            reference_schedules = [schedule_data["fixedSchedules"][i-1]]
                        
                        enhanced_schedule = await enhance_single_schedule_triple(
                            schedule, reference_schedules
                        )
                        
                        # ê²°ê³¼ ì ìš©
                        if enhanced_schedule.get("location") and enhanced_schedule["location"] != current_location:
                            schedule["location"] = enhanced_schedule["location"]
                            schedule["latitude"] = enhanced_schedule.get("latitude", schedule.get("latitude"))
                            schedule["longitude"] = enhanced_schedule.get("longitude", schedule.get("longitude"))
                            
                            force_log(f"    âœ… ìœ„ì¹˜ ì—…ë°ì´íŠ¸: {enhanced_schedule['location']}")
                        else:
                            force_log(f"    âš ï¸ ì¬ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            # ğŸ”¥ Step 3-2: ê¸°ì¡´ ì „ì²´ ìœ„ì¹˜ ë³´ê°• ì‹œìŠ¤í…œ í˜¸ì¶œ
            enhanced_data = await asyncio.wait_for(
                enhance_locations_with_triple_api(schedule_data),
                timeout=30
            )
            force_log("âœ… ì „ì²´ ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì™„ë£Œ")
            
        except Exception as e:
            force_log(f"âš ï¸ ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹¤íŒ¨: {e}")
            enhanced_data = schedule_data
        
        # Step 4: ê°•í™”ëœ ìŒì„± ì…ë ¥ ìƒì„±
        force_log("Step 4: ê°•í™”ëœ ìŒì„± ì…ë ¥ ìƒì„±")
        
        enhanced_voice_input = create_enhanced_voice_input(request.schedules)
        
        # Step 5: ğŸ”¥ ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œìŠ¤í…œ
        force_log("Step 5: ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œìŠ¤í…œ")
        
        # ì‹ì‚¬ ê´€ë ¨ ì¼ì • ì¸ë±ìŠ¤ ì°¾ê¸°
        meal_schedule_indices = []
        for i, schedule in enumerate(enhanced_data.get("fixedSchedules", [])):
            name = schedule.get("name", "").lower()
            if any(word in name for word in ["ì‹ì‚¬", "ë¸ŒëŸ°ì¹˜", "ì ì‹¬", "ì €ë…", "ì¹´í˜", "ì»¤í”¼", "íƒ€ì„"]):
                meal_schedule_indices.append(i)
                force_log(f"  ğŸ½ï¸ ì‹ì‚¬ ì¼ì • ë°œê²¬: ì¸ë±ìŠ¤ {i}, ì´ë¦„ '{schedule.get('name')}'")
        
        if not meal_schedule_indices:
            force_log("  âš ï¸ ì‹ì‚¬ ì¼ì •ì´ ì—†ì–´ì„œ ë‹¨ì¼ ì˜µì…˜ ë°˜í™˜")
            final_result = {"options": [{"optionId": 1, "fixedSchedules": enhanced_data["fixedSchedules"], "flexibleSchedules": []}]}
        else:
            # ğŸ”¥ ê°•ì œë¡œ 5ê°œ ë‹¤ë¥¸ ì˜µì…˜ ìƒì„±
            force_log(f"  ğŸ”¥ {len(meal_schedule_indices)}ê°œ ì‹ì‚¬ ì¼ì •ì— ëŒ€í•´ ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±")
            
            options = []
            used_restaurants = set()
            
            # ì°¸ì¡° ì§€ì—­ ì¶”ì¶œ
            reference_location = "ì„œìš¸"
            for schedule in enhanced_data.get("fixedSchedules", []):
                location = schedule.get("location", "")
                if "ì„œìš¸" in location:
                    reference_location = "ì„œìš¸"
                    break
                elif "ë¶€ì‚°" in location:
                    reference_location = "ë¶€ì‚°"
                    break
                elif "ëŒ€êµ¬" in location:
                    reference_location = "ëŒ€êµ¬"
                    break
            
            force_log(f"  ğŸ“ ì°¸ì¡° ì§€ì—­: {reference_location}")
            
            # 5ê°œ ì˜µì…˜ë³„ ê²€ìƒ‰ ì „ëµ
            search_strategies = [
                {"keywords": ["ë§›ì§‘", "ì¸ê¸°"], "categories": ["í•œì‹", "ì–‘ì‹"]},      # ì˜µì…˜ 1: ì¸ê¸° ë§›ì§‘
                {"keywords": ["í•œì‹", "ì „í†µ"], "categories": ["í•œì‹", "ê°ˆë¹„"]},     # ì˜µì…˜ 2: í•œì‹ ì „í†µ
                {"keywords": ["ë¶„ì‹", "ê¹€ë°¥"], "categories": ["ë¶„ì‹", "ê¹€ë°¥"]},     # ì˜µì…˜ 3: ë¶„ì‹
                {"keywords": ["ì¹´í˜", "ì»¤í”¼"], "categories": ["ì¹´í˜", "ë””ì €íŠ¸"]},   # ì˜µì…˜ 4: ì¹´í˜
                {"keywords": ["ì¹˜í‚¨", "í”¼ì"], "categories": ["ì¹˜í‚¨", "í”¼ì"]}      # ì˜µì…˜ 5: íŒ¨ìŠ¤íŠ¸í‘¸ë“œ
            ]
            
            for option_num in range(5):
                force_log(f"  ğŸ”„ ì˜µì…˜ {option_num + 1} ìƒì„± ì¤‘...")
                
                option_data = copy.deepcopy(enhanced_data)
                option_modified = False
                strategy = search_strategies[option_num]
                
                # ê° ì‹ì‚¬ ì¼ì • ì²˜ë¦¬
                for meal_idx in meal_schedule_indices:
                    if meal_idx < len(option_data["fixedSchedules"]):
                        schedule = option_data["fixedSchedules"][meal_idx]
                        original_name = schedule.get("name", "")
                        
                        force_log(f"    ğŸ½ï¸ ì¼ì • ìˆ˜ì •: '{original_name}' (ì¸ë±ìŠ¤: {meal_idx})")
                        
                        # ğŸ”¥ ì§ì ‘ Kakao API ê²€ìƒ‰
                        search_query = f"{reference_location} {strategy['keywords'][0]}"
                        
                        try:
                            new_restaurant = await search_restaurants_directly(search_query, used_restaurants)
                            
                            if new_restaurant:
                                # ì¼ì • ì—…ë°ì´íŠ¸
                                schedule["name"] = new_restaurant["name"]
                                schedule["location"] = new_restaurant["address"]
                                schedule["latitude"] = new_restaurant["latitude"] 
                                schedule["longitude"] = new_restaurant["longitude"]
                                
                                used_restaurants.add(new_restaurant["name"])
                                option_modified = True
                                
                                force_log(f"      âœ… ìƒˆë¡œìš´ ì‹ë‹¹: {new_restaurant['name']}")
                                force_log(f"      ğŸ“ ì£¼ì†Œ: {new_restaurant['address']}")
                            else:
                                force_log(f"      âš ï¸ ìƒˆë¡œìš´ ì‹ë‹¹ ì°¾ê¸° ì‹¤íŒ¨")
                                
                        except Exception as e:
                            force_log(f"      âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # ê³ ìœ  ID ë¶€ì—¬
                current_time = int(time.time() * 1000)
                for j, schedule in enumerate(option_data["fixedSchedules"]):
                    schedule["id"] = f"{current_time}_{option_num + 1}_{j + 1}"
                
                # ì˜µì…˜ ì¶”ê°€
                options.append({
                    "optionId": option_num + 1,
                    "fixedSchedules": option_data["fixedSchedules"],
                    "flexibleSchedules": option_data.get("flexibleSchedules", [])
                })
                
                force_log(f"    âœ… ì˜µì…˜ {option_num + 1} ì™„ì„± (ìˆ˜ì •ë¨: {option_modified})")
            
            final_result = {"options": options}
            force_log(f"ğŸ‰ ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ: {len(options)}ê°œ")
        
        # Step 6: ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ê²€ìƒ‰
        force_log("Step 6: ê²°ê³¼ í’ˆì§ˆ ê²€ì¦ ë° ë³´ê°•")
        
        option_count = len(final_result.get('options', []))
        force_log(f"ì´ˆê¸° ì˜µì…˜ ìˆ˜: {option_count}ê°œ")
        
        # ì˜µì…˜ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ëª¨ë‘ ë™ì¼í•˜ë©´ ì¶”ê°€ ê²€ìƒ‰
        if option_count < 5:
            force_log(f"ğŸ”„ ì˜µì…˜ ë¶€ì¡± ({option_count}ê°œ), ì¶”ê°€ ìƒì„± ì‹œë„")
            
            # ë¸Œëœë“œ ì‹œìŠ¤í…œë„ ì‹œë„
            try:
                optimizer = DynamicRouteOptimizer(KAKAO_REST_API_KEY)
                additional_result = await optimizer.create_multiple_options(enhanced_data, enhanced_voice_input)
                
                if len(additional_result.get("options", [])) > option_count:
                    force_log("âœ… ë™ì  ì‹œìŠ¤í…œìœ¼ë¡œ ë” ë§ì€ ì˜µì…˜ ìƒì„±ë¨")
                    final_result = additional_result
                
            except Exception as e:
                force_log(f"âš ï¸ ì¶”ê°€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # Step 7: ê° ì˜µì…˜ì˜ í’ˆì§ˆ ê²€ì¦ ë° ë¡œê¹…
        force_log("Step 7: ìµœì¢… ê²°ê³¼ í’ˆì§ˆ ê²€ì¦")
        
        final_option_count = len(final_result.get('options', []))
        force_log(f"ìµœì¢… ì˜µì…˜ ìˆ˜: {final_option_count}ê°œ")
        
        # ê° ì˜µì…˜ì˜ ë‹¤ì–‘ì„± ì²´í¬
        unique_locations = set()
        unique_names = set()
        
        for i, option in enumerate(final_result.get('options', [])):
            force_log(f"ì˜µì…˜ {i+1} í’ˆì§ˆ ê²€ì¦:")
            
            for j, schedule in enumerate(option.get('fixedSchedules', [])):
                name = schedule.get('name', 'N/A')
                location = schedule.get('location', 'N/A')
                
                force_log(f"  ì¼ì • {j+1}: '{name}' @ '{location[:50]}...'")
                
                # ì‹ì‚¬ ê´€ë ¨ ì¼ì •ì˜ ë‹¤ì–‘ì„± ì²´í¬
                if any(word in name.lower() for word in ["ì‹ì‚¬", "ë¸ŒëŸ°ì¹˜", "ì ì‹¬", "ì €ë…", "ì¹´í˜"]):
                    unique_locations.add(location)
                    unique_names.add(name)
        
        force_log(f"ğŸ“Š ë‹¤ì–‘ì„± ë¶„ì„: ê³ ìœ  ìœ„ì¹˜ {len(unique_locations)}ê°œ, ê³ ìœ  ì´ë¦„ {len(unique_names)}ê°œ")
        
        # Step 8: ì›ë³¸ êµ¬ì¡° ë³´ì¡´
        force_log("Step 8: ì›ë³¸ êµ¬ì¡° ë³´ì¡´")
        
        for i, option in enumerate(final_result.get("options", [])):
            for j, schedule in enumerate(option.get("fixedSchedules", [])):
                if j < len(request.schedules):
                    original = request.schedules[j]
                    
                    # ì›ë³¸ì˜ ì‹œê°„ ì •ë³´ ë³´ì¡´
                    for time_field in ["startTime", "endTime", "duration"]:
                        if time_field in original:
                            schedule[time_field] = original[time_field]
                    
                    # ì›ë³¸ì˜ ìš°ì„ ìˆœìœ„ ë³´ì¡´
                    if "priority" in original:
                        schedule["priority"] = original["priority"]
        
        force_log("=== ê°•í™”ëœ ë‹¤ì¤‘ ì˜µì…˜ ì‹œìŠ¤í…œ ì™„ë£Œ ===")
        return UnicodeJSONResponse(content=final_result, status_code=200)
        
    except Exception as e:
        force_log(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        import traceback
        force_log(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        # ìµœì¢… í´ë°±
        fallback_options = []
        current_time = int(time.time() * 1000)
        
        for i in range(5):
            schedules_copy = copy.deepcopy(request.schedules)
            
            for j, schedule in enumerate(schedules_copy):
                schedule["id"] = f"{current_time}_fallback_{i + 1}_{j + 1}"
            
            fallback_options.append({
                "optionId": i + 1,
                "fixedSchedules": schedules_copy,
                "flexibleSchedules": []
            })
        
        return UnicodeJSONResponse(content={"options": fallback_options}, status_code=200)

class ScheduleExpansionRequest(BaseModel):
    """ì¼ì • í™•ì¥ ìš”ì²­ ëª¨ë¸"""
    schedules: List[Dict[str, Any]]

def enhanced_has_meal_schedules(schedules: List[Dict[str, Any]]) -> bool:
    """ê°•í™”ëœ ì‹ì‚¬ ê´€ë ¨ ì¼ì • ê°ì§€"""
    
    # ğŸ”¥ ë” í¬ê´„ì ì¸ ì‹ì‚¬ í‚¤ì›Œë“œ
    meal_keywords = [
        # ê¸°ë³¸ ì‹ì‚¬
        "ì‹ì‚¬", "ë°¥", "ì €ë…", "ì ì‹¬", "ì•„ì¹¨", "ë§›ì§‘", "ë¨¹ê¸°", "ì‹ë‹¹",
        # ì¹´í˜/ìŒë£Œ
        "ì¹´í˜", "ì»¤í”¼", "coffee", "cafe", "ë¸ŒëŸ°ì¹˜", "brunch", "ë””ì €íŠ¸", "dessert",
        # êµ¬ì²´ì  ìŒì‹
        "ì¹˜í‚¨", "í”¼ì", "í–„ë²„ê±°", "íŒŒìŠ¤íƒ€", "ë¼ë©´", "êµ­ë°¥", "ê°ˆë¹„", "ì‚¼ê²¹ì‚´",
        # ì‹ì‚¬ ì‹œê°„
        "íƒ€ì„", "time", "ëŸ°ì¹˜", "lunch", "dinner", "breakfast",
        # ì‹ì‚¬ ê´€ë ¨ í™œë™
        "íšŒì‹", "ìˆ ", "ë§¥ì£¼", "ì†Œì£¼", "ì™€ì¸", "bar", "pub"
    ]
    
    for schedule in schedules:
        name = schedule.get("name", "").lower()
        for keyword in meal_keywords:
            if keyword in name:
                print(f"ğŸ½ï¸ ì‹ì‚¬ í‚¤ì›Œë“œ '{keyword}' ë°œê²¬ in '{name}'")
                return True
    
    return False

def create_enhanced_voice_input(schedules: List[Dict[str, Any]]) -> str:
    """ì¼ì •ë“¤ì„ ë¶„ì„í•˜ì—¬ ë” êµ¬ì²´ì ì¸ ê°€ì§œ ìŒì„± ì…ë ¥ ìƒì„±"""
    
    meal_items = []
    locations = []
    
    for schedule in schedules:
        name = schedule.get("name", "").lower()
        location = schedule.get("location", "")
        
        # ì‹ì‚¬ ê´€ë ¨ ì¼ì • ìˆ˜ì§‘
        if any(word in name for word in ["ì‹ì‚¬", "ë¸ŒëŸ°ì¹˜", "ì ì‹¬", "ì €ë…", "ì¹´í˜", "ì»¤í”¼", "íƒ€ì„"]):
            meal_items.append(name)
        
        # ì§€ì—­ ì •ë³´ ìˆ˜ì§‘
        if location:
            if "ì„œìš¸" in location:
                locations.append("ì„œìš¸")
            elif "ë¶€ì‚°" in location:
                locations.append("ë¶€ì‚°")
            # ê¸°íƒ€ ì§€ì—­ë„ ì¶”ê°€ ê°€ëŠ¥
    
    # ë” êµ¬ì²´ì ì¸ ìŒì„± ì…ë ¥ ìƒì„±
    if meal_items and locations:
        location_str = locations[0] if locations else "ì„œìš¸"
        meal_str = ", ".join(meal_items)
        
        voice_input = f"{location_str}ì—ì„œ {meal_str} ë‹¤ì–‘í•œ ì˜µì…˜ì„ ì›í•©ë‹ˆë‹¤. ê°ê° ë‹¤ë¥¸ ì‹ë‹¹ë“¤ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    else:
        voice_input = "ì„œìš¸ì—ì„œ ë‹¤ì–‘í•œ ì‹ì‚¬ ì˜µì…˜ì„ ì›í•©ë‹ˆë‹¤. ë¸ŒëŸ°ì¹˜, ì¹´í˜, ì‹ë‹¹ ë“± ê°ê° ë‹¤ë¥¸ ê³³ë“¤ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    
    print(f"ğŸ¤ ìƒì„±ëœ ìŒì„± ì…ë ¥: '{voice_input}'")
    return voice_input

@app.post("/expand-schedule-options")
async def expand_schedule_options(request: ScheduleExpansionRequest):
    """ğŸ”¥ ê¸°ì¡´ ì‹œìŠ¤í…œ ì™„ì „ ì¬í™œìš© + ê°•í™”ëœ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±"""
    
    def force_log(msg):
        print(f"ğŸ”„ {msg}")
        logger.info(msg)
    
    force_log("=== ê°•í™”ëœ ë‹¤ì¤‘ ì˜µì…˜ ì‹œìŠ¤í…œ ì‹œì‘ ===")
    force_log(f"ì…ë ¥ ì¼ì • ìˆ˜: {len(request.schedules)}ê°œ")
    
    # ì…ë ¥ ì¼ì • ìƒì„¸ ë¡œê¹…
    for i, schedule in enumerate(request.schedules):
        force_log(f"  ì¼ì • {i+1}: '{schedule.get('name', 'N/A')}' @ '{schedule.get('location', 'N/A')}'")
    
    try:
        # Step 1: ê°•í™”ëœ ì‹ì‚¬ ì¼ì • ê°ì§€
        force_log("Step 1: ê°•í™”ëœ ì‹ì‚¬ ì¼ì • ê°ì§€")
        
        if not enhanced_has_meal_schedules(request.schedules):
            force_log("   ì‹ì‚¬ ì¼ì •ì´ ì—†ì–´ì„œ ì›ë³¸ë§Œ ë°˜í™˜")
            return UnicodeJSONResponse(content={
                "options": [{
                    "optionId": 1,
                    "fixedSchedules": request.schedules,
                    "flexibleSchedules": []
                }]
            })
        
        force_log("   âœ… ì‹ì‚¬ ê´€ë ¨ ì¼ì • ê°ì§€ë¨")
        
        # Step 2: ê¸°ì¡´ extract-schedule í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        force_log("Step 2: ê¸°ì¡´ schedule_data í˜•ì‹ìœ¼ë¡œ ë³€í™˜")
        
        schedule_data = {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }
        
        # ëª¨ë“  ì¼ì •ì„ fixedSchedulesë¡œ ë³€í™˜
        for schedule in request.schedules:
            fixed_schedule = {
                "id": schedule.get("id", f"expand_{int(time.time() * 1000)}_{len(schedule_data['fixedSchedules'])}"),
                "name": schedule.get("name", "ì¼ì •"),
                "type": "FIXED",
                "duration": schedule.get("duration", 60),
                "priority": schedule.get("priority", len(schedule_data['fixedSchedules']) + 1),
                "location": schedule.get("location", ""),
                "latitude": schedule.get("latitude", 37.5665),
                "longitude": schedule.get("longitude", 126.9780),
                "startTime": schedule.get("startTime", ""),
                "endTime": schedule.get("endTime", "")
            }
            
            schedule_data["fixedSchedules"].append(fixed_schedule)
        
        force_log(f"âœ… ë³€í™˜ ì™„ë£Œ: ê³ ì • ì¼ì • {len(schedule_data['fixedSchedules'])}ê°œ")
        
        # Step 3: ğŸ”¥ ì—­/ê³µí•­ ë“± íŠ¹í™”ëœ ìœ„ì¹˜ ë³´ê°• ì‹œìŠ¤í…œ í˜¸ì¶œ
        force_log("Step 3: ì—­/ê³µí•­ íŠ¹í™” ìœ„ì¹˜ ë³´ê°• + ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸ì¶œ")
        
        try:
            # ğŸ”¥ Step 3-1: ì—­/ê³µí•­ ë“± êµ¬ì²´ì  ì¥ì†Œì— ëŒ€í•œ íŠ¹í™” ê²€ìƒ‰
            for i, schedule in enumerate(schedule_data["fixedSchedules"]):
                name = schedule.get("name", "").lower()
                current_location = schedule.get("location", "")
                
                # ì—­, ê³µí•­, í„°ë¯¸ë„ ë“± êµ¬ì²´ì  ì¥ì†Œ ê°ì§€
                if any(keyword in name for keyword in ['ì—­', 'station', 'ê³µí•­', 'airport', 'í„°ë¯¸ë„', 'terminal', 'ëŒ€í•™êµ', 'university']):
                    force_log(f"  ğŸš‰ êµ¬ì²´ì  ì¥ì†Œ ê°ì§€: '{schedule.get('name')}'")
                    
                    # í˜„ì¬ ìœ„ì¹˜ê°€ ë¶€ì •í™•í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ ì¬ê²€ìƒ‰
                    if not current_location or len(current_location) < 10:
                        force_log(f"    ğŸ” '{schedule.get('name')}' ì •í™•í•œ ìœ„ì¹˜ ì¬ê²€ìƒ‰")
                        
                        # ğŸ”¥ Kakao ìš°ì„  ê²€ìƒ‰ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)
                        reference_schedules = []
                        if i > 0:  # ì´ì „ ì¼ì •ì´ ìˆìœ¼ë©´ ì°¸ì¡°ë¡œ í™œìš©
                            reference_schedules = [schedule_data["fixedSchedules"][i-1]]
                        
                        enhanced_schedule = await enhance_single_schedule_triple(
                            schedule, reference_schedules
                        )
                        
                        # ê²°ê³¼ ì ìš©
                        if enhanced_schedule.get("location") and enhanced_schedule["location"] != current_location:
                            schedule["location"] = enhanced_schedule["location"]
                            schedule["latitude"] = enhanced_schedule.get("latitude", schedule.get("latitude"))
                            schedule["longitude"] = enhanced_schedule.get("longitude", schedule.get("longitude"))
                            
                            force_log(f"    âœ… ìœ„ì¹˜ ì—…ë°ì´íŠ¸: {enhanced_schedule['location']}")
                        else:
                            force_log(f"    âš ï¸ ì¬ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            # ğŸ”¥ Step 3-2: ê¸°ì¡´ ì „ì²´ ìœ„ì¹˜ ë³´ê°• ì‹œìŠ¤í…œ í˜¸ì¶œ
            enhanced_data = await asyncio.wait_for(
                enhance_locations_with_triple_api(schedule_data),
                timeout=30
            )
            force_log("âœ… ì „ì²´ ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì™„ë£Œ")
            
        except Exception as e:
            force_log(f"âš ï¸ ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹¤íŒ¨: {e}")
            enhanced_data = schedule_data
        
        # Step 4: ê°•í™”ëœ ìŒì„± ì…ë ¥ ìƒì„±
        force_log("Step 4: ê°•í™”ëœ ìŒì„± ì…ë ¥ ìƒì„±")
        
        enhanced_voice_input = create_enhanced_voice_input(request.schedules)
        
        # Step 5: ğŸ”¥ ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œìŠ¤í…œ
        force_log("Step 5: ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹œìŠ¤í…œ")
        
        # ì‹ì‚¬ ê´€ë ¨ ì¼ì • ì¸ë±ìŠ¤ ì°¾ê¸°
        meal_schedule_indices = []
        for i, schedule in enumerate(enhanced_data.get("fixedSchedules", [])):
            name = schedule.get("name", "").lower()
            if any(word in name for word in ["ì‹ì‚¬", "ë¸ŒëŸ°ì¹˜", "ì ì‹¬", "ì €ë…", "ì¹´í˜", "ì»¤í”¼", "íƒ€ì„"]):
                meal_schedule_indices.append(i)
                force_log(f"  ğŸ½ï¸ ì‹ì‚¬ ì¼ì • ë°œê²¬: ì¸ë±ìŠ¤ {i}, ì´ë¦„ '{schedule.get('name')}'")
        
        if not meal_schedule_indices:
            force_log("  âš ï¸ ì‹ì‚¬ ì¼ì •ì´ ì—†ì–´ì„œ ë‹¨ì¼ ì˜µì…˜ ë°˜í™˜")
            final_result = {"options": [{"optionId": 1, "fixedSchedules": enhanced_data["fixedSchedules"], "flexibleSchedules": []}]}
        else:
            # ğŸ”¥ ê°•ì œë¡œ 5ê°œ ë‹¤ë¥¸ ì˜µì…˜ ìƒì„±
            force_log(f"  ğŸ”¥ {len(meal_schedule_indices)}ê°œ ì‹ì‚¬ ì¼ì •ì— ëŒ€í•´ ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±")
            
            options = []
            used_restaurants = set()
            
            # ì°¸ì¡° ì§€ì—­ ì¶”ì¶œ
            reference_location = "ì„œìš¸"
            for schedule in enhanced_data.get("fixedSchedules", []):
                location = schedule.get("location", "")
                if "ì„œìš¸" in location:
                    reference_location = "ì„œìš¸"
                    break
                elif "ë¶€ì‚°" in location:
                    reference_location = "ë¶€ì‚°"
                    break
                elif "ëŒ€êµ¬" in location:
                    reference_location = "ëŒ€êµ¬"
                    break
            
            force_log(f"  ğŸ“ ì°¸ì¡° ì§€ì—­: {reference_location}")
            
            # 5ê°œ ì˜µì…˜ë³„ ê²€ìƒ‰ ì „ëµ
            search_strategies = [
                {"keywords": ["ë§›ì§‘", "ì¸ê¸°"], "categories": ["í•œì‹", "ì–‘ì‹"]},      # ì˜µì…˜ 1: ì¸ê¸° ë§›ì§‘
                {"keywords": ["í•œì‹", "ì „í†µ"], "categories": ["í•œì‹", "ê°ˆë¹„"]},     # ì˜µì…˜ 2: í•œì‹ ì „í†µ
                {"keywords": ["ë¶„ì‹", "ê¹€ë°¥"], "categories": ["ë¶„ì‹", "ê¹€ë°¥"]},     # ì˜µì…˜ 3: ë¶„ì‹
                {"keywords": ["ì¹´í˜", "ì»¤í”¼"], "categories": ["ì¹´í˜", "ë””ì €íŠ¸"]},   # ì˜µì…˜ 4: ì¹´í˜
                {"keywords": ["ì¹˜í‚¨", "í”¼ì"], "categories": ["ì¹˜í‚¨", "í”¼ì"]}      # ì˜µì…˜ 5: íŒ¨ìŠ¤íŠ¸í‘¸ë“œ
            ]
            
            for option_num in range(5):
                force_log(f"  ğŸ”„ ì˜µì…˜ {option_num + 1} ìƒì„± ì¤‘...")
                
                option_data = copy.deepcopy(enhanced_data)
                option_modified = False
                strategy = search_strategies[option_num]
                
                # ê° ì‹ì‚¬ ì¼ì • ì²˜ë¦¬
                for meal_idx in meal_schedule_indices:
                    if meal_idx < len(option_data["fixedSchedules"]):
                        schedule = option_data["fixedSchedules"][meal_idx]
                        original_name = schedule.get("name", "")
                        
                        force_log(f"    ğŸ½ï¸ ì¼ì • ìˆ˜ì •: '{original_name}' (ì¸ë±ìŠ¤: {meal_idx})")
                        
                        # ğŸ”¥ ì§ì ‘ Kakao API ê²€ìƒ‰
                        search_query = f"{reference_location} {strategy['keywords'][0]}"
                        
                        try:
                            new_restaurant = await search_restaurants_directly(search_query, used_restaurants)
                            
                            if new_restaurant:
                                # ì¼ì • ì—…ë°ì´íŠ¸
                                schedule["name"] = new_restaurant["name"]
                                schedule["location"] = new_restaurant["address"]
                                schedule["latitude"] = new_restaurant["latitude"] 
                                schedule["longitude"] = new_restaurant["longitude"]
                                
                                used_restaurants.add(new_restaurant["name"])
                                option_modified = True
                                
                                force_log(f"      âœ… ìƒˆë¡œìš´ ì‹ë‹¹: {new_restaurant['name']}")
                                force_log(f"      ğŸ“ ì£¼ì†Œ: {new_restaurant['address']}")
                            else:
                                force_log(f"      âš ï¸ ìƒˆë¡œìš´ ì‹ë‹¹ ì°¾ê¸° ì‹¤íŒ¨")
                                
                        except Exception as e:
                            force_log(f"      âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # ê³ ìœ  ID ë¶€ì—¬
                current_time = int(time.time() * 1000)
                for j, schedule in enumerate(option_data["fixedSchedules"]):
                    schedule["id"] = f"{current_time}_{option_num + 1}_{j + 1}"
                
                # ì˜µì…˜ ì¶”ê°€
                options.append({
                    "optionId": option_num + 1,
                    "fixedSchedules": option_data["fixedSchedules"],
                    "flexibleSchedules": option_data.get("flexibleSchedules", [])
                })
                
                force_log(f"    âœ… ì˜µì…˜ {option_num + 1} ì™„ì„± (ìˆ˜ì •ë¨: {option_modified})")
            
            final_result = {"options": options}
            force_log(f"ğŸ‰ ê°•ì œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ: {len(options)}ê°œ")
        
        # Step 6: ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ê²€ìƒ‰
        force_log("Step 6: ê²°ê³¼ í’ˆì§ˆ ê²€ì¦ ë° ë³´ê°•")
        
        option_count = len(final_result.get('options', []))
        force_log(f"ì´ˆê¸° ì˜µì…˜ ìˆ˜: {option_count}ê°œ")
        
        # ì˜µì…˜ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ëª¨ë‘ ë™ì¼í•˜ë©´ ì¶”ê°€ ê²€ìƒ‰
        if option_count < 5:
            force_log(f"ğŸ”„ ì˜µì…˜ ë¶€ì¡± ({option_count}ê°œ), ì¶”ê°€ ìƒì„± ì‹œë„")
            
            # ë¸Œëœë“œ ì‹œìŠ¤í…œë„ ì‹œë„
            try:
                optimizer = DynamicRouteOptimizer(KAKAO_REST_API_KEY)
                additional_result = await optimizer.create_multiple_options(enhanced_data, enhanced_voice_input)
                
                if len(additional_result.get("options", [])) > option_count:
                    force_log("âœ… ë™ì  ì‹œìŠ¤í…œìœ¼ë¡œ ë” ë§ì€ ì˜µì…˜ ìƒì„±ë¨")
                    final_result = additional_result
                
            except Exception as e:
                force_log(f"âš ï¸ ì¶”ê°€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # Step 7: ê° ì˜µì…˜ì˜ í’ˆì§ˆ ê²€ì¦ ë° ë¡œê¹…
        force_log("Step 7: ìµœì¢… ê²°ê³¼ í’ˆì§ˆ ê²€ì¦")
        
        final_option_count = len(final_result.get('options', []))
        force_log(f"ìµœì¢… ì˜µì…˜ ìˆ˜: {final_option_count}ê°œ")
        
        # ê° ì˜µì…˜ì˜ ë‹¤ì–‘ì„± ì²´í¬
        unique_locations = set()
        unique_names = set()
        
        for i, option in enumerate(final_result.get('options', [])):
            force_log(f"ì˜µì…˜ {i+1} í’ˆì§ˆ ê²€ì¦:")
            
            for j, schedule in enumerate(option.get('fixedSchedules', [])):
                name = schedule.get('name', 'N/A')
                location = schedule.get('location', 'N/A')
                
                force_log(f"  ì¼ì • {j+1}: '{name}' @ '{location[:50]}...'")
                
                # ì‹ì‚¬ ê´€ë ¨ ì¼ì •ì˜ ë‹¤ì–‘ì„± ì²´í¬
                if any(word in name.lower() for word in ["ì‹ì‚¬", "ë¸ŒëŸ°ì¹˜", "ì ì‹¬", "ì €ë…", "ì¹´í˜"]):
                    unique_locations.add(location)
                    unique_names.add(name)
        
        force_log(f"ğŸ“Š ë‹¤ì–‘ì„± ë¶„ì„: ê³ ìœ  ìœ„ì¹˜ {len(unique_locations)}ê°œ, ê³ ìœ  ì´ë¦„ {len(unique_names)}ê°œ")
        
        # Step 8: ì›ë³¸ êµ¬ì¡° ë³´ì¡´
        force_log("Step 8: ì›ë³¸ êµ¬ì¡° ë³´ì¡´")
        
        for i, option in enumerate(final_result.get("options", [])):
            for j, schedule in enumerate(option.get("fixedSchedules", [])):
                if j < len(request.schedules):
                    original = request.schedules[j]
                    
                    # ì›ë³¸ì˜ ì‹œê°„ ì •ë³´ ë³´ì¡´
                    for time_field in ["startTime", "endTime", "duration"]:
                        if time_field in original:
                            schedule[time_field] = original[time_field]
                    
                    # ì›ë³¸ì˜ ìš°ì„ ìˆœìœ„ ë³´ì¡´
                    if "priority" in original:
                        schedule["priority"] = original["priority"]
        
        force_log("=== ê°•í™”ëœ ë‹¤ì¤‘ ì˜µì…˜ ì‹œìŠ¤í…œ ì™„ë£Œ ===")
        return UnicodeJSONResponse(content=final_result, status_code=200)
        
    except Exception as e:
        force_log(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        import traceback
        force_log(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        # ìµœì¢… í´ë°±
        fallback_options = []
        current_time = int(time.time() * 1000)
        
        for i in range(5):
            schedules_copy = copy.deepcopy(request.schedules)
            
            for j, schedule in enumerate(schedules_copy):
                schedule["id"] = f"{current_time}_fallback_{i + 1}_{j + 1}"
            
            fallback_options.append({
                "optionId": i + 1,
                "fixedSchedules": schedules_copy,
                "flexibleSchedules": []
            })
        
        return UnicodeJSONResponse(content={"options": fallback_options}, status_code=200)
# ì„œë²„ ì‹œì‘
if __name__ == "__main__":
    import uvicorn
    
    # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì„œë²„ ì‹œì‘
    uvicorn.run(
        "app:app", 
        host="0.0.0.0", 
        port=8083, 
        reload=True,
        # í•œê¸€ ì§€ì›ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        access_log=True,
        log_config={
            "version": 1,
            "disable_existing_loggers": False,
            "formatters": {
                "default": {
                    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                },
            },
            "handlers": {
                "default": {
                    "formatter": "default",
                    "class": "logging.StreamHandler",
                    "stream": "ext://sys.stdout",
                },
            },
            "root": {
                "level": "INFO",
                "handlers": ["default"],
            },
        }
    )