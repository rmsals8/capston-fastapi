import logging
import asyncio
import copy
import sys
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from typing import Dict, List, Any, Optional
import os
import json
import re
import time
import datetime
from dotenv import load_dotenv
import aiohttp
import math
from openai import OpenAI

# ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ ì„í¬íŠ¸
from scheduler.utils import detect_and_resolve_time_conflicts
from scheduler import (
    create_enhancement_chain,
    apply_time_inference,
    apply_priorities,
    enhance_schedule_with_relationships,
    parse_datetime,
    generate_multiple_options  
)

 
# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),  # ì½˜ì†” ì¶œë ¥ ëª…ì‹œ
        logging.StreamHandler(sys.stderr)   # ì—ëŸ¬ë„ í™•ì‹¤íˆ ì¶œë ¥
    ]
)

# ëª¨ë“  ë¡œê±° ë ˆë²¨ ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ë‹¤ë¥¸ ëª¨ë“ˆë“¤ë„ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
scheduler_logger = logging.getLogger('multiple_options')
scheduler_logger.setLevel(logging.INFO)

relationship_logger = logging.getLogger('relationship_analyzer')
relationship_logger.setLevel(logging.INFO)

priority_logger = logging.getLogger('priority_analyzer')
priority_logger.setLevel(logging.INFO)

time_logger = logging.getLogger('time_inference')
time_logger.setLevel(logging.INFO)

utils_logger = logging.getLogger('scheduler.utils')
utils_logger.setLevel(logging.INFO)

# ë¡œê·¸ í…ŒìŠ¤íŠ¸
logger.info("ğŸ”¥ ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
logger.info(f"   í˜„ì¬ ë¡œê·¸ ë ˆë²¨: {logger.level}")
logger.info(f"   í•¸ë“¤ëŸ¬ ìˆ˜: {len(logger.handlers)}")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì „ì— ë¡œê·¸
logger.info("ğŸ“ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹œì‘")
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
# API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") 
GOOGLE_MAPS_API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")
KAKAO_REST_API_KEY = os.getenv("KAKAO_REST_API_KEY", "357d3401893dc5c9cbefc83bb65df4ee")
FOURSQUARE_API_KEY = os.getenv("FOURSQUARE_API_KEY", "fsq3VpVQLn5hZptfpIHLogZHRb7vAbteiSkiUlZT4QvpC8U=")

if not OPENAI_API_KEY:
    logger.error("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    raise ValueError("OPENAI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="3ì¤‘ API ì •í™•í•œ ì£¼ì†Œ ê²€ìƒ‰ ì¼ì • ì¶”ì¶œ API", version="3.0.0")

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í•œêµ­ ì§€ì—­ ì •ë³´
KOREA_REGIONS = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": {"ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
               "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
               "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"},
    "ë¶€ì‚°ê´‘ì—­ì‹œ": {"ê°•ì„œêµ¬", "ê¸ˆì •êµ¬", "ê¸°ì¥êµ°", "ë‚¨êµ¬", "ë™êµ¬", "ë™ë˜êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë¶êµ¬", "ì‚¬ìƒêµ¬",
               "ì‚¬í•˜êµ¬", "ì„œêµ¬", "ìˆ˜ì˜êµ¬", "ì—°ì œêµ¬", "ì˜ë„êµ¬", "ì¤‘êµ¬", "í•´ìš´ëŒ€êµ¬"},
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": {"ë‚¨êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬", "ìˆ˜ì„±êµ¬", "ì¤‘êµ¬"},
    "ì¸ì²œê´‘ì—­ì‹œ": {"ê°•í™”êµ°", "ê³„ì–‘êµ¬", "ë‚¨ë™êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ë¶€í‰êµ¬", "ì„œêµ¬", "ì—°ìˆ˜êµ¬", "ì˜¹ì§„êµ°", "ì¤‘êµ¬"},
    "ê´‘ì£¼ê´‘ì—­ì‹œ": {"ê´‘ì‚°êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬"},
    "ëŒ€ì „ê´‘ì—­ì‹œ": {"ëŒ€ë•êµ¬", "ë™êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ì¤‘êµ¬"},
    "ìš¸ì‚°ê´‘ì—­ì‹œ": {"ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°", "ì¤‘êµ¬"},
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {"ì„¸ì¢…ì‹œ"},
    "ê²½ê¸°ë„": {"ê°€í‰êµ°", "ê³ ì–‘ì‹œ", "ê³¼ì²œì‹œ", "ê´‘ëª…ì‹œ", "ê´‘ì£¼ì‹œ", "êµ¬ë¦¬ì‹œ", "êµ°í¬ì‹œ", "ê¹€í¬ì‹œ", "ë‚¨ì–‘ì£¼ì‹œ",
             "ë™ë‘ì²œì‹œ", "ë¶€ì²œì‹œ", "ì„±ë‚¨ì‹œ", "ìˆ˜ì›ì‹œ", "ì‹œí¥ì‹œ", "ì•ˆì‚°ì‹œ", "ì•ˆì„±ì‹œ", "ì•ˆì–‘ì‹œ", "ì–‘ì£¼ì‹œ",
             "ì–‘í‰êµ°", "ì—¬ì£¼ì‹œ", "ì—°ì²œêµ°", "ì˜¤ì‚°ì‹œ", "ìš©ì¸ì‹œ", "ì˜ì™•ì‹œ", "ì˜ì •ë¶€ì‹œ", "ì´ì²œì‹œ", "íŒŒì£¼ì‹œ",
             "í‰íƒì‹œ", "í¬ì²œì‹œ", "í•˜ë‚¨ì‹œ", "í™”ì„±ì‹œ"},
    "ê°•ì›íŠ¹ë³„ìì¹˜ë„": {"ê°•ë¦‰ì‹œ", "ê³ ì„±êµ°", "ë™í•´ì‹œ", "ì‚¼ì²™ì‹œ", "ì†ì´ˆì‹œ", "ì–‘êµ¬êµ°", "ì–‘ì–‘êµ°", "ì˜ì›”êµ°", "ì›ì£¼ì‹œ",
                  "ì¸ì œêµ°", "ì •ì„ êµ°", "ì² ì›êµ°", "ì¶˜ì²œì‹œ", "íƒœë°±ì‹œ", "í‰ì°½êµ°", "í™ì²œêµ°", "í™”ì²œêµ°", "íš¡ì„±êµ°"},
    "ì¶©ì²­ë¶ë„": {"ê´´ì‚°êµ°", "ë‹¨ì–‘êµ°", "ë³´ì€êµ°", "ì˜ë™êµ°", "ì˜¥ì²œêµ°", "ìŒì„±êµ°", "ì œì²œì‹œ", "ì¦í‰êµ°", "ì§„ì²œêµ°", "ì²­ì£¼ì‹œ", "ì¶©ì£¼ì‹œ"},
    "ì¶©ì²­ë‚¨ë„": {"ê³„ë£¡ì‹œ", "ê³µì£¼ì‹œ", "ê¸ˆì‚°êµ°", "ë…¼ì‚°ì‹œ", "ë‹¹ì§„ì‹œ", "ë³´ë ¹ì‹œ", "ë¶€ì—¬êµ°", "ì„œì‚°ì‹œ", "ì„œì²œêµ°",
             "ì•„ì‚°ì‹œ", "ì˜ˆì‚°êµ°", "ì²œì•ˆì‹œ", "ì²­ì–‘êµ°", "íƒœì•ˆêµ°", "í™ì„±êµ°"},
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„": {"ê³ ì°½êµ°", "êµ°ì‚°ì‹œ", "ê¹€ì œì‹œ", "ë‚¨ì›ì‹œ", "ë¬´ì£¼êµ°", "ë¶€ì•ˆêµ°", "ìˆœì°½êµ°", "ì™„ì£¼êµ°",
                  "ìµì‚°ì‹œ", "ì„ì‹¤êµ°", "ì¥ìˆ˜êµ°", "ì „ì£¼ì‹œ", "ì •ìì‹œ", "ì§„ì•ˆêµ°"},
    "ì „ë¼ë‚¨ë„": {"ê°•ì§„êµ°", "ê³ í¥êµ°", "ê³¡ì„±êµ°", "ê´‘ì–‘ì‹œ", "êµ¬ë¡€êµ°", "ë‚˜ì£¼ì‹œ", "ë‹´ì–‘êµ°", "ëª©í¬ì‹œ", "ë¬´ì•ˆêµ°",
             "ë³´ì„±êµ°", "ìˆœì²œì‹œ", "ì‹ ì•ˆêµ°", "ì—¬ìˆ˜ì‹œ", "ì˜ê´‘êµ°", "ì˜ì•”êµ°", "ì™„ë„êµ°", "ì¥ì„±êµ°", "ì¥í¥êµ°",
             "ì§„ë„êµ°", "í•¨í‰êµ°", "í•´ë‚¨êµ°", "í™”ìˆœêµ°"},
    "ê²½ìƒë¶ë„": {"ê²½ì‚°ì‹œ", "ê²½ì£¼ì‹œ", "ê³ ë ¹êµ°", "êµ¬ë¯¸ì‹œ", "êµ°ìœ„êµ°", "ê¹€ì²œì‹œ", "ë¬¸ê²½ì‹œ", "ë´‰í™”êµ°", "ìƒì£¼ì‹œ",
             "ì„±ì£¼êµ°", "ì•ˆë™ì‹œ", "ì˜ë•êµ°", "ì˜ì–‘êµ°", "ì˜ì£¼ì‹œ", "ì˜ì²œì‹œ", "ì˜ˆì²œêµ°", "ìš¸ë¦‰êµ°", "ìš¸ì§„êµ°",
             "ì˜ì„±êµ°", "ì²­ë„êµ°", "ì²­ì†¡êµ°", "ì¹ ê³¡êµ°", "í¬í•­ì‹œ"},
    "ê²½ìƒë‚¨ë„": {"ê±°ì œì‹œ", "ê±°ì°½êµ°", "ê³ ì„±êµ°", "ê¹€í•´ì‹œ", "ë‚¨í•´êµ°", "ë°€ì–‘ì‹œ", "ì‚¬ì²œì‹œ", "ì‚°ì²­êµ°", "ì–‘ì‚°ì‹œ",
             "ì˜ë ¹êµ°", "ì§„ì£¼ì‹œ", "ì°½ë…•êµ°", "ì°½ì›ì‹œ", "í†µì˜ì‹œ", "í•˜ë™êµ°", "í•¨ì•ˆêµ°", "í•¨ì–‘êµ°", "í•©ì²œêµ°"},
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {"ì„œê·€í¬ì‹œ", "ì œì£¼ì‹œ"}
}
def clean_korean_text(text: str) -> str:
    import re
    cleaned = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,()-]', '', text)
    return cleaned.strip()
# ----- ëª¨ë¸ ì •ì˜ -----
class ScheduleRequest(BaseModel):
    voice_input: str
@app.post("/new-extract-schedule")
async def new_extract_schedule(request: ScheduleRequest):
    """ğŸ†• ì™„ì „íˆ ìƒˆë¡œìš´ ë‹¤ì¤‘ ì˜µì…˜ ì¼ì • ì¶”ì¶œ ì—”ë“œí¬ì¸íŠ¸"""
    from datetime import datetime
    import sys
    
    print("ğŸ”¥ğŸ”¥ğŸ”¥ NEW EXTRACT SCHEDULE ì‹œì‘! ğŸ”¥ğŸ”¥ğŸ”¥")
    print(f"ğŸ”¥ í˜„ì¬ ì‹œê°„: {datetime.now()}")
    print(f"ğŸ”¥ ì…ë ¥ ë°ì´í„°: {request.voice_input}")
    print(f"ğŸ”¥ ì…ë ¥ ê¸¸ì´: {len(request.voice_input)}ì")
    sys.stdout.flush()
    
    logger.info("ğŸ†• NEW EXTRACT SCHEDULE ì‹œì‘!")
    logger.info(f"ì…ë ¥: {request.voice_input}")
    
    try:
        print("ğŸ”¥ Step 1: LLM ì²´ì¸ ìƒì„± ì‹œì‘")
        chain = create_schedule_chain()
        print("ğŸ”¥ Step 1: LLM ì²´ì¸ ìƒì„± ì™„ë£Œ")
        
        print("ğŸ”¥ Step 2: LLM í˜¸ì¶œ ì‹œì‘")
        result = await asyncio.wait_for(
            run_in_executor(lambda: chain.invoke({"input": request.voice_input})),
            timeout=20
        )
        print(f"ğŸ”¥ Step 2: LLM ì‘ë‹µ ìˆ˜ì‹ , íƒ€ì…: {type(result)}")
        print(f"ğŸ”¥ Step 2: LLM ì‘ë‹µ ë‚´ìš©: {str(result)[:200]}...")
        
        print("ğŸ”¥ Step 3: ê²°ê³¼ íŒŒì‹±")
        if isinstance(result, dict):
            schedule_data = result
        else:
            schedule_data = safe_parse_json(str(result))
        
        fixed_count = len(schedule_data.get('fixedSchedules', []))
        flexible_count = len(schedule_data.get('flexibleSchedules', []))
        print(f"ğŸ”¥ Step 3: íŒŒì‹± ì™„ë£Œ - ê³ ì •: {fixed_count}ê°œ, ìœ ì—°: {flexible_count}ê°œ")
        
        # ê°„ë‹¨í•œ ë‹¤ì¤‘ ì˜µì…˜ ì‘ë‹µ ìƒì„± (ë³µì¡í•œ ë¡œì§ ì—†ì´)
        print("ğŸ”¥ Step 4: ê°„ë‹¨í•œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±")
        
        simple_options = []
        for i in range(5):
            option = {
                "optionId": i + 1,
                "fixedSchedules": schedule_data.get('fixedSchedules', []),
                "flexibleSchedules": schedule_data.get('flexibleSchedules', [])
            }
            simple_options.append(option)
        
        final_result = {"options": simple_options}
        
        print(f"ğŸ”¥ Step 4: ê°„ë‹¨í•œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ - {len(simple_options)}ê°œ ì˜µì…˜")
        print("ğŸ”¥ğŸ”¥ğŸ”¥ NEW EXTRACT SCHEDULE ì™„ë£Œ! ğŸ”¥ğŸ”¥ğŸ”¥")
        
        return UnicodeJSONResponse(content=final_result, status_code=200)
        
    except Exception as e:
        print(f"ğŸ”¥ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ğŸ”¥ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        
        error_result = {
            "options": [
                {
                    "optionId": 1,
                    "fixedSchedules": [],
                    "flexibleSchedules": []
                }
            ]
        }
        
        print("ğŸ”¥ ì˜¤ë¥˜ ì‘ë‹µ ë°˜í™˜")
        return UnicodeJSONResponse(content=error_result, status_code=200)
class UnicodeJSONResponse(JSONResponse):
    def render(self, content) -> bytes:
        return json.dumps(
            content,
            ensure_ascii=False,  # ğŸ‘ˆ í•µì‹¬! í•œê¸€ì„ ìœ ë‹ˆì½”ë“œ ê·¸ëŒ€ë¡œ ì¶œë ¥
            separators=(',', ':'),
            indent=None
        ).encode('utf-8')  # ğŸ‘ˆ UTF-8ë¡œ ì¸ì½”ë”©
    
class FixedSchedule(BaseModel):
    id: str
    name: str
    type: str = "FIXED"
    duration: int = 60
    priority: float  = 1.0
    location: str = ""
    latitude: float = 37.5665
    longitude: float = 126.9780
    startTime: str
    endTime: str

class FlexibleSchedule(BaseModel):
    id: str
    name: str
    type: str = "FLEXIBLE"
    duration: int = 60
    priority: float  = 3.0
    location: str = ""
    latitude: float = 37.5665
    longitude: float = 126.9780

class ExtractScheduleResponse(BaseModel):
    fixedSchedules: List[FixedSchedule] = []
    flexibleSchedules: List[FlexibleSchedule] = []

class LocationAnalysis(BaseModel):
    place_name: str
    region: str
    district: str
    category: str
    search_keywords: List[str]

class PlaceResult(BaseModel):
    name: str
    address: str
    latitude: float
    longitude: float
    source: str  # foursquare, kakao, google
    rating: Optional[float] = None


def safe_parse_json(json_str):
    """ì•ˆì „í•œ JSON íŒŒì‹± - í•œê¸€ ì§€ì›"""
    try:
        if isinstance(json_str, str):
            # í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
            return json.loads(json_str, strict=False)
        else:
            return json_str
    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ (í•œê¸€ í¬í•¨): {str(e)}")
        return {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }

def normalize_priorities(schedules_data: Dict[str, Any]) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì •ìˆ˜ë¡œ ì •ê·œí™”"""
    logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ìˆ˜ ë³€í™˜ ì‹œì‘")
    
    all_schedules = []
    all_schedules.extend(schedules_data.get("fixedSchedules", []))
    all_schedules.extend(schedules_data.get("flexibleSchedules", []))
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    all_schedules.sort(key=lambda s: s.get("priority", 999))
    
    # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ë¡œ ì¬í• ë‹¹
    for i, schedule in enumerate(all_schedules):
        old_priority = schedule.get("priority", "ì—†ìŒ")
        new_priority = i + 1
        schedule["priority"] = new_priority
        logger.info(f"ìš°ì„ ìˆœìœ„ ì •ê·œí™”: '{schedule.get('name', '')}' {old_priority} â†’ {new_priority}")
    
    # ë‹¤ì‹œ ë¶„ë¥˜
    fixed_schedules = [s for s in all_schedules if s.get("type") == "FIXED" and "startTime" in s]
    flexible_schedules = [s for s in all_schedules if s.get("type") != "FIXED" or "startTime" not in s]
    
    logger.info(f"âœ… ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì™„ë£Œ: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
    
    return {
        "fixedSchedules": fixed_schedules,
        "flexibleSchedules": flexible_schedules
    }
# ----- ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ -----
class AddressQualityChecker:
    """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
    
    @staticmethod
    def is_complete_address(address: str) -> bool:
        """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦"""
        if not address or address.strip() == "":
            return False
        
        # ê¸°ë³¸ ê²€ì¦
        address_lower = address.lower()
        
        # 1. ë„ˆë¬´ ì§§ì€ ì£¼ì†Œ (ë‹¨ì–´ 2ê°œ ì´í•˜)
        words = [word for word in address.split() if len(word) > 1]
        if len(words) <= 2:
            logger.info(f"âŒ ì£¼ì†Œ ë„ˆë¬´ ì§§ìŒ: {address} ({len(words)}ê°œ ë‹¨ì–´)")
            return False
        
        # 2. ëª¨í˜¸í•œ í‘œí˜„ ì²´í¬
        vague_terms = ["ê·¼ì²˜", "ì¸ê·¼", "ì£¼ë³€", "ê·¼ë°©", "ë¶€ê·¼", "ì¼ëŒ€", "ë™ë„¤"]
        if any(term in address for term in vague_terms):
            logger.info(f"âŒ ëª¨í˜¸í•œ ì£¼ì†Œ í‘œí˜„: {address}")
            return False
        
        # 3. í•œêµ­ ì£¼ì†Œ í•„ìˆ˜ ìš”ì†Œ ì²´í¬
        korean_regions = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        has_region = any(region in address for region in korean_regions)
        
        # 4. ìƒì„¸ ì£¼ì†Œ ìš”ì†Œ ì²´í¬ (êµ¬/ì‹œ/êµ° + ë™/ì/ë©´)
        detail_keywords = ["êµ¬", "ì‹œ", "êµ°", "ë™", "ì", "ë©´", "ë¡œ", "ê¸¸", "ê°€"]
        has_detail = any(keyword in address for keyword in detail_keywords)
        
        # 5. ê±´ë¬¼ëª…ì´ë‚˜ ë²ˆì§€ìˆ˜ ì²´í¬
        import re
        has_number = bool(re.search(r'\d+', address))
        
        quality_score = has_region + has_detail + has_number
        is_complete = quality_score >= 2  # 3ì  ë§Œì ì— 2ì  ì´ìƒ
        
        logger.info(f"ğŸ“Š ì£¼ì†Œ í’ˆì§ˆ ì ìˆ˜: {quality_score}/3 - {address}")
        logger.info(f"   ì§€ì—­í¬í•¨: {has_region}, ìƒì„¸ìš”ì†Œ: {has_detail}, ë²ˆì§€í¬í•¨: {has_number}")
        logger.info(f"   ì™„ì „ì„±: {'âœ… ì™„ì „' if is_complete else 'âŒ ë¶ˆì™„ì „'}")
        
        return is_complete
    
    @staticmethod
    def get_category_keywords(place_name: str) -> List[str]:
        """ì¥ì†Œëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        name_lower = place_name.lower()
        keywords = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        category_map = {
            "ì¹´í˜": ["ì¹´í˜", "ì»¤í”¼", "coffee", "dessert", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"],
            "ì‹ë‹¹": ["ì‹ë‹¹", "ë§›ì§‘", "ìŒì‹ì ", "ë ˆìŠ¤í† ë‘", "restaurant", "food"],
            "íšŒì˜": ["íšŒì˜ì‹¤", "ì˜¤í”¼ìŠ¤", "ì‚¬ë¬´ì‹¤", "ì»¨í¼ëŸ°ìŠ¤", "meeting"],
            "íšŒì‹": ["ìˆ ì§‘", "bar", "pub", "í˜¸í”„", "ì´ìì¹´ì•¼", "restaurant"],
            "ì‡¼í•‘": ["ì‡¼í•‘ëª°", "ë°±í™”ì ", "ë§ˆíŠ¸", "ìƒì ", "mall"],
            "ìˆ™ë°•": ["í˜¸í…”", "ëª¨í…”", "íœì…˜", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤", "ë¦¬ì¡°íŠ¸"]
        }
        
        for category, words in category_map.items():
            if any(word in name_lower for word in words):
                keywords.extend(words)
                logger.info(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ '{category}' ê°ì§€: {words}")
                break
        
        # ê¸°ë³¸ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¥ì†Œëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if not keywords:
            keywords = [place_name]
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°
class TripleLocationSearchService:
    """Foursquare + Kakao + Google 3ì¤‘ ìœ„ì¹˜ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    # app.pyì˜ TripleLocationSearchService í´ë˜ìŠ¤ ë‚´ë¶€
    @staticmethod
    async def analyze_location_with_gpt(text: str, reference_location: Optional[str] = None, route_context: Optional[str] = None) -> LocationAnalysis:
        """GPTë¡œ ì •í™•í•œ ì§€ì—­ê³¼ ì¥ì†Œ ë¶„ì„ - ê²½ë¡œ ë§¥ë½ê³¼ ì°¸ì¡° ìœ„ì¹˜ ì¶”ê°€"""
        
        # setì„ listë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
        korea_regions_list = {region: list(districts) for region, districts in KOREA_REGIONS.items()}
        regions_text = json.dumps(korea_regions_list, ensure_ascii=False, indent=2)
        
        # ì°¸ì¡° ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
        reference_context = ""
        if reference_location:
            reference_context = f"\nì°¸ì¡° ìœ„ì¹˜ (ì´ì „ ì¼ì •): {reference_location}"
            reference_context += "\n'ê·¼ì²˜', 'ì£¼ë³€' ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ì´ ì°¸ì¡° ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”."
        
        # ğŸ”¥ ê²½ë¡œ ë§¥ë½ ì¶”ê°€ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        route_context_text = ""
        if route_context:
            route_context_text = f"\nê²½ë¡œ ì •ë³´: {route_context}"
            route_context_text += "\n'ì¤‘ê°„ì—' ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ê²½ë¡œìƒì˜ ì¤‘ê°„ ì§€ì ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”."
            
            # ê²½ë¡œì—ì„œ ì§€ì—­ ì¶”ì¶œí•˜ì—¬ ì¤‘ê°„ ì§€ì  ì§€ì—­ ê²°ì •
            import re
            route_pattern = r'(.+?)ì—ì„œ\s*(.+?)ê¹Œì§€'
            match = re.search(route_pattern, route_context)
            if match:
                start_place = match.group(1).strip()
                end_place = match.group(2).strip()
                
                # ì¶œë°œì§€ì™€ ë„ì°©ì§€ ì‚¬ì´ì˜ ì¤‘ê°„ ì§€ì—­ ê²°ì •
                start_region = None
                end_region = None
                
                # ì„œìš¸ ì§€ì—­ ë§¤í•‘
                seoul_areas = {
                    "ì‹ ê¸¸ì—­": "ì˜ë“±í¬êµ¬",
                    "ì„œìš¸ì—­": "ì¤‘êµ¬",
                    "ê°•ë‚¨ì—­": "ê°•ë‚¨êµ¬",
                    "í™ëŒ€": "ë§ˆí¬êµ¬",
                    "ì´íƒœì›": "ìš©ì‚°êµ¬",
                    "ëª…ë™": "ì¤‘êµ¬",
                    "ì ì‹¤": "ì†¡íŒŒêµ¬",
                    "ê°•ë™": "ê°•ë™êµ¬"
                }
                
                for place, district in seoul_areas.items():
                    if place in start_place:
                        start_region = district
                    if place in end_place:
                        end_region = district
                
                # ì¤‘ê°„ ì§€ì—­ ê²°ì • ë¡œì§
                if start_region and end_region:
                    # ì˜ë“±í¬êµ¬ â†’ ì¤‘êµ¬ ê²½ë¡œë©´ ì¤‘ê°„ì€ ìš©ì‚°êµ¬ ë˜ëŠ” ë§ˆí¬êµ¬
                    if start_region == "ì˜ë“±í¬êµ¬" and end_region == "ì¤‘êµ¬":
                        route_context_text += f"\nì¤‘ê°„ ì§€ì  ì¶”ì²œ ì§€ì—­: ìš©ì‚°êµ¬, ë§ˆí¬êµ¬ (ê²½ë¡œìƒ ì¤‘ê°„)"
                    elif start_region == "ì¤‘êµ¬" and end_region == "ê°•ë‚¨êµ¬":
                        route_context_text += f"\nì¤‘ê°„ ì§€ì  ì¶”ì²œ ì§€ì—­: ìš©ì‚°êµ¬, ì„œì´ˆêµ¬ (ê²½ë¡œìƒ ì¤‘ê°„)"
                    else:
                        route_context_text += f"\nì¤‘ê°„ ì§€ì  ì¶”ì²œ ì§€ì—­: {start_region}ê³¼ {end_region} ì‚¬ì´"

        prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ì˜ ì •í™•í•œ ì§€ì—­ ì •ë³´ì™€ ì¥ì†Œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

    í…ìŠ¤íŠ¸: "{text}"{reference_context}{route_context_text}

    í•œêµ­ ì§€ì—­ ì •ë³´:
    {regions_text}

    **ì¤‘ìš” ë¶„ì„ ê·œì¹™**: 
    1. "ê·¼ì²˜", "ì£¼ë³€" ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ì°¸ì¡° ìœ„ì¹˜ì™€ ê°™ì€ ì§€ì—­ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    2. "ì¤‘ê°„ì—" ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ê²½ë¡œìƒì˜ ì¤‘ê°„ ì§€ì  ì§€ì—­ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”.
    3. ëª¨í˜¸í•œ í‘œí˜„("ì¹´í˜", "ì‹ë‹¹")ë„ ì°¸ì¡° ìœ„ì¹˜ë‚˜ ê²½ë¡œ ê·¼ì²˜ì—ì„œ ê²€ìƒ‰í•˜ë„ë¡ ì§€ì—­ì„ ì„¤ì •í•˜ì„¸ìš”.
    4. êµ¬ì²´ì ì¸ ì¥ì†Œëª…(ì˜ˆ: ìš¸ì‚°ëŒ€í•™êµ, ë¬¸ìˆ˜ì›”ë“œì»µê²½ê¸°ì¥)ì€ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ìš°ì„ í•˜ì„¸ìš”.
    5. ê²½ë¡œ ë§¥ë½ì´ ìˆìœ¼ë©´ ì§€ë¦¬ì ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ì¤‘ê°„ ì§€ì ì„ ì„ íƒí•˜ì„¸ìš”.

    **ì§€ë¦¬ì  íš¨ìœ¨ì„± ê³ ë ¤ì‚¬í•­**:
    - ì‹ ê¸¸ì—­(ì˜ë“±í¬êµ¬) â†’ ì„œìš¸ì—­(ì¤‘êµ¬): ì¤‘ê°„ì€ ìš©ì‚°êµ¬, ë§ˆí¬êµ¬
    - ì„œìš¸ì—­(ì¤‘êµ¬) â†’ ê°•ë‚¨ì—­(ê°•ë‚¨êµ¬): ì¤‘ê°„ì€ ìš©ì‚°êµ¬, ì„œì´ˆêµ¬  
    - ì§€í•˜ì²  ë…¸ì„ ì„ ê³ ë ¤í•œ ì ‘ê·¼ì„± ìš°ì„ 

    JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
    {{
    "place_name": "ì¶”ì¶œëœ ì¥ì†Œëª… (ë§¥ë½ ê³ ë ¤)",
    "region": "ì‹œ/ë„ (ê²½ë¡œë‚˜ ì°¸ì¡° ìœ„ì¹˜ ê³ ë ¤)",
    "district": "ì‹œ/êµ°/êµ¬ (ê²½ë¡œë‚˜ ì°¸ì¡° ìœ„ì¹˜ ê³ ë ¤)",
    "category": "ì¥ì†Œ ì¹´í…Œê³ ë¦¬",
    "search_keywords": ["ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë“¤", "ì§€ì—­ëª…+ì¥ì†Œëª…", "ì¹´í…Œê³ ë¦¬ëª…"],
    "geographical_context": "ì§€ë¦¬ì  ë§¥ë½ ì„¤ëª…"
    }}
    """

        try:
            response = openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì§€ì—­ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê²½ë¡œ ë§¥ë½ê³¼ ì°¸ì¡° ìœ„ì¹˜ë¥¼ ê³ ë ¤í•˜ì—¬ 'ì¤‘ê°„ì—', 'ê·¼ì²˜', 'ì£¼ë³€' í‘œí˜„ì„ ì§€ë¦¬ì ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”. íŠ¹íˆ ì§€í•˜ì²  ë…¸ì„ ê³¼ ì‹¤ì œ ì´ë™ ê²½ë¡œë¥¼ ê³ ë ¤í•œ ì¤‘ê°„ ì§€ì ì„ ì œì•ˆí•˜ì„¸ìš”."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500,  # ë” ìì„¸í•œ ì‘ë‹µì„ ìœ„í•´ í† í° ì¦ê°€
            )

            content = response.choices[0].message.content.strip()
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(content)
            
            # ì‘ë‹µì— geographical_contextê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
            if "geographical_context" not in data:
                data["geographical_context"] = "ê¸°ë³¸ ë¶„ì„"
            
            logger.info(f"ğŸ§  GPT ì§€ì—­ ë¶„ì„ ì™„ë£Œ: {data.get('region')} {data.get('district')} - {data.get('place_name')}")
            logger.info(f"ğŸ—ºï¸ ì§€ë¦¬ì  ë§¥ë½: {data.get('geographical_context')}")
            
            return LocationAnalysis(**data)
            
        except Exception as e:
            logger.error(f"âŒ GPT ì§€ì—­ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            # ì°¸ì¡° ìœ„ì¹˜ë‚˜ ê²½ë¡œ ë§¥ë½ì´ ìˆìœ¼ë©´ ê°™ì€ ì§€ì—­ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
            default_region = "ì„œìš¸íŠ¹ë³„ì‹œ"
            default_district = "ì¤‘êµ¬"
            
            if reference_location:
                # ì°¸ì¡° ìœ„ì¹˜ì—ì„œ ì§€ì—­ ì¶”ì¶œ ì‹œë„
                for region in ["ìš¸ì‚°", "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „"]:
                    if region in reference_location:
                        if region == "ì„œìš¸":
                            default_region = "ì„œìš¸íŠ¹ë³„ì‹œ"
                        else:
                            default_region = f"{region}ê´‘ì—­ì‹œ"
                        break
                
                # êµ¬ ì •ë³´ ì¶”ì¶œ ì‹œë„
                for district in ["ì¤‘êµ¬", "ì˜ë“±í¬êµ¬", "ê°•ë‚¨êµ¬", "ë§ˆí¬êµ¬", "ìš©ì‚°êµ¬"]:
                    if district in reference_location:
                        default_district = district
                        break
            
            elif route_context:
                # ê²½ë¡œ ë§¥ë½ì—ì„œ ì§€ì—­ ì¶”ì¶œ
                if "ì„œìš¸" in route_context:
                    default_region = "ì„œìš¸íŠ¹ë³„ì‹œ"
                    if "ì˜ë“±í¬" in route_context and "ì¤‘êµ¬" in route_context:
                        default_district = "ìš©ì‚°êµ¬"  # ì¤‘ê°„ ì§€ì 
            
            logger.info(f"ğŸ”„ ê¸°ë³¸ê°’ ì‚¬ìš©: {default_region} {default_district}")
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return LocationAnalysis(
                place_name=text,
                region=default_region,
                district=default_district,
                category="ì¥ì†Œ",
                search_keywords=[f"{default_district} {text}", text],
                geographical_context="ê¸°ë³¸ê°’ ì ìš©"
            )

    @staticmethod
    async def search_foursquare(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """3ìˆœìœ„: Foursquare API ê²€ìƒ‰ - ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ê°•í™”"""
        if not FOURSQUARE_API_KEY:
            logger.warning("âŒ Foursquare API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 3ìˆœìœ„ Foursquare ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            # ì§€ì—­ ì¢Œí‘œ (ê¸°ì¡´ê³¼ ë™ì¼)
            region_coords = {
                # íŠ¹ë³„ì‹œÂ·ê´‘ì—­ì‹œ
                "ì„œìš¸íŠ¹ë³„ì‹œ": {"lat": 37.5665, "lng": 126.9780},
                "ë¶€ì‚°ê´‘ì—­ì‹œ": {"lat": 35.1796, "lng": 129.0756},
                "ëŒ€êµ¬ê´‘ì—­ì‹œ": {"lat": 35.8714, "lng": 128.6014},
                "ì¸ì²œê´‘ì—­ì‹œ": {"lat": 37.4563, "lng": 126.7052},
                "ê´‘ì£¼ê´‘ì—­ì‹œ": {"lat": 35.1595, "lng": 126.8526},
                "ëŒ€ì „ê´‘ì—­ì‹œ": {"lat": 36.3504, "lng": 127.3845},
                "ìš¸ì‚°ê´‘ì—­ì‹œ": {"lat": 35.5384, "lng": 129.3114},
                
                # íŠ¹ë³„ìì¹˜ì‹œÂ·íŠ¹ë³„ìì¹˜ë„
                "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {"lat": 36.4800, "lng": 127.2890},
                "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {"lat": 33.4996, "lng": 126.5312},
                
                # ê²½ê¸°ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ê¸°ë„": {"lat": 37.4138, "lng": 127.5183},
                "ê°€í‰êµ°": {"lat": 37.8313, "lng": 127.5109},
                "ê³ ì–‘ì‹œ": {"lat": 37.6584, "lng": 126.8320},
                "ê³¼ì²œì‹œ": {"lat": 37.4292, "lng": 126.9876},
                "ê´‘ëª…ì‹œ": {"lat": 37.4784, "lng": 126.8664},
                "ê´‘ì£¼ì‹œ": {"lat": 37.4297, "lng": 127.2550},
                "êµ¬ë¦¬ì‹œ": {"lat": 37.5943, "lng": 127.1296},
                "êµ°í¬ì‹œ": {"lat": 37.3614, "lng": 126.9350},
                "ê¹€í¬ì‹œ": {"lat": 37.6150, "lng": 126.7158},
                "ë‚¨ì–‘ì£¼ì‹œ": {"lat": 37.6369, "lng": 127.2165},
                "ë™ë‘ì²œì‹œ": {"lat": 37.9036, "lng": 127.0606},
                "ë¶€ì²œì‹œ": {"lat": 37.5036, "lng": 126.7660},
                "ì„±ë‚¨ì‹œ": {"lat": 37.4201, "lng": 127.1262},
                "ìˆ˜ì›ì‹œ": {"lat": 37.2636, "lng": 127.0286},
                "ì‹œí¥ì‹œ": {"lat": 37.3803, "lng": 126.8030},
                "ì•ˆì‚°ì‹œ": {"lat": 37.3236, "lng": 126.8219},
                "ì•ˆì„±ì‹œ": {"lat": 37.0078, "lng": 127.2797},
                "ì•ˆì–‘ì‹œ": {"lat": 37.3943, "lng": 126.9568},
                "ì–‘ì£¼ì‹œ": {"lat": 37.7853, "lng": 127.0456},
                "ì–‘í‰êµ°": {"lat": 37.4916, "lng": 127.4874},
                "ì—¬ì£¼ì‹œ": {"lat": 37.2982, "lng": 127.6376},
                "ì—°ì²œêµ°": {"lat": 38.0960, "lng": 127.0751},
                "ì˜¤ì‚°ì‹œ": {"lat": 37.1499, "lng": 127.0776},
                "ìš©ì¸ì‹œ": {"lat": 37.2411, "lng": 127.1776},
                "ì˜ì™•ì‹œ": {"lat": 37.3448, "lng": 126.9687},
                "ì˜ì •ë¶€ì‹œ": {"lat": 37.7381, "lng": 127.0339},
                "ì´ì²œì‹œ": {"lat": 37.2724, "lng": 127.4349},
                "íŒŒì£¼ì‹œ": {"lat": 37.7598, "lng": 126.7800},
                "í‰íƒì‹œ": {"lat": 36.9921, "lng": 127.1127},
                "í¬ì²œì‹œ": {"lat": 37.8950, "lng": 127.2003},
                "í•˜ë‚¨ì‹œ": {"lat": 37.5394, "lng": 127.2147},
                "í™”ì„±ì‹œ": {"lat": 37.1996, "lng": 126.8310},
                
                # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°  
                "ê°•ì›íŠ¹ë³„ìì¹˜ë„": {"lat": 37.8228, "lng": 128.1555},
                "ê°•ë¦‰ì‹œ": {"lat": 37.7519, "lng": 128.8761},
                "ê³ ì„±êµ°": {"lat": 38.3806, "lng": 128.4678},
                "ë™í•´ì‹œ": {"lat": 37.5244, "lng": 129.1144},
                "ì‚¼ì²™ì‹œ": {"lat": 37.4501, "lng": 129.1649},
                "ì†ì´ˆì‹œ": {"lat": 38.2070, "lng": 128.5918},
                "ì–‘êµ¬êµ°": {"lat": 38.1065, "lng": 127.9897},
                "ì–‘ì–‘êµ°": {"lat": 38.0759, "lng": 128.6190},
                "ì˜ì›”êµ°": {"lat": 37.1839, "lng": 128.4617},
                "ì›ì£¼ì‹œ": {"lat": 37.3422, "lng": 127.9202},
                "ì¸ì œêµ°": {"lat": 38.0695, "lng": 128.1707},
                "ì •ì„ êµ°": {"lat": 37.3801, "lng": 128.6607},
                "ì² ì›êµ°": {"lat": 38.1465, "lng": 127.3134},
                "ì¶˜ì²œì‹œ": {"lat": 37.8813, "lng": 127.7298},
                "íƒœë°±ì‹œ": {"lat": 37.1641, "lng": 128.9856},
                "í‰ì°½êµ°": {"lat": 37.3708, "lng": 128.3897},
                "í™ì²œêµ°": {"lat": 37.6971, "lng": 127.8888},
                "í™”ì²œêµ°": {"lat": 38.1063, "lng": 127.7082},
                "íš¡ì„±êµ°": {"lat": 37.4916, "lng": 127.9856},
                
                # ì¶©ì²­ë¶ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì¶©ì²­ë¶ë„": {"lat": 36.4919, "lng": 127.7417},
                "ê´´ì‚°êµ°": {"lat": 36.8154, "lng": 127.7874},
                "ë‹¨ì–‘êµ°": {"lat": 36.9845, "lng": 128.3659},
                "ë³´ì€êµ°": {"lat": 36.4894, "lng": 127.7293},
                "ì˜ë™êµ°": {"lat": 36.1750, "lng": 127.7764},
                "ì˜¥ì²œêµ°": {"lat": 36.3061, "lng": 127.5721},
                "ìŒì„±êµ°": {"lat": 36.9433, "lng": 127.6864},
                "ì œì²œì‹œ": {"lat": 37.1326, "lng": 128.1909},
                "ì¦í‰êµ°": {"lat": 36.7848, "lng": 127.5814},
                "ì§„ì²œêµ°": {"lat": 36.8565, "lng": 127.4335},
                "ì²­ì£¼ì‹œ": {"lat": 36.4919, "lng": 127.7417},
                "ì¶©ì£¼ì‹œ": {"lat": 36.9910, "lng": 127.9259},
                
                # ì¶©ì²­ë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì¶©ì²­ë‚¨ë„": {"lat": 36.5184, "lng": 126.8000},
                "ê³„ë£¡ì‹œ": {"lat": 36.2742, "lng": 127.2489},
                "ê³µì£¼ì‹œ": {"lat": 36.4464, "lng": 127.1248},
                "ê¸ˆì‚°êµ°": {"lat": 36.1088, "lng": 127.4881},
                "ë…¼ì‚°ì‹œ": {"lat": 36.1872, "lng": 127.0985},
                "ë‹¹ì§„ì‹œ": {"lat": 36.8934, "lng": 126.6292},
                "ë³´ë ¹ì‹œ": {"lat": 36.3334, "lng": 126.6127},
                "ë¶€ì—¬êµ°": {"lat": 36.2756, "lng": 126.9098},
                "ì„œì‚°ì‹œ": {"lat": 36.7848, "lng": 126.4503},
                "ì„œì²œêµ°": {"lat": 36.0805, "lng": 126.6919},
                "ì•„ì‚°ì‹œ": {"lat": 36.7898, "lng": 127.0019},
                "ì˜ˆì‚°êµ°": {"lat": 36.6826, "lng": 126.8503},
                "ì²œì•ˆì‹œ": {"lat": 36.8151, "lng": 127.1139},
                "ì²­ì–‘êµ°": {"lat": 36.4590, "lng": 126.8025},
                "íƒœì•ˆêµ°": {"lat": 36.7456, "lng": 126.2983},
                "í™ì„±êµ°": {"lat": 36.6012, "lng": 126.6608},
                
                # ì „ë¶íŠ¹ë³„ìì¹˜ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì „ë¶íŠ¹ë³„ìì¹˜ë„": {"lat": 35.7175, "lng": 127.1530},
                "ê³ ì°½êµ°": {"lat": 35.4346, "lng": 126.7017},
                "êµ°ì‚°ì‹œ": {"lat": 35.9678, "lng": 126.7368},
                "ê¹€ì œì‹œ": {"lat": 35.8033, "lng": 126.8805},
                "ë‚¨ì›ì‹œ": {"lat": 35.4163, "lng": 127.3906},
                "ë¬´ì£¼êµ°": {"lat": 36.0073, "lng": 127.6610},
                "ë¶€ì•ˆêµ°": {"lat": 35.7318, "lng": 126.7332},
                "ìˆœì°½êµ°": {"lat": 35.3748, "lng": 127.1374},
                "ì™„ì£¼êµ°": {"lat": 35.9058, "lng": 127.1649},
                "ìµì‚°ì‹œ": {"lat": 35.9483, "lng": 126.9575},
                "ì„ì‹¤êµ°": {"lat": 35.6176, "lng": 127.2896},
                "ì¥ìˆ˜êµ°": {"lat": 35.6477, "lng": 127.5217},
                "ì „ì£¼ì‹œ": {"lat": 35.8242, "lng": 127.1480},
                "ì •ìì‹œ": {"lat": 35.5700, "lng": 126.8557},
                "ì§„ì•ˆêµ°": {"lat": 35.7917, "lng": 127.4244},
                
                # ì „ë¼ë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì „ë¼ë‚¨ë„": {"lat": 34.8679, "lng": 126.9910},
                "ê°•ì§„êµ°": {"lat": 34.6417, "lng": 126.7669},
                "ê³ í¥êµ°": {"lat": 34.6111, "lng": 127.2855},
                "ê³¡ì„±êµ°": {"lat": 35.2818, "lng": 127.2914},
                "ê´‘ì–‘ì‹œ": {"lat": 34.9406, "lng": 127.5956},
                "êµ¬ë¡€êµ°": {"lat": 35.2020, "lng": 127.4632},
                "ë‚˜ì£¼ì‹œ": {"lat": 35.0160, "lng": 126.7107},
                "ë‹´ì–‘êµ°": {"lat": 35.3214, "lng": 126.9882},
                "ëª©í¬ì‹œ": {"lat": 34.8118, "lng": 126.3922},
                "ë¬´ì•ˆêµ°": {"lat": 34.9900, "lng": 126.4816},
                "ë³´ì„±êµ°": {"lat": 34.7712, "lng": 127.0800},
                "ìˆœì²œì‹œ": {"lat": 34.9507, "lng": 127.4872},
                "ì‹ ì•ˆêµ°": {"lat": 34.8267, "lng": 126.1063},
                "ì—¬ìˆ˜ì‹œ": {"lat": 34.7604, "lng": 127.6622},
                "ì˜ê´‘êµ°": {"lat": 35.2773, "lng": 126.5120},
                "ì˜ì•”êµ°": {"lat": 34.8000, "lng": 126.6968},
                "ì™„ë„êµ°": {"lat": 34.3105, "lng": 126.7551},
                "ì¥ì„±êµ°": {"lat": 35.3017, "lng": 126.7886},
                "ì¥í¥êµ°": {"lat": 34.6816, "lng": 126.9066},
                "ì§„ë„êµ°": {"lat": 34.4867, "lng": 126.2636},
                "í•¨í‰êµ°": {"lat": 35.0666, "lng": 126.5168},
                "í•´ë‚¨êµ°": {"lat": 34.5736, "lng": 126.5986},
                "í™”ìˆœêµ°": {"lat": 35.0648, "lng": 126.9855},
                
                # ê²½ìƒë¶ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ìƒë¶ë„": {"lat": 36.4919, "lng": 128.8889},
                "ê²½ì‚°ì‹œ": {"lat": 35.8251, "lng": 128.7411},
                "ê²½ì£¼ì‹œ": {"lat": 35.8562, "lng": 129.2247},
                "ê³ ë ¹êµ°": {"lat": 35.7284, "lng": 128.2634},
                "êµ¬ë¯¸ì‹œ": {"lat": 36.1196, "lng": 128.3441},
                "êµ°ìœ„êµ°": {"lat": 36.2393, "lng": 128.5717},
                "ê¹€ì²œì‹œ": {"lat": 36.1395, "lng": 128.1137},
                "ë¬¸ê²½ì‹œ": {"lat": 36.5866, "lng": 128.1866},
                "ë´‰í™”êµ°": {"lat": 36.8932, "lng": 128.7327},
                "ìƒì£¼ì‹œ": {"lat": 36.4107, "lng": 128.1590},
                "ì„±ì£¼êµ°": {"lat": 35.9186, "lng": 128.2829},
                "ì•ˆë™ì‹œ": {"lat": 36.5684, "lng": 128.7294},
                "ì˜ë•êµ°": {"lat": 36.4153, "lng": 129.3655},
                "ì˜ì–‘êµ°": {"lat": 36.6666, "lng": 129.1124},
                "ì˜ì£¼ì‹œ": {"lat": 36.8056, "lng": 128.6239},
                "ì˜ì²œì‹œ": {"lat": 35.9733, "lng": 128.9386},
                "ì˜ˆì²œêµ°": {"lat": 36.6580, "lng": 128.4517},
                "ìš¸ë¦‰êµ°": {"lat": 37.4845, "lng": 130.9058},
                "ìš¸ì§„êµ°": {"lat": 36.9930, "lng": 129.4004},
                "ì˜ì„±êµ°": {"lat": 36.3526, "lng": 128.6974},
                "ì²­ë„êµ°": {"lat": 35.6477, "lng": 128.7363},
                "ì²­ì†¡êµ°": {"lat": 36.4359, "lng": 129.0572},
                "ì¹ ê³¡êµ°": {"lat": 35.9951, "lng": 128.4019},
                "í¬í•­ì‹œ": {"lat": 36.0190, "lng": 129.3435},
                
                # ê²½ìƒë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ìƒë‚¨ë„": {"lat": 35.4606, "lng": 128.2132},
                "ê±°ì œì‹œ": {"lat": 34.8804, "lng": 128.6212},
                "ê±°ì°½êµ°": {"lat": 35.6869, "lng": 127.9095},
                "ê³ ì„±êµ°": {"lat": 34.9735, "lng": 128.3229},
                "ê¹€í•´ì‹œ": {"lat": 35.2342, "lng": 128.8899},
                "ë‚¨í•´êµ°": {"lat": 34.8375, "lng": 127.8926},
                "ë°€ì–‘ì‹œ": {"lat": 35.5040, "lng": 128.7469},
                "ì‚¬ì²œì‹œ": {"lat": 35.0036, "lng": 128.0645},
                "ì‚°ì²­êµ°": {"lat": 35.4150, "lng": 127.8736},
                "ì–‘ì‚°ì‹œ": {"lat": 35.3350, "lng": 129.0371},
                "ì˜ë ¹êµ°": {"lat": 35.3219, "lng": 128.2618},
                "ì§„ì£¼ì‹œ": {"lat": 35.1800, "lng": 128.1076},
                "ì°½ë…•êµ°": {"lat": 35.5444, "lng": 128.4924},
                "ì°½ì›ì‹œ": {"lat": 35.2281, "lng": 128.6811},
                "í†µì˜ì‹œ": {"lat": 34.8544, "lng": 128.4331},
                "í•˜ë™êµ°": {"lat": 35.0675, "lng": 127.7514},
                "í•¨ì•ˆêµ°": {"lat": 35.2730, "lng": 128.4069},
                "í•¨ì–‘êµ°": {"lat": 35.5203, "lng": 127.7252},
                "í•©ì²œêµ°": {"lat": 35.5666, "lng": 128.1655},
            }
                        
            coords = region_coords.get(analysis.region, {"lat": 37.5665, "lng": 126.9780})
            
            url = "https://api.foursquare.com/v3/places/search"
            headers = {
                "Authorization": FOURSQUARE_API_KEY,
                "Accept": "application/json"
            }
            
            # ğŸ”¥ ì¹´í…Œê³ ë¦¬ë³„ ê°•í™”ëœ ê²€ìƒ‰ ì „ëµ
            search_strategies = []
            
            # 1) êµ¬ì²´ì ì¸ ì¥ì†Œëª… (ëŒ€í•™êµ, ê²½ê¸°ì¥ ë“±)
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ', 'ê³µí•­', 'ì—­']):
                search_strategies.append(analysis.place_name)
                
            # 2) ì§€ì—­ëª… + ì¥ì†Œëª…
            region_name = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '')
            search_strategies.append(f"{region_name} {analysis.place_name}")
            
            # 3) ğŸ”¥ ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ê²€ìƒ‰ (ê°•í™”ë¨)
            place_lower = analysis.place_name.lower()
            if any(word in place_lower for word in ["ì‹ë‹¹", "restaurant", "ì‹ì‚¬", "ë°¥", "ì €ë…", "ì ì‹¬"]):
                search_strategies.extend([
                    f"{region_name} restaurant",
                    f"{region_name} ì‹ë‹¹",
                    f"{region_name} food",
                    f"{analysis.district} restaurant"
                ])
                logger.info(f"ğŸ½ï¸ ì‹ì‚¬ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì¶”ê°€")
            elif any(word in place_lower for word in ["ì¹´í˜", "cafe", "ì»¤í”¼"]):
                search_strategies.extend([
                    f"{region_name} cafe",
                    f"{region_name} ì»¤í”¼",
                    f"{region_name} coffee"
                ])
                logger.info(f"â˜• ì¹´í˜ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì¶”ê°€")
            
            logger.info(f"ğŸ” Foursquare ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        "query": strategy,
                        "ll": f"{coords['lat']},{coords['lng']}",
                        "radius": 15000,  # 15km
                        "limit": 20,      # ë” ë§ì€ ê²°ê³¼
                        "sort": "DISTANCE"
                    }
                    
                    # ğŸ”¥ ì‹ì‚¬ ê´€ë ¨ì´ë©´ ì¹´í…Œê³ ë¦¬ í•„í„° ì¶”ê°€
                    if any(word in strategy.lower() for word in ['restaurant', 'ì‹ë‹¹', 'food']):
                        params["categories"] = "13000"  # Food & Dining
                        logger.info(f"ğŸ½ï¸ ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©")
                    elif any(word in strategy.lower() for word in ['cafe', 'coffee', 'ì»¤í”¼']):
                        params["categories"] = "13032,13040"  # Cafe, Coffee Shop
                        logger.info(f"â˜• ì¹´í˜ ì¹´í…Œê³ ë¦¬ í•„í„° ì ìš©")
                    
                    logger.info(f"ğŸ” Foursquare ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get("results"):
                                    logger.info(f"âœ… Foursquare ê²°ê³¼ {len(data['results'])}ê°œ ë°œê²¬")
                                    
                                    # ğŸ”¥ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ì ìˆ˜ ê³„ì‚° ê°•í™”
                                    for i, place in enumerate(data["results"]):
                                        location = place.get("geocodes", {}).get("main", {})
                                        address = place.get("location", {}).get("formatted_address", "")
                                        place_name = place.get("name", "")
                                        categories = place.get("categories", [])
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        logger.info(f"     ì¹´í…Œê³ ë¦¬: {[cat.get('name') for cat in categories]}")
                                        
                                        if not (location.get("latitude") and location.get("longitude")):
                                            logger.info(f"     âŒ ì¢Œí‘œ ì •ë³´ ì—†ìŒ")
                                            continue
                                        
                                        # ğŸ”¥ ê°•í™”ëœ í•„í„°ë§
                                        
                                        # 1) ë¶€ì •ì  í‚¤ì›Œë“œ í•„í„° (ëŒ€í­ ê°•í™”)
                                        negative_keywords = [
                                            "í•™ì›", "ë³‘ì›", "ì˜ì›", "ì•½êµ­", "ì€í–‰", "ë¶€ë™ì‚°", 
                                            "ìœ í•™", "í•™íšŒ", "ì»¨ì„¤íŒ…", "ì‚¬ë¬´ì‹¤", "office", 
                                            "academy", "hospital", "clinic", "bank",
                                            "real estate", "study abroad", "immigration",
                                            "consulting", "law firm", "immigration office",
                                            "ì–´í•™ì›", "ì»¨ì„¤í„´íŠ¸", "ì´ë¯¼", "ë²•ë¬´ë²•ì¸"
                                        ]
                                        
                                        is_negative = any(neg in place_name.lower() for neg in negative_keywords)
                                        
                                        if is_negative:
                                            logger.info(f"     âŒ ë¶€ì • í‚¤ì›Œë“œ í•„í„°ë§: {place_name}")
                                            continue
                                        
                                        # 2) ì¹´í…Œê³ ë¦¬ ì í•©ì„± í™•ì¸ (ëŒ€í­ ê°•í™”)
                                        category_match = False
                                        category_score = 0
                                        
                                        if any(word in strategy.lower() for word in ['restaurant', 'ì‹ë‹¹', 'food', 'ì‹ì‚¬', 'ë°¥']):
                                            # ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ í™•ì¸
                                            food_categories = [
                                                "restaurant", "food", "dining", "korean", "chinese", 
                                                "japanese", "italian", "american", "thai", "indian",
                                                "ì‹ë‹¹", "ìŒì‹ì ", "ë ˆìŠ¤í† ë‘", "eatery", "bistro",
                                                "steakhouse", "pizzeria", "noodle", "barbecue"
                                            ]
                                            for cat in categories:
                                                cat_name = cat.get("name", "").lower()
                                                if any(food_cat in cat_name for food_cat in food_categories):
                                                    category_match = True
                                                    category_score += 5
                                                    logger.info(f"     âœ… ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜: {cat_name}")
                                                    break
                                                    
                                        elif any(word in strategy.lower() for word in ['cafe', 'coffee', 'ì»¤í”¼']):
                                            # ì¹´í˜ ì¹´í…Œê³ ë¦¬ í™•ì¸
                                            cafe_categories = ["cafe", "coffee", "bakery", "dessert", "ì¹´í˜", "tea"]
                                            for cat in categories:
                                                cat_name = cat.get("name", "").lower()
                                                if any(cafe_cat in cat_name for cafe_cat in cafe_categories):
                                                    category_match = True
                                                    category_score += 5
                                                    logger.info(f"     âœ… ì¹´í˜ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜: {cat_name}")
                                                    break
                                        else:
                                            category_match = True  # ê¸°íƒ€ ê²€ìƒ‰ì€ ì¹´í…Œê³ ë¦¬ ì œí•œ ì—†ìŒ
                                            category_score += 2
                                        
                                        # 3) ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_score = 0
                                        region_keywords = [
                                            analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', ''),
                                            analysis.district
                                        ]
                                        
                                        for keyword in region_keywords:
                                            if keyword and keyword in address:
                                                region_score += 3
                                                logger.info(f"     âœ… ì§€ì—­ ì¼ì¹˜: {keyword}")
                                        
                                        # 4) ì´ë¦„ ìœ ì‚¬ë„ í™•ì¸
                                        name_score = 0
                                        search_terms = analysis.place_name.lower().split()
                                        place_terms = place_name.lower().split()
                                        
                                        for term in search_terms:
                                            if len(term) > 1:
                                                if any(term in pt for pt in place_terms):
                                                    name_score += 2
                                        
                                        # 5) ì´ì  ê³„ì‚°
                                        total_score = category_score + region_score + name_score
                                        
                                        logger.info(f"     ğŸ“Š ì ìˆ˜: ì¹´í…Œê³ ë¦¬={category_score} + ì§€ì—­={region_score} + ì´ë¦„={name_score} = {total_score}")
                                        
                                        # ğŸ”¥ ì—„ê²©í•œ ê¸°ì¤€ ì ìš© (ì‹ì‚¬/ì¹´í˜ëŠ” ì¹´í…Œê³ ë¦¬ í•„ìˆ˜)
                                        min_score = 5 if any(word in strategy.lower() for word in ['restaurant', 'ì‹ë‹¹', 'cafe']) else 3
                                        
                                        if category_match and total_score >= min_score:
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=location["latitude"],
                                                longitude=location["longitude"],
                                                source="foursquare",
                                                rating=place.get("rating")
                                            )
                                            
                                            logger.info(f"ğŸ‰ Foursquare í•„í„°ë§ ê²€ìƒ‰ ì„±ê³µ!")
                                            logger.info(f"   ğŸª ì¥ì†Œ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            logger.info(f"   ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {[cat.get('name') for cat in categories]}")
                                            return result
                                        else:
                                            logger.info(f"     âŒ ê¸°ì¤€ ë¯¸ë‹¬: ì¹´í…Œê³ ë¦¬ë§¤ì¹˜={category_match}, ì ìˆ˜={total_score} < {min_score}")
                                    
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê²°ê³¼ ì—†ìŒ")
                            else:
                                logger.warning(f"âš ï¸ Foursquare API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Foursquare ì „ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Foursquare ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def enhanced_search_with_quality_check(place_text: str) -> Optional[PlaceResult]:
        """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ê³¼ ì¬ê²€ìƒ‰ì„ í¬í•¨í•œ í–¥ìƒëœ ê²€ìƒ‰"""
        logger.info(f"ğŸ” í–¥ìƒëœ í’ˆì§ˆ ê²€ì¦ ê²€ìƒ‰ ì‹œì‘: {place_text}")
        
        # 1ë‹¨ê³„: ê¸°ë³¸ 3ì¤‘ API ê²€ìƒ‰
        result = await TripleLocationSearchService.search_triple_api(place_text)
        
        # 2ë‹¨ê³„: ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦
        if result and AddressQualityChecker.is_complete_address(result.address):
            logger.info(f"âœ… 1ì°¨ ê²€ìƒ‰ ì„±ê³µ (ì™„ì „í•œ ì£¼ì†Œ): {result.address}")
            return result
        
        logger.warning(f"âš ï¸ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ ë¶ˆì™„ì „: {result.address if result else 'None'}")
        
        # 3ë‹¨ê³„: ì¬ê²€ìƒ‰ ì „ëµ
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_text)
        category_keywords = AddressQualityChecker.get_category_keywords(place_text)
        
        logger.info(f"ğŸ”„ ì¬ê²€ìƒ‰ ì‹œì‘ - ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ: {category_keywords}")
        
        # 4ë‹¨ê³„: í™•ì¥ ê²€ìƒ‰ (ë°˜ê²½ í™•ëŒ€ + ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ)
        for radius in [1000, 2000, 5000, 10000]:  # 1km â†’ 10kmê¹Œì§€ í™•ëŒ€
            logger.info(f"ğŸ” í™•ì¥ ê²€ìƒ‰ (ë°˜ê²½ {radius}m)")
            
            for keyword in category_keywords:
                enhanced_query = f"{analysis.region} {analysis.district} {keyword}"
                
                # Kakao í™•ì¥ ê²€ìƒ‰
                kakao_result = await TripleLocationSearchService.search_kakao_enhanced(
                    analysis, enhanced_query, radius
                )
                
                if kakao_result and AddressQualityChecker.is_complete_address(kakao_result.address):
                    logger.info(f"âœ… Kakao í™•ì¥ ê²€ìƒ‰ ì„±ê³µ: {kakao_result.address}")
                    return kakao_result
                
                # Google í™•ì¥ ê²€ìƒ‰
                google_result = await TripleLocationSearchService.search_google_enhanced(
                    analysis, enhanced_query
                )
                
                if google_result and AddressQualityChecker.is_complete_address(google_result.address):
                    logger.info(f"âœ… Google í™•ì¥ ê²€ìƒ‰ ì„±ê³µ: {google_result.address}")
                    return google_result
        
        # 5ë‹¨ê³„: ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì£¼ì†Œê°€ ì™„ì „í•˜ì§€ ì•Šë”ë¼ë„)
        if result:
            logger.warning(f"âš ï¸ í™•ì¥ ê²€ìƒ‰ ì‹¤íŒ¨, 1ì°¨ ê²°ê³¼ ì‚¬ìš©: {result.address}")
            return result
        
        logger.error(f"âŒ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {place_text}")
        return None

    @staticmethod
    async def search_kakao_enhanced(analysis: LocationAnalysis, query: str, radius: int) -> Optional[PlaceResult]:
        """Kakao API í™•ì¥ ê²€ìƒ‰"""
        if not KAKAO_REST_API_KEY:
            return None
            
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
            
            params = {
                "query": query,
                "size": 10,  # ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                "radius": radius
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get("documents"):
                            # ê°€ì¥ ì™„ì „í•œ ì£¼ì†Œë¥¼ ê°€ì§„ ê²°ê³¼ ì„ íƒ
                            for place in data["documents"]:
                                address = place.get("road_address_name") or place.get("address_name", "")
                                
                                if AddressQualityChecker.is_complete_address(address):
                                    return PlaceResult(
                                        name=place.get("place_name", analysis.place_name),
                                        address=address,
                                        latitude=float(place.get("y", 0)),
                                        longitude=float(place.get("x", 0)),
                                        source="kakao_enhanced"
                                    )
                                    
        except Exception as e:
            logger.error(f"âŒ Kakao í™•ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None

    @staticmethod
    async def search_google_enhanced(analysis: LocationAnalysis, query: str) -> Optional[PlaceResult]:
        """Google Places API í™•ì¥ ê²€ìƒ‰ - ìˆ˜ì •ëœ ë²„ì „"""
        if not GOOGLE_MAPS_API_KEY:
            return None
            
        try:
            url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
            
            # ì§€ì—­ ì œí•œ ê°•í™”
            region_query = f"{analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '')} {analysis.district} {query}"
            
            params = {
                'input': region_query,
                'inputtype': 'textquery',
                'fields': 'name,formatted_address,geometry,rating',
                'language': 'ko',
                'region': 'kr',
                'key': GOOGLE_MAPS_API_KEY
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get('status') == 'OK' and data.get('candidates'):
                            for place in data['candidates']:
                                address = place.get('formatted_address', '')
                                
                                # ì§€ì—­ ì¼ì¹˜ í™•ì¸ ê°•í™”
                                region_match = any(region_name in address for region_name in 
                                                 [analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', ''), 
                                                  analysis.district])
                                
                                if AddressQualityChecker.is_complete_address(address) and region_match:
                                    location = place['geometry']['location']
                                    return PlaceResult(
                                        name=place.get('name', analysis.place_name),
                                        address=address,
                                        latitude=location['lat'],
                                        longitude=location['lng'],
                                        source="google_enhanced",
                                        rating=place.get('rating')
                                    )
                                    
        except Exception as e:
            logger.error(f"âŒ Google í™•ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None


# app.pyì˜ search_kakao í•¨ìˆ˜ ìˆ˜ì • - KOREA_REGIONS í™œìš©

    @staticmethod
    async def search_kakao(analysis: LocationAnalysis, reference_schedules: List[Dict] = None) -> Optional[PlaceResult]:
        """1ìˆœìœ„: Kakao API ê²€ìƒ‰ - ì§€ì—­ ë§¤ì¹­ ë¡œì§ ê°œì„  (ë™ëª…ì´ì¸ ë°©ì§€)"""
        if not KAKAO_REST_API_KEY:
            logger.warning("âŒ Kakao API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 1ìˆœìœ„ Kakao ê²€ìƒ‰: {analysis.place_name}")
        
        # ğŸ”¥ KOREA_REGIONSì—ì„œ ì „êµ­ êµ¬/ì‹œ/êµ° ì •ë³´ ì¶”ì¶œ
        all_districts = []
        for region, districts in KOREA_REGIONS.items():
            all_districts.extend(list(districts))
        
        logger.info(f"ğŸ“ ì „êµ­ êµ¬/ì‹œ/êµ° {len(all_districts)}ê°œ ì§€ì—­ ëŒ€ì‘")
        
        # ğŸ”¥ ì°¸ì¡° ìœ„ì¹˜ì—ì„œ ì •í™•í•œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ (ì‹œ/ë„ + êµ¬/ì‹œ/êµ°)
        reference_region = None
        reference_district = None
        reference_dong = None
        
        if reference_schedules:
            for ref_schedule in reference_schedules:
                ref_location = ref_schedule.get("location", "")
                if ref_location:
                    logger.info(f"ğŸ“ ì°¸ì¡° ìœ„ì¹˜ ë¶„ì„: {ref_location}")
                    
                    # ì‹œ/ë„ ì •ë³´ ì¶”ì¶œ (ë” ì •í™•í•˜ê²Œ)
                    for region_key, districts in KOREA_REGIONS.items():
                        region_short = region_key.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                        if region_short in ref_location or region_key in ref_location:
                            reference_region = region_key
                            logger.info(f"   ğŸ“ ì°¸ì¡° ì‹œ/ë„: {region_key}")
                            
                            # í•´ë‹¹ ì‹œ/ë„ì˜ êµ¬/ì‹œ/êµ°ë§Œ í™•ì¸
                            for district in districts:
                                if district in ref_location:
                                    reference_district = district
                                    logger.info(f"   ğŸ“ ì°¸ì¡° êµ¬/ì‹œ/êµ°: {district}")
                                    break
                            break
                    
                    # ë™ ì •ë³´ë„ ì¶”ì¶œ ì‹œë„
                    import re
                    dong_match = re.search(r'(\w+ë™)', ref_location)
                    if dong_match:
                        reference_dong = dong_match.group(1)
                        logger.info(f"   ğŸ“ ì°¸ì¡° ë™: {reference_dong}")
                    
                    break

        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
            
            # ğŸ”¥ ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì „ëµ
            search_strategies = []
            
            # 1) êµ¬ì²´ì  ì¥ì†Œëª… (ì—­, ëŒ€í•™êµ ë“±)ì€ ì§€ì—­ ì œí•œ ì—†ì´
            if any(keyword in analysis.place_name.lower() for keyword in ['ì—­', 'ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ê³µí•­', 'ë³‘ì›', 'ë§ˆíŠ¸', 'í„°ë¯¸ë„']):
                search_strategies.append(analysis.place_name)
                if reference_district and reference_region:
                    # ì‹œ/ë„ + êµ¬/ì‹œ/êµ° í•¨ê»˜ ê²€ìƒ‰
                    region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    search_strategies.append(f"{region_short} {reference_district} {analysis.place_name}")
                search_strategies.append(f"{analysis.district} {analysis.place_name}")
            
            # 2) ğŸ”¥ ì‹ì‚¬/ì¹´í˜ëŠ” ë°˜ë“œì‹œ ì •í™•í•œ ì§€ì—­ìœ¼ë¡œ ê²€ìƒ‰ (ì‹œ/ë„ + êµ¬/ì‹œ/êµ°)
            elif any(word in analysis.place_name.lower() for word in ['ì‹ì‚¬', 'ì‹ë‹¹', 'ë°¥', 'ì¹´í˜', 'ì»¤í”¼', 'ë§›ì§‘']):
                
                if reference_district and reference_region:
                    region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                    
                    # A) ë™ ë‹¨ìœ„ ê²€ìƒ‰ (ì‹œ/ë„ + êµ¬/ì‹œ/êµ° + ë™)
                    if reference_dong:
                        search_strategies.extend([
                            f"{region_short} {reference_district} {reference_dong} ë§›ì§‘",
                            f"{region_short} {reference_district} {reference_dong} ì‹ë‹¹",
                            f"{reference_district} {reference_dong} ë§›ì§‘"
                        ])
                    
                    # B) êµ¬/ì‹œ/êµ° + ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ (ì‹œ/ë„ í¬í•¨)
                    search_strategies.extend([
                        f"{region_short} {reference_district} ë§›ì§‘",
                        f"{region_short} {reference_district} ì‹ë‹¹",
                        f"{region_short} {reference_district} ì¹´í˜",
                        f"{reference_region} {reference_district} ë§›ì§‘"  # ì „ì²´ ì‹œ/ë„ëª…ë„ ì‹œë„
                    ])
                    
                    logger.info(f"ğŸ¯ ì°¸ì¡° ì§€ì—­ '{region_short} {reference_district}' ê¸°ì¤€ ê²€ìƒ‰")
                    
                else:
                    # ì°¸ì¡° ì—†ìœ¼ë©´ analysis ì •ë³´ í™œìš©
                    analysis_region_short = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    search_strategies.extend([
                        f"{analysis_region_short} {analysis.district} ë§›ì§‘",
                        f"{analysis_region_short} {analysis.district} ì‹ë‹¹",
                        f"{analysis.region} {analysis.district} ë§›ì§‘"
                    ])
            
            # 3) ê¸°íƒ€ ì¼ë°˜ ê²€ìƒ‰
            else:
                if reference_district and reference_region:
                    region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                    search_strategies.extend([
                        f"{region_short} {reference_district} {analysis.place_name}",
                        f"{analysis.place_name}"
                    ])
                else:
                    search_strategies.extend([
                        f"{analysis.district} {analysis.place_name}",
                        f"{analysis.place_name}"
                    ])
            
            # ì¤‘ë³µ ì œê±°
            search_strategies = list(dict.fromkeys(search_strategies))
            
            logger.info(f"ğŸ” ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì „ëµ ({len(search_strategies)}ê°œ):")
            for i, strategy in enumerate(search_strategies):
                logger.info(f"   {i+1}. {strategy}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        "query": strategy,
                        "size": 15,  # ë” ë§ì€ ê²°ê³¼
                        "sort": "accuracy"
                    }
                    
                    logger.info(f"ğŸ” Kakao ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get("documents"):
                                    logger.info(f"âœ… Kakao ê²°ê³¼ {len(data['documents'])}ê°œ ë°œê²¬")
                                    
                                    for i, place in enumerate(data["documents"]):
                                        place_name = place.get("place_name", "")
                                        address = place.get("road_address_name") or place.get("address_name", "")
                                        category = place.get("category_name", "")
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        
                                        if not address.strip():
                                            continue
                                        
                                        # ğŸ”¥ ê°œì„ ëœ ì§€ì—­ ë§¤ì¹­ ì ìˆ˜ (ë™ëª…ì´ì¸ ë°©ì§€)
                                        location_score = 0
                                        
                                        if reference_district and reference_region:
                                            # ğŸ“ ì°¸ì¡° ì§€ì—­ì´ ìˆì„ ë•Œ: ì‹œ/ë„ + êµ¬/ì‹œ/êµ° ëª¨ë‘ í™•ì¸
                                            reference_region_short = reference_region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                                            
                                            # ì£¼ì†Œì—ì„œ ì‹œ/ë„ ì •ë³´ í™•ì¸
                                            address_has_region = any(region_name in address for region_name in [
                                                reference_region_short, 
                                                reference_region
                                            ])
                                            
                                            # ì£¼ì†Œì—ì„œ êµ¬/ì‹œ/êµ° ì •ë³´ í™•ì¸
                                            address_has_district = reference_district in address
                                            
                                            if address_has_region and address_has_district:
                                                location_score += 10  # ğŸ”¥ ì‹œ/ë„ + êµ¬/ì‹œ/êµ° ëª¨ë‘ ì¼ì¹˜ (ìµœê³ ì )
                                                logger.info(f"     âœ… ì™„ì „ ì§€ì—­ ì¼ì¹˜ ({reference_region_short} {reference_district})")
                                            elif address_has_district and not address_has_region:
                                                # ğŸ”¥ ê°™ì€ êµ¬ëª…ì´ì§€ë§Œ ë‹¤ë¥¸ ì‹œ/ë„ (ì˜ˆ: ë¶€ì‚° ë™êµ¬ vs ëŒ€êµ¬ ë™êµ¬)
                                                location_score -= 20  # ëŒ€í­ ê°ì 
                                                logger.warning(f"     âŒ ë™ëª…ì´ì¸ ì§€ì—­! {reference_district}ì´ì§€ë§Œ ë‹¤ë¥¸ ì‹œ/ë„ ({address})")
                                            elif address_has_region and not address_has_district:
                                                # ê°™ì€ ì‹œ/ë„ ë‚´ ë‹¤ë¥¸ êµ¬/ì‹œ/êµ°
                                                found_district = None
                                                if reference_region in KOREA_REGIONS:
                                                    region_districts = KOREA_REGIONS[reference_region]
                                                    for district in region_districts:
                                                        if district in address:
                                                            found_district = district
                                                            break
                                                
                                                if found_district:
                                                    location_score += 5  # ê°™ì€ ì‹œ/ë„ ë‚´
                                                    logger.info(f"     âœ… ê°™ì€ ì‹œ/ë„ ë‚´ ({reference_region_short} {found_district})")
                                                else:
                                                    location_score += 2  # ê°™ì€ ì‹œ/ë„ì´ì§€ë§Œ êµ¬ ë¶ˆë¶„ëª…
                                                    logger.info(f"     âœ… ê°™ì€ ì‹œ/ë„ ({reference_region_short})")
                                            else:
                                                location_score += 1  # ê¸°íƒ€ ì§€ì—­
                                                
                                        elif reference_district:
                                            # ì°¸ì¡° êµ¬/ì‹œ/êµ°ë§Œ ìˆì„ ë•Œ (ì‹œ/ë„ ì •ë³´ ì—†ìŒ)
                                            if reference_district in address:
                                                # ğŸ”¥ êµ¬ëª…ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš° ì¶”ê°€ ê²€ì¦ í•„ìš”
                                                # í•œêµ­ì—ì„œ ë™ëª…ì´ì¸ ê°€ëŠ¥ì„± ë†’ì€ êµ¬ëª…ë“¤
                                                common_district_names = ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬"]
                                                
                                                if reference_district in common_district_names:
                                                    # ë™ëª…ì´ì¸ ê°€ëŠ¥ì„± ë†’ìŒ - ë‚®ì€ ì ìˆ˜
                                                    location_score += 2
                                                    logger.warning(f"     âš ï¸ ë™ëª…ì´ì¸ ê°€ëŠ¥ ì§€ì—­: {reference_district}")
                                                else:
                                                    # ê³ ìœ í•œ êµ¬ëª… (ì˜ˆ: "ì˜ë“±í¬êµ¬", "ê¸ˆì •êµ¬")
                                                    location_score += 6
                                                    logger.info(f"     âœ… ê³ ìœ  êµ¬ëª… ì¼ì¹˜ ({reference_district})")
                                            else:
                                                location_score += 1  # ê¸°íƒ€
                                                
                                        else:
                                            # ì°¸ì¡° ì§€ì—­ ì—†ìœ¼ë©´ analysis ì§€ì—­ê³¼ ë¹„êµ
                                            analysis_region_short = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('ë„', '')
                                            
                                            # ì‹œ/ë„ + êµ¬/ì‹œ/êµ° í™•ì¸
                                            address_has_analysis_region = any(region_name in address for region_name in [
                                                analysis_region_short,
                                                analysis.region
                                            ])
                                            
                                            if analysis.district in address and address_has_analysis_region:
                                                location_score += 8  # ë¶„ì„ ì§€ì—­ ì™„ì „ ì¼ì¹˜
                                                logger.info(f"     âœ… ë¶„ì„ ì§€ì—­ ì™„ì „ ì¼ì¹˜ ({analysis_region_short} {analysis.district})")
                                            elif analysis.district in address:
                                                # êµ¬ëª…ë§Œ ì¼ì¹˜ - ë™ëª…ì´ì¸ ì²´í¬
                                                common_district_names = ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬"]
                                                if analysis.district in common_district_names:
                                                    location_score += 2  # ë™ëª…ì´ì¸ ê°€ëŠ¥ì„±ìœ¼ë¡œ ë‚®ì€ ì ìˆ˜
                                                    logger.warning(f"     âš ï¸ ë™ëª…ì´ì¸ ê°€ëŠ¥: {analysis.district}")
                                                else:
                                                    location_score += 5  # ê³ ìœ  êµ¬ëª…
                                            elif address_has_analysis_region:
                                                location_score += 3  # ì‹œ/ë„ë§Œ ì¼ì¹˜
                                                logger.info(f"     âœ… ì‹œ/ë„ ì¼ì¹˜ ({analysis_region_short})")
                                            else:
                                                location_score += 1  # ê¸°íƒ€
                                        
                                        # ì¹´í…Œê³ ë¦¬ ì ìˆ˜
                                        category_score = 0
                                        if any(word in strategy.lower() for word in ["ë§›ì§‘", "ì‹ë‹¹", "ë°¥"]):
                                            if any(cat in category for cat in ["ìŒì‹ì ", "ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹"]):
                                                category_score += 3
                                                logger.info(f"     âœ… ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜")
                                        elif "ì¹´í˜" in strategy.lower():
                                            if any(cat in category for cat in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸"]):
                                                category_score += 3
                                                logger.info(f"     âœ… ì¹´í˜ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜")
                                        
                                        # ë¶€ì • í‚¤ì›Œë“œ (ì‹ë‹¹ì´ ì•„ë‹Œ ê²ƒë“¤ í•„í„°ë§)
                                        negative_score = 0
                                        negative_keywords = ["í•™ì›", "ë³‘ì›", "ì˜ì›", "ì•½êµ­", "ì€í–‰", "ë¶€ë™ì‚°", "ìœ í•™", "í•™íšŒ", "ì»¨ì„¤íŒ…"]
                                        if any(neg in place_name.lower() for neg in negative_keywords):
                                            negative_score -= 10
                                            logger.info(f"     âŒ ë¶€ì • í‚¤ì›Œë“œ ({place_name})")
                                        
                                        # ì´ì  ê³„ì‚°
                                        total_score = location_score + category_score + negative_score
                                        
                                        logger.info(f"     ğŸ“Š ì ìˆ˜: ì§€ì—­={location_score} + ì¹´í…Œê³ ë¦¬={category_score} + ë¶€ì •={negative_score} = {total_score}")
                                        
                                        # ğŸ”¥ ë†’ì€ ì ìˆ˜ ê¸°ì¤€ (ë™ëª…ì´ì¸ ë°©ì§€)
                                        min_score = 8 if reference_region and reference_district else 6
                                        
                                        if total_score >= min_score:
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=float(place.get("y", 0)),
                                                longitude=float(place.get("x", 0)),
                                                source="kakao"
                                            )
                                            
                                            logger.info(f"ğŸ‰ Kakao ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì„±ê³µ!")
                                            logger.info(f"   ğŸª ì¥ì†Œ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            logger.info(f"   ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {category}")
                                            logger.info(f"   ğŸ¯ ê²€ìƒ‰ì–´: {strategy}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê¸°ì¤€ ë¯¸ë‹¬ (ìµœê³ ì : {max([total_score for _ in range(1)] or [0])})")
                                else:
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê²°ê³¼ ì—†ìŒ")
                            else:
                                logger.warning(f"âš ï¸ Kakao API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Kakao ì „ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Kakao ë™ëª…ì´ì¸ ë°©ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def search_google(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """2ìˆœìœ„: Google Places API ê²€ìƒ‰ - ê°•í™”ëœ ë²„ì „"""
        if not GOOGLE_MAPS_API_KEY:
            logger.warning("âŒ Google API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 2ìˆœìœ„ Google ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
            
            # ê²€ìƒ‰ ì „ëµ
            region_name = analysis.region.replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ì‹œ', '')
            search_strategies = []
            
            # êµ¬ì²´ì  ì¥ì†Œëª…
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ']):
                search_strategies.extend([
                    f"{region_name} {analysis.place_name}",
                    analysis.place_name
                ])
            
            # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
            place_lower = analysis.place_name.lower()
            if any(word in place_lower for word in ['ì‹ë‹¹', 'restaurant']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} restaurant",
                    f"{region_name} ë§›ì§‘"
                ])
            elif any(word in place_lower for word in ['ì¹´í˜', 'cafe']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} cafe",
                    f"{region_name} ì¹´í˜"
                ])
            
            logger.info(f"ğŸ” Google ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        'input': strategy,
                        'inputtype': 'textquery',
                        'fields': 'name,formatted_address,geometry,rating,types',
                        'language': 'ko',
                        'region': 'kr',
                        'key': GOOGLE_MAPS_API_KEY
                    }
                    
                    logger.info(f"ğŸ” Google ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get('status') == 'OK' and data.get('candidates'):
                                    logger.info(f"âœ… Google ê²°ê³¼ {len(data['candidates'])}ê°œ ë°œê²¬")
                                    
                                    for i, place in enumerate(data['candidates']):
                                        place_name = place.get('name', '')
                                        address = place.get('formatted_address', '')
                                        types = place.get('types', [])
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        logger.info(f"     íƒ€ì…: {types}")
                                        
                                        # ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_keywords = [region_name, analysis.district]
                                        region_match = any(keyword in address for keyword in region_keywords if keyword)
                                        
                                        # íƒ€ì… ì í•©ì„± í™•ì¸
                                        type_match = False
                                        if "ì‹ë‹¹" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["restaurant", "food", "meal_takeaway"])
                                        elif "ì¹´í˜" in analysis.place_name.lower():  
                                            type_match = any(t in types for t in ["cafe", "bakery"])
                                        elif "ëŒ€í•™êµ" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["university", "school"])
                                        elif "ê²½ê¸°ì¥" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["stadium", "gym"])
                                        else:
                                            type_match = True
                                        
                                        score = (1 if region_match else 0) + (1 if type_match else 0)
                                        logger.info(f"     ì§€ì—­ì¼ì¹˜: {region_match}, íƒ€ì…ì í•©: {type_match}, ì ìˆ˜: {score}")
                                        
                                        if score >= 1:
                                            location = place['geometry']['location']
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=location['lat'],
                                                longitude=location['lng'],
                                                source="google",
                                                rating=place.get('rating')
                                            )
                                            
                                            logger.info(f"âœ… Google ê²€ìƒ‰ ì„±ê³µ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ Google ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ Google API ì‘ë‹µ: {data.get('status', 'UNKNOWN')}")
                            else:
                                logger.warning(f"âš ï¸ Google API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ Google ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Google ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Google ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def search_triple_api(place_text: str) -> Optional[PlaceResult]:
        """3ì¤‘ API ìˆœì°¨ ê²€ìƒ‰ - ì¹´ì¹´ì˜¤ ìš°ì„ ìœ¼ë¡œ ë³€ê²½"""
        logger.info(f"ğŸ¯ 3ì¤‘ API ê²€ìƒ‰ ì‹œì‘: {place_text}")
        
        # 1ë‹¨ê³„: GPTë¡œ ì§€ì—­ ë¶„ì„
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_text)
        logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {analysis.region} {analysis.district} - {analysis.place_name}")
        
        # 2ë‹¨ê³„: ê²€ìƒ‰ ìˆœì„œ ê²°ì • - ì¹´ì¹´ì˜¤ ìš°ì„ !
        search_methods = [
            ("Kakao (1ìˆœìœ„)", TripleLocationSearchService.search_kakao),
            ("Google (2ìˆœìœ„)", TripleLocationSearchService.search_google),
            ("Foursquare (3ìˆœìœ„)", TripleLocationSearchService.search_foursquare)
        ]
        
        for api_name, search_method in search_methods:
            try:
                result = await asyncio.wait_for(search_method(analysis), timeout=10)
                if result and result.address and result.address.strip():
                    logger.info(f"ğŸ‰ {api_name}ì—ì„œ ê²€ìƒ‰ ì„±ê³µ!")
                    return result
                else:
                    logger.info(f"âš ï¸ {api_name} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, ë‹¤ìŒ API ì‹œë„...")
            except asyncio.TimeoutError:
                logger.warning(f"â° {api_name} ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ")
            except Exception as e:
                logger.error(f"âŒ {api_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # ëª¨ë“  API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¢Œí‘œ ë°˜í™˜
        logger.warning(f"âš ï¸ ëª¨ë“  API ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ì¢Œí‘œ ì‚¬ìš©: {place_text}")
        return None

# ----- ë¹„ë™ê¸° ìœ„ì¹˜ ì •ë³´ ë³´ê°• -----
async def enhance_locations_with_triple_api(schedule_data: Dict) -> Dict:
    """3ì¤‘ APIë¡œ ìœ„ì¹˜ ì •ë³´ ë³´ê°• - ì°¸ì¡° ìœ„ì¹˜ í™œìš©"""
    logger.info("ğŸš€ 3ì¤‘ API ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹œì‘")
    
    try:
        enhanced_data = json.loads(json.dumps(schedule_data))
        
        # ëª¨ë“  ì¼ì • ìˆ˜ì§‘ (ìˆœì„œëŒ€ë¡œ)
        all_schedules = []
        all_schedules.extend(enhanced_data.get("fixedSchedules", []))
        all_schedules.extend(enhanced_data.get("flexibleSchedules", []))
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì´ì „ ì¼ì •ì˜ ìœ„ì¹˜ë¥¼ ì°¸ì¡°ë¡œ í™œìš©
        processed_schedules = []
        
        for i, schedule in enumerate(all_schedules):
            # ì´ì „ ì²˜ë¦¬ëœ ì¼ì •ë“¤ì„ ì°¸ì¡°ë¡œ ì „ë‹¬
            enhanced_schedule = await enhance_single_schedule_triple(schedule, processed_schedules)
            processed_schedules.append(enhanced_schedule)
        
        logger.info(f"âœ… 3ì¤‘ API ìœ„ì¹˜ ë³´ê°• ì™„ë£Œ: {len(processed_schedules)}ê°œ ì²˜ë¦¬")
        
        return enhanced_data
        
    except Exception as e:
        logger.error(f"âŒ 3ì¤‘ API ìœ„ì¹˜ ë³´ê°• ì‹¤íŒ¨: {e}")
        return schedule_data

def _is_reasonable_distance(address1: str, address2: str) -> bool:
    """ë‘ ì£¼ì†Œê°€ í•©ë¦¬ì ì¸ ê±°ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
    try:
        # ì‹œ/ë„ ë‹¨ìœ„ ë¹„êµ
        regions1 = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        
        region1 = None
        region2 = None
        
        for region in regions1:
            if region in address1:
                region1 = region
            if region in address2:
                region2 = region
        
        # ê°™ì€ ê´‘ì—­ì‹œ/ë„ë©´ OK
        if region1 == region2:
            return True
        
        # ì¸ì ‘ ì§€ì—­ í—ˆìš© (ì˜ˆ: ì„œìš¸-ê²½ê¸°, ë¶€ì‚°-ê²½ë‚¨ ë“±)
        adjacent_regions = {
            "ì„œìš¸": ["ê²½ê¸°"],
            "ê²½ê¸°": ["ì„œìš¸", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨"],
            "ë¶€ì‚°": ["ê²½ë‚¨"],
            "ê²½ë‚¨": ["ë¶€ì‚°", "ê²½ë¶"],
            "ìš¸ì‚°": ["ê²½ë‚¨", "ê²½ë¶"],
            "ëŒ€êµ¬": ["ê²½ë¶", "ê²½ë‚¨"]
        }
        
        if region1 in adjacent_regions and region2 in adjacent_regions[region1]:
            return True
        if region2 in adjacent_regions and region1 in adjacent_regions[region2]:
            return True
            
        # ê·¸ ì™¸ëŠ” ë„ˆë¬´ ë©€ë‹¤ê³  íŒë‹¨
        logger.info(f"ğŸ“ ê±°ë¦¬ ì²´í¬: {region1} vs {region2} - ë„ˆë¬´ ë©€ìŒ")
        return False
        
    except Exception:
        return True  # ì˜¤ë¥˜ ì‹œ í—ˆìš©
    
async def enhance_single_schedule_triple(schedule: Dict, reference_schedules: List[Dict] = None):
    """ë‹¨ì¼ ì¼ì •ì˜ 3ì¤‘ API + í’ˆì§ˆ ê²€ì¦ ìœ„ì¹˜ ê²€ìƒ‰ - ì¹´ì¹´ì˜¤ ìš°ì„ """
    place_name = schedule.get("name", "")
    if not place_name:
        return schedule
    
    logger.info(f"ğŸ¯ í’ˆì§ˆ ê²€ì¦ ìœ„ì¹˜ ê²€ìƒ‰: {place_name}")
    
    # ì°¸ì¡° ìœ„ì¹˜ ì°¾ê¸°
    reference_location = None
    if reference_schedules:
        for ref_schedule in reference_schedules:
            if ref_schedule.get("location") and ref_schedule["location"].strip():
                reference_location = ref_schedule["location"]
                logger.info(f"ğŸ“ ì°¸ì¡° ìœ„ì¹˜ ì„¤ì •: {reference_location}")
                break
    
    try:
        # ì°¸ì¡° ìœ„ì¹˜ë¥¼ ê³ ë ¤í•œ ë¶„ì„
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_name, reference_location)
        
        # ì¹´ì¹´ì˜¤ ìš°ì„  ê²€ìƒ‰ ìˆœì„œ
        search_methods = [
            ("Kakao", TripleLocationSearchService.search_kakao),
            ("Google", TripleLocationSearchService.search_google),
            ("Foursquare", TripleLocationSearchService.search_foursquare)
        ]
        
        for api_name, search_method in search_methods:
            try:
                result = await asyncio.wait_for(search_method(analysis), timeout=10)
                if result and result.address and result.address.strip():
                    # ì°¸ì¡° ìœ„ì¹˜ì™€ì˜ ê±°ë¦¬ ì²´í¬
                    if reference_location and not _is_reasonable_distance(reference_location, result.address):
                        logger.warning(f"âš ï¸ {api_name} ê²°ê³¼ê°€ ì°¸ì¡° ìœ„ì¹˜ì™€ ë„ˆë¬´ ë©€ì–´ì„œ ì œì™¸: {result.address}")
                        continue
                    
                    schedule["location"] = result.address
                    schedule["latitude"] = result.latitude
                    schedule["longitude"] = result.longitude
                    
                    logger.info(f"âœ… {api_name} ìœ„ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {place_name}")
                    logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                    return schedule
                    
            except Exception as e:
                logger.error(f"âŒ {api_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ ëª¨ë“  API ê²€ìƒ‰ ì‹¤íŒ¨: {place_name}")
            
    except Exception as e:
        logger.error(f"âŒ ìœ„ì¹˜ ê²€ìƒ‰ ì˜¤ë¥˜: {place_name}, {e}")
    
    return schedule

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ -----
async def run_in_executor(func, *args, **kwargs):
    """ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor(max_workers=4) as executor:
        return await loop.run_in_executor(executor, func, *args, **kwargs)

def safe_parse_json(json_str):
    """ì•ˆì „í•œ JSON íŒŒì‹±"""
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }

# app.pyì˜ create_schedule_chain() í•¨ìˆ˜ ê°œì„ 

def create_schedule_chain():
    """LangChainì„ ì‚¬ìš©í•œ ì¼ì • ì¶”ì¶œ ì²´ì¸ ìƒì„± - ì‹œê°„ ë§¥ë½ ê°•í™”"""
    current_time = int(datetime.datetime.now().timestamp() * 1000)
    
    today = datetime.datetime.now()
    tomorrow = today + datetime.timedelta(days=1)
    day_after_tomorrow = today + datetime.timedelta(days=2)
    
    # ğŸ”¥ í˜„ì¬ ì‹¤ì œ ì‹œê°„ ì •ë³´ ì¶”ê°€
    actual_now = datetime.datetime.now()
    current_hour = actual_now.hour
    
    template = """ë‹¤ìŒ ìŒì„± ë©”ì‹œì§€ì—ì„œ **ëª¨ë“  ì¼ì • ì •ë³´**ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ìŒì„± ë©”ì‹œì§€: {input}

í˜„ì¬ ë‚ ì§œ: {today_date}
í˜„ì¬ ì‹¤ì œ ì‹œê°„: {current_hour}ì‹œ ({current_time_desc})
ë‚´ì¼: {tomorrow_date}
ëª¨ë ˆ: {day_after_tomorrow_date}

**ğŸ”¥ ì¤‘ìš”í•œ ì‹œê°„ ë§¥ë½ ê·œì¹™**:
1. "ì €ë…", "dinner" â†’ 18:00~20:00 (ì €ë… ì‹œê°„)
2. "ì ì‹¬", "lunch" â†’ 12:00~14:00 (ì ì‹¬ ì‹œê°„)  
3. "ì•„ì¹¨", "morning" â†’ 08:00~10:00 (ì•„ì¹¨ ì‹œê°„)
4. í˜„ì¬ ì‹œê°„ì´ {current_hour}ì‹œì´ë¯€ë¡œ, ì¼ë°˜ì ì¸ "ì‹ì‚¬"ëŠ” ë‹¤ìŒ ì‹ì‚¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
5. "ì¤‘ê°„ì—"ëŠ” ì•ë’¤ ì¼ì • ì‚¬ì´ ì‹œê°„ìœ¼ë¡œ ì„¤ì •

**ì¤‘ìš”**: ë©”ì‹œì§€ì— ì–¸ê¸‰ëœ ëª¨ë“  ì¥ì†Œì™€ í™œë™ì„ ê°œë³„ ì¼ì •ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”!

ì˜ˆì‹œ ì…ë ¥: "ë¶€ì‚°ì—­ì—ì„œ ì¥ì „ì—­ê¹Œì§€ ê°€ëŠ”ë°, ì¤‘ê°„ì— ì €ë…ë¨¹ê³ ì‹¶ì–´"
â†’ 3ê°œ ì¼ì •: 1) ë¶€ì‚°ì—­ 2) ì €ë… ì‹ì‚¬ (18:00) 3) ì¥ì „ì—­

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
{{
  "fixedSchedules": [
    {{
      "id": "{current_time}",
      "name": "ë¶€ì‚°ì—­",
      "type": "FIXED",
      "duration": 60,
      "priority": 1,
      "location": "",
      "latitude": 35.1,
      "longitude": 129.0,
      "startTime": "2025-06-01T10:00:00",
      "endTime": "2025-06-01T11:00:00"
    }},
    {{
      "id": "{current_time_2}",
      "name": "ì €ë… ì‹ì‚¬",
      "type": "FIXED", 
      "duration": 120,
      "priority": 2,
      "location": "",
      "latitude": 35.1,
      "longitude": 129.0,
      "startTime": "2025-06-01T18:00:00",
      "endTime": "2025-06-01T20:00:00"
    }},
    {{
      "id": "{current_time_3}",
      "name": "ì¥ì „ì—­",
      "type": "FIXED",
      "duration": 60,
      "priority": 3,
      "location": "",
      "latitude": 35.2,
      "longitude": 129.1,
      "startTime": "2025-06-01T20:30:00",
      "endTime": "2025-06-01T21:30:00"
    }}
  ],
  "flexibleSchedules": []
}}

ì£¼ì˜ì‚¬í•­:
1. **ì‹œê°„ ë§¥ë½ì„ ì •í™•íˆ ë°˜ì˜**: "ì €ë…" â†’ 18:00, "ì ì‹¬" â†’ 12:00
2. **"ì¤‘ê°„ì—"ëŠ” ìˆœì„œìƒ ì¤‘ê°„ ì‹œê°„**ìœ¼ë¡œ ë°°ì¹˜
3. ì´ë™ì‹œê°„ ê³ ë ¤í•˜ì—¬ ìµœì†Œ 30ë¶„ ê°„ê²© ìœ ì§€
4. JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€
"""
    
    # í˜„ì¬ ì‹œê°„ëŒ€ ì„¤ëª… ì¶”ê°€
    if 6 <= current_hour < 12:
        current_time_desc = "ì˜¤ì „"
    elif 12 <= current_hour < 18:
        current_time_desc = "ì˜¤í›„"
    elif 18 <= current_hour < 22:
        current_time_desc = "ì €ë…"
    else:
        current_time_desc = "ë°¤"
    
    prompt = PromptTemplate(
        template=template,
        input_variables=["input"],
        partial_variables={
            "current_time": str(current_time),
            "current_time_2": str(current_time + 1),
            "current_time_3": str(current_time + 2),
            "today_date": today.strftime("%Y-%m-%d"),
            "tomorrow_date": tomorrow.strftime("%Y-%m-%d"),
            "day_after_tomorrow_date": day_after_tomorrow.strftime("%Y-%m-%d"),
            "current_hour": current_hour,
            "current_time_desc": current_time_desc
        }
    )
    
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model_name="gpt-4-turbo",
        temperature=0
    )
    
    parser = JsonOutputParser()
    chain = prompt | llm | parser
    
    return chain

# ----- ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ -----
@app.get("/")
async def root():
    return {"message": "3ì¤‘ API (Foursquare+Kakao+Google) ì •í™•í•œ ì£¼ì†Œ ê²€ìƒ‰ ì¼ì • ì¶”ì¶œ API v3.0", "status": "running"}

# app.pyì—ì„œ AddressQualityChecker í´ë˜ìŠ¤ ë’¤ì— ì¶”ê°€ (í´ë˜ìŠ¤ ë°–ì—!)

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ -----
def normalize_priorities(schedules_data: Dict[str, Any]) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì •ìˆ˜ë¡œ ì •ê·œí™”"""
    logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ìˆ˜ ë³€í™˜ ì‹œì‘")
    
    all_schedules = []
    all_schedules.extend(schedules_data.get("fixedSchedules", []))
    all_schedules.extend(schedules_data.get("flexibleSchedules", []))
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    all_schedules.sort(key=lambda s: s.get("priority", 999))
    
    # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ë¡œ ì¬í• ë‹¹
    for i, schedule in enumerate(all_schedules):
        old_priority = schedule.get("priority", "ì—†ìŒ")
        new_priority = i + 1
        schedule["priority"] = new_priority
        logger.info(f"ìš°ì„ ìˆœìœ„ ì •ê·œí™”: '{schedule.get('name', '')}' {old_priority} â†’ {new_priority}")
    
    # ë‹¤ì‹œ ë¶„ë¥˜
    fixed_schedules = [s for s in all_schedules if s.get("type") == "FIXED" and "startTime" in s]
    flexible_schedules = [s for s in all_schedules if s.get("type") != "FIXED" or "startTime" not in s]
    
    logger.info(f"âœ… ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì™„ë£Œ: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
    
    return {
        "fixedSchedules": fixed_schedules,
        "flexibleSchedules": flexible_schedules
    }



# extract_schedule í•¨ìˆ˜ì—ì„œ ì‚¬ìš©
# app.pyì˜ extract_schedule ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì • ë¶€ë¶„

# ê¸°ì¡´ importì— ì¶”ê°€
from scheduler import (
    create_enhancement_chain,
    apply_time_inference,
    apply_priorities,
    enhance_schedule_with_relationships,
    parse_datetime,
    generate_multiple_options  # ğŸ†• ìƒˆë¡œ ì¶”ê°€
)
def _create_single_option_fallback(enhanced_data: Dict[str, Any]) -> Dict[str, Any]:
    """ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ê²°ê³¼ë¥¼ ë‹¨ì¼ ì˜µì…˜ìœ¼ë¡œ ë³€í™˜"""
    import time
    import copy
    
    logger.info("ğŸ”„ ë‹¨ì¼ ì˜µì…˜ í´ë°± ìƒì„± ì‹œì‘")
    logger.info(f"   ì…ë ¥ ë°ì´í„° í™•ì¸:")
    logger.info(f"     ê³ ì • ì¼ì •: {len(enhanced_data.get('fixedSchedules', []))}ê°œ")
    logger.info(f"     ìœ ì—° ì¼ì •: {len(enhanced_data.get('flexibleSchedules', []))}ê°œ")
    
    try:
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        timestamp = int(time.time() * 1000)
        logger.info(f"   ê³ ìœ  íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±: {timestamp}")
        
        # ì›ë³¸ ë°ì´í„° ê¹Šì€ ë³µì‚¬
        logger.info("   ì›ë³¸ ë°ì´í„° ê¹Šì€ ë³µì‚¬ ì‹œì‘")
        fixed_schedules = copy.deepcopy(enhanced_data.get("fixedSchedules", []))
        flexible_schedules = copy.deepcopy(enhanced_data.get("flexibleSchedules", []))
        logger.info("   âœ… ê¹Šì€ ë³µì‚¬ ì™„ë£Œ")
        
        # ê³ ì • ì¼ì • ID ì—…ë°ì´íŠ¸
        logger.info("   ê³ ì • ì¼ì • ID ì—…ë°ì´íŠ¸ ì‹œì‘")
        for i, schedule in enumerate(fixed_schedules):
            old_id = schedule.get("id", "ì—†ìŒ")
            
            if schedule.get("id"):
                new_id = f"{timestamp}01{i:02d}"
                schedule["id"] = new_id
                logger.info(f"     ê³ ì • ì¼ì • {i+1}: '{old_id}' â†’ '{new_id}'")
                logger.info(f"       ì´ë¦„: {schedule.get('name', 'N/A')}")
                logger.info(f"       ìœ„ì¹˜: {schedule.get('location', 'N/A')}")
            else:
                logger.warning(f"     ê³ ì • ì¼ì • {i+1}: IDê°€ ì—†ì–´ì„œ ìŠ¤í‚µ")
        
        # ìœ ì—° ì¼ì • ID ì—…ë°ì´íŠ¸  
        logger.info("   ìœ ì—° ì¼ì • ID ì—…ë°ì´íŠ¸ ì‹œì‘")
        for i, schedule in enumerate(flexible_schedules):
            old_id = schedule.get("id", "ì—†ìŒ")
            
            if schedule.get("id"):
                new_id = f"{timestamp}01{i+100:02d}"
                schedule["id"] = new_id
                logger.info(f"     ìœ ì—° ì¼ì • {i+1}: '{old_id}' â†’ '{new_id}'")
                logger.info(f"       ì´ë¦„: {schedule.get('name', 'N/A')}")
                logger.info(f"       ìœ„ì¹˜: {schedule.get('location', 'N/A')}")
            else:
                logger.warning(f"     ìœ ì—° ì¼ì • {i+1}: IDê°€ ì—†ì–´ì„œ ìŠ¤í‚µ")
        
        # ìµœì¢… ì˜µì…˜ êµ¬ì„±
        logger.info("   ìµœì¢… ì˜µì…˜ êµ¬ì„± ì‹œì‘")
        result = {
            "options": [
                {
                    "optionId": 1,
                    "fixedSchedules": fixed_schedules,
                    "flexibleSchedules": flexible_schedules
                }
            ]
        }
        
        logger.info("âœ… ë‹¨ì¼ ì˜µì…˜ í´ë°± ìƒì„± ì™„ë£Œ")
        logger.info(f"   ìµœì¢… ê²°ê³¼:")
        logger.info(f"     ì˜µì…˜ ìˆ˜: 1ê°œ")
        logger.info(f"     ê³ ì • ì¼ì •: {len(fixed_schedules)}ê°œ")
        logger.info(f"     ìœ ì—° ì¼ì •: {len(flexible_schedules)}ê°œ")
        
        # ì¼ì • ìƒì„¸ ì •ë³´ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ)
        logger.info("   ğŸ“‹ ìƒì„±ëœ ì¼ì • ìƒì„¸ ì •ë³´:")
        
        for i, schedule in enumerate(fixed_schedules[:3]):  # ì²˜ìŒ 3ê°œë§Œ
            name = schedule.get('name', 'N/A')
            location = schedule.get('location', 'N/A')
            start_time = schedule.get('startTime', 'N/A')
            priority = schedule.get('priority', 'N/A')
            
            logger.info(f"     ê³ ì • {i+1}: {name}")
            logger.info(f"       ğŸ“ ìœ„ì¹˜: {location}")
            logger.info(f"       â° ì‹œê°„: {start_time}")
            logger.info(f"       ğŸ¯ ìš°ì„ ìˆœìœ„: {priority}")
        
        if len(fixed_schedules) > 3:
            logger.info(f"     ... ê³ ì • ì¼ì • {len(fixed_schedules) - 3}ê°œ ë” ìˆìŒ")
        
        for i, schedule in enumerate(flexible_schedules[:3]):  # ì²˜ìŒ 3ê°œë§Œ
            name = schedule.get('name', 'N/A')
            location = schedule.get('location', 'N/A')
            priority = schedule.get('priority', 'N/A')
            
            logger.info(f"     ìœ ì—° {i+1}: {name}")
            logger.info(f"       ğŸ“ ìœ„ì¹˜: {location}")
            logger.info(f"       ğŸ¯ ìš°ì„ ìˆœìœ„: {priority}")
        
        if len(flexible_schedules) > 3:
            logger.info(f"     ... ìœ ì—° ì¼ì • {len(flexible_schedules) - 3}ê°œ ë” ìˆìŒ")
        
        logger.info("ğŸ‰ ë‹¨ì¼ ì˜µì…˜ í´ë°± ë°˜í™˜ ì¤€ë¹„ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ë‹¨ì¼ ì˜µì…˜ í´ë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        
        # ìµœì¢… ì‹¤íŒ¨ ì‹œ ì™„ì „íˆ ë¹ˆ ì˜µì…˜
        logger.warning("âš ï¸ ì˜¤ë¥˜ë¡œ ì¸í•´ ì™„ì „íˆ ë¹ˆ ì˜µì…˜ìœ¼ë¡œ í´ë°±")
        
        empty_result = {
            "options": [
                {
                    "optionId": 1,
                    "fixedSchedules": [],
                    "flexibleSchedules": []
                }
            ]
        }
        
        logger.info("âœ… ë¹ˆ ì˜µì…˜ í´ë°± ì™„ë£Œ")
        logger.info("   ë¹ˆ ì˜µì…˜ êµ¬ì„±:")
        logger.info("     ì˜µì…˜ ìˆ˜: 1ê°œ")
        logger.info("     ê³ ì • ì¼ì •: 0ê°œ")
        logger.info("     ìœ ì—° ì¼ì •: 0ê°œ")
        
        return empty_result

@app.post("/extract-schedule")
async def extract_schedule(request: ScheduleRequest):
    """ìˆ˜ì •ëœ ë‹¤ì¤‘ ì˜µì…˜ ì¼ì • ì¶”ì¶œ API - datetime ì˜¤ë¥˜ í•´ê²° + ìœ„ì¹˜ ì •ë³´ ë³´ê°•"""
    import datetime as dt  # ğŸ”¥ ì´ë¦„ì„ ë‹¤ë¥´ê²Œ í•´ì„œ ì¶©ëŒ ë°©ì§€
    import time
    import copy
    
    # ê°•ì œ ë¡œê¹… í•¨ìˆ˜
    def force_log(message):
        timestamp = dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        output = f"ğŸ”¥ {timestamp} - {message}"
        print(output)
        logger.info(message)
        return output
    
    force_log("=== ìˆ˜ì •ëœ ì¼ì • ì¶”ì¶œ ì‹œì‘ ===")
    force_log(f"ì…ë ¥ í…ìŠ¤íŠ¸: {request.voice_input}")
    force_log(f"ì…ë ¥ ê¸¸ì´: {len(request.voice_input)}ì")
    
    start_time = time.time()
    
    try:
        # Step 1: ê°„ë‹¨í•œ LLM ì²´ì¸ ìƒì„± (datetime ì˜¤ë¥˜ ìˆ˜ì •)
        force_log("Step 1: ìˆ˜ì •ëœ LLM ì²´ì¸ ìƒì„±")
        
        try:
            # ğŸ”¥ datetime ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì§ì ‘ êµ¬í˜„
            current_time = int(dt.datetime.now().timestamp() * 1000)
            today = dt.datetime.now()
            current_hour = today.hour
            
            # í˜„ì¬ ì‹œê°„ëŒ€ ì„¤ëª…
            if 6 <= current_hour < 12:
                current_time_desc = "ì˜¤ì „"
            elif 12 <= current_hour < 18:
                current_time_desc = "ì˜¤í›„"
            elif 18 <= current_hour < 22:
                current_time_desc = "ì €ë…"
            else:
                current_time_desc = "ë°¤"
            
            force_log(f"í˜„ì¬ ì‹œê°„: {current_hour}ì‹œ ({current_time_desc})")
            
            # ğŸ”¥ ê°„ë‹¨í•œ í…œí”Œë¦¿ (datetime ì˜¤ë¥˜ ì—†ì´)
            # ğŸ”¥ ê°œì„ ëœ í…œí”Œë¦¿ (ê°œë³„ ì¥ì†Œ ì¶”ì¶œ)
            simple_template = f"""ë‹¤ìŒ ìŒì„± ë©”ì‹œì§€ì—ì„œ **ëª¨ë“  ê°œë³„ ì¥ì†Œì™€ í™œë™**ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ìŒì„± ë©”ì‹œì§€: {request.voice_input}

í˜„ì¬ ì‹œê°„: {current_hour}ì‹œ ({current_time_desc})
í˜„ì¬ ë‚ ì§œ: {today.strftime('%Y-%m-%d')}

ğŸ”¥ **ì¤‘ìš”í•œ ì¶”ì¶œ ê·œì¹™**:
1. "Aì—ì„œ Bê¹Œì§€" â†’ Aì™€ Bë¥¼ **ê°ê° ë³„ë„ ì¼ì •**ìœ¼ë¡œ ì¶”ì¶œ
2. "ì¤‘ê°„ì— C" â†’ Cë¥¼ **ë³„ë„ ì¼ì •**ìœ¼ë¡œ ì¶”ì¶œ  
3. ëª¨ë“  ì¥ì†Œì™€ í™œë™ì„ **ê°œë³„ ì¼ì •**ìœ¼ë¡œ ë¶„ë¦¬
4. ì‹œê°„ ë°°ì¹˜: ì–¸ê¸‰ ìˆœì„œëŒ€ë¡œ ì‹œê°„ í• ë‹¹

**ì‹œê°„ ê·œì¹™**:
- "ì €ë…" â†’ 18:00~20:00
- "ì ì‹¬" â†’ 12:00~14:00  
- "ì•„ì¹¨" â†’ 08:00~10:00
- ìˆœì„œëŒ€ë¡œ ë°°ì¹˜ (ì´ë™ì‹œê°„ 30ë¶„ ê³ ë ¤)

**ì˜ˆì‹œ**:
ì…ë ¥: "ë¶€ì‚°ì—­ì—ì„œ ì¥ì „ì—­ê¹Œì§€ ê°€ëŠ”ë°, ì¤‘ê°„ì— ì €ë…ë¨¹ê³ ì‹¶ì–´"
â†’ 3ê°œ ì¼ì •: 1) ë¶€ì‚°ì—­ 2) ì €ë… ì‹ì‚¬ 3) ì¥ì „ì—­

JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
{{
  "fixedSchedules": [
    {{
      "id": "{current_time}_1",
      "name": "ë¶€ì‚°ì—­", 
      "type": "FIXED",
      "duration": 30,
      "priority": 1,
      "location": "",
      "latitude": 35.1,
      "longitude": 129.0,
      "startTime": "{today.strftime('%Y-%m-%d')}T15:00:00",
      "endTime": "{today.strftime('%Y-%m-%d')}T15:30:00"
    }},
    {{
      "id": "{current_time}_2",
      "name": "ì €ë… ì‹ì‚¬",
      "type": "FIXED", 
      "duration": 120,
      "priority": 2,
      "location": "",
      "latitude": 35.1,
      "longitude": 129.0,
      "startTime": "{today.strftime('%Y-%m-%d')}T18:00:00",
      "endTime": "{today.strftime('%Y-%m-%d')}T20:00:00"
    }},
    {{
      "id": "{current_time}_3",
      "name": "ì¥ì „ì—­",
      "type": "FIXED",
      "duration": 30,
      "priority": 3,
      "location": "",
      "latitude": 35.2,
      "longitude": 129.1,
      "startTime": "{today.strftime('%Y-%m-%d')}T20:30:00",
      "endTime": "{today.strftime('%Y-%m-%d')}T21:00:00"
    }}
  ],
  "flexibleSchedules": []
}}

ì£¼ì˜ì‚¬í•­:
1. **ê° ì¥ì†Œë¥¼ ê°œë³„ ì¼ì •ìœ¼ë¡œ ë¶„ë¦¬**
2. **"ì´ë™" ê°™ì€ ë§ ì‚¬ìš© ê¸ˆì§€** - ì¥ì†Œëª…ë§Œ ì‚¬ìš©
3. **ìˆœì„œëŒ€ë¡œ ì‹œê°„ ë°°ì¹˜** (ì´ë™ì‹œê°„ 30ë¶„ ê³ ë ¤)
4. **JSONë§Œ ë°˜í™˜**, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€"""
            
            force_log("âœ… í…œí”Œë¦¿ ìƒì„± ì„±ê³µ")
            
        except Exception as e:
            force_log(f"âŒ í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨: {e}")
            raise e
        
        # Step 2: LLM í˜¸ì¶œ (OpenAI ì§ì ‘ í˜¸ì¶œ)
        force_log("Step 2: OpenAI ì§ì ‘ í˜¸ì¶œ")
        
        try:
            response = openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì¼ì • ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ ìŒì„± ë©”ì‹œì§€ì—ì„œ ì¼ì •ì„ ì¶”ì¶œí•˜ì—¬ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”."
                    },
                    {"role": "user", "content": simple_template}
                ],
                temperature=0,
                max_tokens=1000
            )
            
            llm_content = response.choices[0].message.content.strip()
            force_log(f"âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹ : {len(llm_content)}ì")
            
            # JSON ì¶”ì¶œ
            if llm_content.startswith("```json"):
                llm_content = llm_content.replace("```json", "").replace("```", "").strip()
            
            schedule_data = json.loads(llm_content)
            force_log(f"âœ… JSON íŒŒì‹± ì„±ê³µ")
            
        except Exception as e:
            force_log(f"âŒ OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ìˆ˜ë™ìœ¼ë¡œ ì¼ì • ìƒì„±
            force_log("í´ë°±: ìˆ˜ë™ ì¼ì • ìƒì„±")
            
            # ì…ë ¥ í…ìŠ¤íŠ¸ ë¶„ì„
            voice_text = request.voice_input.lower()
            schedules = []
            
            # ë¶€ì‚°ì—­ ì°¾ê¸°
            if "ë¶€ì‚°ì—­" in voice_text:
                schedules.append({
                    "id": f"{current_time}_1",
                    "name": "ë¶€ì‚°ì—­",
                    "type": "FIXED",
                    "duration": 30,
                    "priority": 1,
                    "location": "ë¶€ì‚°ì—­",
                    "latitude": 35.1151,
                    "longitude": 129.0425,
                    "startTime": f"{today.strftime('%Y-%m-%d')}T10:00:00",
                    "endTime": f"{today.strftime('%Y-%m-%d')}T10:30:00"
                })
            
            # ì €ë… ì‹ì‚¬ ì°¾ê¸°
            if "ì €ë…" in voice_text or "ì‹ì‚¬" in voice_text:
                schedules.append({
                    "id": f"{current_time}_2",
                    "name": "ì €ë… ì‹ì‚¬",
                    "type": "FIXED",
                    "duration": 90,
                    "priority": 2,
                    "location": "",
                    "latitude": 35.1151,
                    "longitude": 129.0425,
                    "startTime": f"{today.strftime('%Y-%m-%d')}T18:00:00",
                    "endTime": f"{today.strftime('%Y-%m-%d')}T19:30:00"
                })
            
            # ì¥ì „ì—­ ì°¾ê¸°
            if "ì¥ì „ì—­" in voice_text:
                schedules.append({
                    "id": f"{current_time}_3",
                    "name": "ì¥ì „ì—­",
                    "type": "FIXED",
                    "duration": 30,
                    "priority": 3,
                    "location": "ì¥ì „ì—­",
                    "latitude": 35.2311,
                    "longitude": 129.0839,
                    "startTime": f"{today.strftime('%Y-%m-%d')}T20:00:00",
                    "endTime": f"{today.strftime('%Y-%m-%d')}T20:30:00"
                })
            
            schedule_data = {
                "fixedSchedules": schedules,
                "flexibleSchedules": []
            }
            
            force_log(f"âœ… ìˆ˜ë™ ì¼ì • ìƒì„± ì™„ë£Œ: {len(schedules)}ê°œ")
        
        # Step 3: ê²°ê³¼ íŒŒì‹± í™•ì¸
        force_log("Step 3: ê²°ê³¼ íŒŒì‹± í™•ì¸")
        
        fixed_count = len(schedule_data.get('fixedSchedules', []))
        flexible_count = len(schedule_data.get('flexibleSchedules', []))
        force_log(f"âœ… íŒŒì‹± ì™„ë£Œ - ê³ ì •: {fixed_count}ê°œ, ìœ ì—°: {flexible_count}ê°œ")
        
        # ğŸ”¥ Step 3.5: ëª¨ë“  ì¼ì •ì— ìœ„ì¹˜ ì •ë³´ ë³´ê°• (ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì „)
        force_log("Step 3.5: ìœ„ì¹˜ ì •ë³´ ë³´ê°•")
        try:
            enhanced_data = await asyncio.wait_for(
                enhance_locations_with_triple_api(schedule_data),
                timeout=20
            )
            force_log("âœ… ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì™„ë£Œ")
            schedule_data = enhanced_data
            
            # ìœ„ì¹˜ ì •ë³´ ë³´ê°• ê²°ê³¼ ë¡œê¹…
            for i, schedule in enumerate(schedule_data.get("fixedSchedules", [])):
                name = schedule.get('name', 'N/A')
                location = schedule.get('location', 'N/A')
                force_log(f"   ê³ ì • ì¼ì • {i+1}: {name} - {location}")
                
            for i, schedule in enumerate(schedule_data.get("flexibleSchedules", [])):
                name = schedule.get('name', 'N/A')
                location = schedule.get('location', 'N/A')
                force_log(f"   ìœ ì—° ì¼ì • {i+1}: {name} - {location}")
                
        except Exception as e:
            force_log(f"âš ï¸ ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹¤íŒ¨: {e}")
        
        # Step 4: ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±
        force_log("Step 4: ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ í™œìš© ë‹¤ì¤‘ ì˜µì…˜ ìƒì„±")
        
        try:
            # ğŸ”¥ ë°©ë²• 1: ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê° ì˜µì…˜ë³„ ë‹¤ë¥¸ ìœ„ì¹˜ ê²€ìƒ‰
            force_log("ê¸°ì¡´ ë‹¨ì¼ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜ í™œìš© ì‹œì‘...")
            
            options = []
            
            for option_num in range(5):  # 5ê°œ ì˜µì…˜ ìƒì„±
                force_log(f"ì˜µì…˜ {option_num + 1} ìƒì„± ì¤‘...")
                
                # ì›ë³¸ ì¼ì • ë³µì‚¬
                option_schedule_data = copy.deepcopy(schedule_data)
                
                # ê° ì˜µì…˜ë³„ë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ ì „ëµ ì ìš©
                search_strategies = [
                    "ë§›ì§‘",      # ì˜µì…˜ 1: ì¼ë°˜ ë§›ì§‘
                    "ê³ ê¸‰",      # ì˜µì…˜ 2: ê³ ê¸‰ ë ˆìŠ¤í† ë‘  
                    "ê°€ì„±ë¹„",    # ì˜µì…˜ 3: ê°€ì„±ë¹„ ë§›ì§‘
                    "ì¹´í˜",      # ì˜µì…˜ 4: ì¹´í˜/ë””ì €íŠ¸
                    "ìˆ ì§‘"       # ì˜µì…˜ 5: ìˆ ì§‘/íšŒì‹
                ]
                
                strategy = search_strategies[option_num]
                force_log(f"ì˜µì…˜ {option_num + 1} ì „ëµ: {strategy}")
                
                # ğŸ”¥ "ì €ë… ì‹ì‚¬" ì¼ì •ë§Œ ë‹¤ì‹œ ê²€ìƒ‰ (ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ)
                for i, schedule in enumerate(option_schedule_data.get("fixedSchedules", [])):
                    if "ì €ë…" in schedule.get("name", "") or "ì‹ì‚¬" in schedule.get("name", ""):
                        force_log(f"ì €ë… ì‹ì‚¬ ì¼ì • ì¬ê²€ìƒ‰: {strategy} ì „ëµ")
                        
                        # ë¶€ì‚° ì§€ì—­ì—ì„œ ì „ëµë³„ ê²€ìƒ‰
                        search_query = f"ë¶€ì‚° ê¸ˆì •êµ¬ {strategy}"
                        
                        # ì°¸ì¡° ìœ„ì¹˜ (ì¥ì „ì—­ ê·¼ì²˜)
                        reference_location = None
                        for ref_schedule in option_schedule_data.get("fixedSchedules", []):
                            if ref_schedule.get("location") and "ì¥ì „" in ref_schedule.get("location", ""):
                                reference_location = ref_schedule.get("location")
                                break
                        
                        # ğŸ”¥ ê¸°ì¡´ enhance_single_schedule_triple í•¨ìˆ˜ í™œìš©
                        try:
                            # ì„ì‹œë¡œ ìœ„ì¹˜ ì •ë³´ ì´ˆê¸°í™” (ì¬ê²€ìƒ‰ì„ ìœ„í•´)
                            temp_schedule = copy.deepcopy(schedule)
                            temp_schedule["name"] = f"{strategy} ì‹ì‚¬"  # ì „ëµë³„ ì´ë¦„ ë³€ê²½
                            temp_schedule["location"] = ""  # ìœ„ì¹˜ ì´ˆê¸°í™”í•˜ì—¬ ì¬ê²€ìƒ‰ ìœ ë„
                            
                            # ê¸°ì¡´ í•¨ìˆ˜ë¡œ ìœ„ì¹˜ ê²€ìƒ‰
                            enhanced_schedule = await enhance_single_schedule_triple(
                                temp_schedule, 
                                [{"location": reference_location}] if reference_location else []
                            )
                            
                            if enhanced_schedule.get("location"):
                                # ê²€ìƒ‰ ì„±ê³µì‹œ ì—…ë°ì´íŠ¸
                                schedule["name"] = enhanced_schedule["name"]
                                schedule["location"] = enhanced_schedule["location"] 
                                schedule["latitude"] = enhanced_schedule.get("latitude", 35.2311)
                                schedule["longitude"] = enhanced_schedule.get("longitude", 129.0839)
                                
                                # ì˜µì…˜ë³„ ê³ ìœ  ID ìƒì„±
                                schedule["id"] = f"{int(time.time() * 1000)}_{option_num + 1}_{i + 1}"
                                
                                force_log(f"âœ… ì˜µì…˜ {option_num + 1} ì €ë… ì‹ì‚¬ ì—…ë°ì´íŠ¸: {schedule['name']}")
                                force_log(f"   ğŸ“ ìœ„ì¹˜: {schedule['location']}")
                            else:
                                force_log(f"âš ï¸ ì˜µì…˜ {option_num + 1} ì¬ê²€ìƒ‰ ì‹¤íŒ¨, ì›ë³¸ ìœ ì§€")
                                
                        except Exception as e:
                            force_log(f"âš ï¸ ì˜µì…˜ {option_num + 1} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                
                # ë‹¤ë¥¸ ì¼ì •ë“¤ë„ ì˜µì…˜ë³„ ê³ ìœ  ID ë¶€ì—¬
                for schedule_list in [option_schedule_data.get("fixedSchedules", []), option_schedule_data.get("flexibleSchedules", [])]:
                    for j, schedule in enumerate(schedule_list):
                        if not schedule.get("id", "").endswith(f"_{option_num + 1}_"):
                            schedule["id"] = f"{int(time.time() * 1000)}_{option_num + 1}_{j + 1}"
                
                # ì˜µì…˜ ìƒì„±
                option = {
                    "optionId": option_num + 1,
                    "fixedSchedules": option_schedule_data.get("fixedSchedules", []),
                    "flexibleSchedules": option_schedule_data.get("flexibleSchedules", [])
                }
                
                options.append(option)
                force_log(f"âœ… ì˜µì…˜ {option_num + 1} ìƒì„± ì™„ë£Œ")
            
            final_result = {"options": options}
            option_count = len(options)
            force_log(f"âœ… ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ í™œìš© ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ: {option_count}ê°œ ì˜µì…˜")
            
        except Exception as e:
            force_log(f"âŒ ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ í™œìš© ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ë‹¨ìˆœí•œ ë‹¤ì¤‘ ì˜µì…˜ (í•˜ì§€ë§Œ IDëŠ” ë‹¤ë¥´ê²Œ)
            options = []
            for i in range(5):
                option_data = copy.deepcopy(schedule_data)
                
                # IDë§Œ ë‹¤ë¥´ê²Œ ì„¤ì •
                for schedule_list in [option_data.get("fixedSchedules", []), option_data.get("flexibleSchedules", [])]:
                    for j, schedule in enumerate(schedule_list):
                        schedule["id"] = f"{int(time.time() * 1000)}_{i + 1}_{j + 1}"
                
                option = {
                    "optionId": i + 1,
                    "fixedSchedules": option_data.get("fixedSchedules", []),
                    "flexibleSchedules": option_data.get("flexibleSchedules", [])
                }
                options.append(option)
            
            final_result = {"options": options}
            force_log("í´ë°±: ë‹¨ìˆœ ë‹¤ì¤‘ ì˜µì…˜ ìƒì„± ì™„ë£Œ")
        
        # Step 5: ìµœì¢… ì‘ë‹µ
        total_time = time.time() - start_time
        force_log(f"Step 5: ìµœì¢… ì™„ë£Œ - ì´ {total_time:.2f}ì´ˆ")
        
        option_count = len(final_result.get('options', []))
        force_log(f"ìµœì¢… ì˜µì…˜ ìˆ˜: {option_count}ê°œ")
        
        # ê° ì˜µì…˜ì˜ ì¼ì • ìˆ˜ ë¡œê¹…
        for i, option in enumerate(final_result.get('options', [])):
            fixed_count = len(option.get('fixedSchedules', []))
            flexible_count = len(option.get('flexibleSchedules', []))
            force_log(f"ì˜µì…˜ {i+1}: ê³ ì • {fixed_count}ê°œ, ìœ ì—° {flexible_count}ê°œ")
            
            # ì²« ë²ˆì§¸ ì˜µì…˜ì˜ ì¼ì • ìƒì„¸ ë¡œê¹…
            if i == 0:
                for j, schedule in enumerate(option.get('fixedSchedules', [])):
                    name = schedule.get('name', 'N/A')
                    location = schedule.get('location', 'N/A')
                    start_time = schedule.get('startTime', 'N/A')
                    force_log(f"  ì¼ì • {j+1}: {name} ({location}) {start_time}")
        
        force_log("=== ìˆ˜ì •ëœ ì¼ì • ì¶”ì¶œ ì™„ë£Œ ===")
        
        return UnicodeJSONResponse(content=final_result, status_code=200)
    
    except Exception as e:
        force_log(f"âŒ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
        force_log(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        
        # ìµœì¢… í´ë°±
        current_time = int(dt.datetime.now().timestamp() * 1000)
        today = dt.datetime.now()
        
        fallback_result = {
            "options": [
                {
                    "optionId": 1,
                    "fixedSchedules": [
                        {
                            "id": f"{current_time}_fallback",
                            "name": "ì¼ì • ì¶”ì¶œ ì‹¤íŒ¨",
                            "type": "FIXED",
                            "duration": 60,
                            "priority": 1,
                            "location": "ì˜¤ë¥˜ ë°œìƒ",
                            "latitude": 37.5665,
                            "longitude": 126.9780,
                            "startTime": f"{today.strftime('%Y-%m-%d')}T12:00:00",
                            "endTime": f"{today.strftime('%Y-%m-%d')}T13:00:00"
                        }
                    ],
                    "flexibleSchedules": []
                }
            ],
            "error": str(e)
        }
        
        force_log("ìµœì¢… í´ë°± ê²°ê³¼ ë°˜í™˜")
        return UnicodeJSONResponse(content=fallback_result, status_code=200)

 
# ì„œë²„ ì‹œì‘
if __name__ == "__main__":
    import uvicorn
    
    # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì„œë²„ ì‹œì‘
    uvicorn.run(
        "app:app", 
        host="0.0.0.0", 
        port=8082, 
        reload=True,
        # í•œê¸€ ì§€ì›ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        access_log=True,
        log_config={
            "version": 1,
            "disable_existing_loggers": False,
            "formatters": {
                "default": {
                    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                },
            },
            "handlers": {
                "default": {
                    "formatter": "default",
                    "class": "logging.StreamHandler",
                    "stream": "ext://sys.stdout",
                },
            },
            "root": {
                "level": "INFO",
                "handlers": ["default"],
            },
        }
    )