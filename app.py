import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from typing import Dict, List, Any, Optional
import os
import json
import re
import time
import datetime
from dotenv import load_dotenv
import aiohttp
import math
from openai import OpenAI

# ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ ì„í¬íŠ¸
from scheduler.utils import detect_and_resolve_time_conflicts
from scheduler import (
    create_enhancement_chain,
    apply_time_inference,
    apply_priorities,
    enhance_schedule_with_relationships,
    parse_datetime
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") 
GOOGLE_MAPS_API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")
KAKAO_REST_API_KEY = os.getenv("KAKAO_REST_API_KEY", "357d3401893dc5c9cbefc83bb65df4ee")
FOURSQUARE_API_KEY = os.getenv("FOURSQUARE_API_KEY", "fsq3VpVQLn5hZptfpIHLogZHRb7vAbteiSkiUlZT4QvpC8U=")

if not OPENAI_API_KEY:
    logger.error("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    raise ValueError("OPENAI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="3ì¤‘ API ì •í™•í•œ ì£¼ì†Œ ê²€ìƒ‰ ì¼ì • ì¶”ì¶œ API", version="3.0.0")

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í•œêµ­ ì§€ì—­ ì •ë³´
KOREA_REGIONS = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": {"ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
               "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
               "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"},
    "ë¶€ì‚°ê´‘ì—­ì‹œ": {"ê°•ì„œêµ¬", "ê¸ˆì •êµ¬", "ê¸°ì¥êµ°", "ë‚¨êµ¬", "ë™êµ¬", "ë™ë˜êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë¶êµ¬", "ì‚¬ìƒêµ¬",
               "ì‚¬í•˜êµ¬", "ì„œêµ¬", "ìˆ˜ì˜êµ¬", "ì—°ì œêµ¬", "ì˜ë„êµ¬", "ì¤‘êµ¬", "í•´ìš´ëŒ€êµ¬"},
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": {"ë‚¨êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬", "ìˆ˜ì„±êµ¬", "ì¤‘êµ¬"},
    "ì¸ì²œê´‘ì—­ì‹œ": {"ê°•í™”êµ°", "ê³„ì–‘êµ¬", "ë‚¨ë™êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ë¶€í‰êµ¬", "ì„œêµ¬", "ì—°ìˆ˜êµ¬", "ì˜¹ì§„êµ°", "ì¤‘êµ¬"},
    "ê´‘ì£¼ê´‘ì—­ì‹œ": {"ê´‘ì‚°êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ì„œêµ¬"},
    "ëŒ€ì „ê´‘ì—­ì‹œ": {"ëŒ€ë•êµ¬", "ë™êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ì¤‘êµ¬"},
    "ìš¸ì‚°ê´‘ì—­ì‹œ": {"ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°", "ì¤‘êµ¬"},
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {"ì„¸ì¢…ì‹œ"},
    "ê²½ê¸°ë„": {"ê°€í‰êµ°", "ê³ ì–‘ì‹œ", "ê³¼ì²œì‹œ", "ê´‘ëª…ì‹œ", "ê´‘ì£¼ì‹œ", "êµ¬ë¦¬ì‹œ", "êµ°í¬ì‹œ", "ê¹€í¬ì‹œ", "ë‚¨ì–‘ì£¼ì‹œ",
             "ë™ë‘ì²œì‹œ", "ë¶€ì²œì‹œ", "ì„±ë‚¨ì‹œ", "ìˆ˜ì›ì‹œ", "ì‹œí¥ì‹œ", "ì•ˆì‚°ì‹œ", "ì•ˆì„±ì‹œ", "ì•ˆì–‘ì‹œ", "ì–‘ì£¼ì‹œ",
             "ì–‘í‰êµ°", "ì—¬ì£¼ì‹œ", "ì—°ì²œêµ°", "ì˜¤ì‚°ì‹œ", "ìš©ì¸ì‹œ", "ì˜ì™•ì‹œ", "ì˜ì •ë¶€ì‹œ", "ì´ì²œì‹œ", "íŒŒì£¼ì‹œ",
             "í‰íƒì‹œ", "í¬ì²œì‹œ", "í•˜ë‚¨ì‹œ", "í™”ì„±ì‹œ"},
    "ê°•ì›íŠ¹ë³„ìì¹˜ë„": {"ê°•ë¦‰ì‹œ", "ê³ ì„±êµ°", "ë™í•´ì‹œ", "ì‚¼ì²™ì‹œ", "ì†ì´ˆì‹œ", "ì–‘êµ¬êµ°", "ì–‘ì–‘êµ°", "ì˜ì›”êµ°", "ì›ì£¼ì‹œ",
                  "ì¸ì œêµ°", "ì •ì„ êµ°", "ì² ì›êµ°", "ì¶˜ì²œì‹œ", "íƒœë°±ì‹œ", "í‰ì°½êµ°", "í™ì²œêµ°", "í™”ì²œêµ°", "íš¡ì„±êµ°"},
    "ì¶©ì²­ë¶ë„": {"ê´´ì‚°êµ°", "ë‹¨ì–‘êµ°", "ë³´ì€êµ°", "ì˜ë™êµ°", "ì˜¥ì²œêµ°", "ìŒì„±êµ°", "ì œì²œì‹œ", "ì¦í‰êµ°", "ì§„ì²œêµ°", "ì²­ì£¼ì‹œ", "ì¶©ì£¼ì‹œ"},
    "ì¶©ì²­ë‚¨ë„": {"ê³„ë£¡ì‹œ", "ê³µì£¼ì‹œ", "ê¸ˆì‚°êµ°", "ë…¼ì‚°ì‹œ", "ë‹¹ì§„ì‹œ", "ë³´ë ¹ì‹œ", "ë¶€ì—¬êµ°", "ì„œì‚°ì‹œ", "ì„œì²œêµ°",
             "ì•„ì‚°ì‹œ", "ì˜ˆì‚°êµ°", "ì²œì•ˆì‹œ", "ì²­ì–‘êµ°", "íƒœì•ˆêµ°", "í™ì„±êµ°"},
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„": {"ê³ ì°½êµ°", "êµ°ì‚°ì‹œ", "ê¹€ì œì‹œ", "ë‚¨ì›ì‹œ", "ë¬´ì£¼êµ°", "ë¶€ì•ˆêµ°", "ìˆœì°½êµ°", "ì™„ì£¼êµ°",
                  "ìµì‚°ì‹œ", "ì„ì‹¤êµ°", "ì¥ìˆ˜êµ°", "ì „ì£¼ì‹œ", "ì •ìì‹œ", "ì§„ì•ˆêµ°"},
    "ì „ë¼ë‚¨ë„": {"ê°•ì§„êµ°", "ê³ í¥êµ°", "ê³¡ì„±êµ°", "ê´‘ì–‘ì‹œ", "êµ¬ë¡€êµ°", "ë‚˜ì£¼ì‹œ", "ë‹´ì–‘êµ°", "ëª©í¬ì‹œ", "ë¬´ì•ˆêµ°",
             "ë³´ì„±êµ°", "ìˆœì²œì‹œ", "ì‹ ì•ˆêµ°", "ì—¬ìˆ˜ì‹œ", "ì˜ê´‘êµ°", "ì˜ì•”êµ°", "ì™„ë„êµ°", "ì¥ì„±êµ°", "ì¥í¥êµ°",
             "ì§„ë„êµ°", "í•¨í‰êµ°", "í•´ë‚¨êµ°", "í™”ìˆœêµ°"},
    "ê²½ìƒë¶ë„": {"ê²½ì‚°ì‹œ", "ê²½ì£¼ì‹œ", "ê³ ë ¹êµ°", "êµ¬ë¯¸ì‹œ", "êµ°ìœ„êµ°", "ê¹€ì²œì‹œ", "ë¬¸ê²½ì‹œ", "ë´‰í™”êµ°", "ìƒì£¼ì‹œ",
             "ì„±ì£¼êµ°", "ì•ˆë™ì‹œ", "ì˜ë•êµ°", "ì˜ì–‘êµ°", "ì˜ì£¼ì‹œ", "ì˜ì²œì‹œ", "ì˜ˆì²œêµ°", "ìš¸ë¦‰êµ°", "ìš¸ì§„êµ°",
             "ì˜ì„±êµ°", "ì²­ë„êµ°", "ì²­ì†¡êµ°", "ì¹ ê³¡êµ°", "í¬í•­ì‹œ"},
    "ê²½ìƒë‚¨ë„": {"ê±°ì œì‹œ", "ê±°ì°½êµ°", "ê³ ì„±êµ°", "ê¹€í•´ì‹œ", "ë‚¨í•´êµ°", "ë°€ì–‘ì‹œ", "ì‚¬ì²œì‹œ", "ì‚°ì²­êµ°", "ì–‘ì‚°ì‹œ",
             "ì˜ë ¹êµ°", "ì§„ì£¼ì‹œ", "ì°½ë…•êµ°", "ì°½ì›ì‹œ", "í†µì˜ì‹œ", "í•˜ë™êµ°", "í•¨ì•ˆêµ°", "í•¨ì–‘êµ°", "í•©ì²œêµ°"},
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {"ì„œê·€í¬ì‹œ", "ì œì£¼ì‹œ"}
}
def clean_korean_text(text: str) -> str:
    import re
    cleaned = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,()-]', '', text)
    return cleaned.strip()
# ----- ëª¨ë¸ ì •ì˜ -----
class ScheduleRequest(BaseModel):
    voice_input: str

class UnicodeJSONResponse(JSONResponse):
    def render(self, content) -> bytes:
        return json.dumps(
            content,
            ensure_ascii=False,  # ğŸ‘ˆ í•µì‹¬! í•œê¸€ì„ ìœ ë‹ˆì½”ë“œ ê·¸ëŒ€ë¡œ ì¶œë ¥
            separators=(',', ':'),
            indent=None
        ).encode('utf-8')  # ğŸ‘ˆ UTF-8ë¡œ ì¸ì½”ë”©
    
class FixedSchedule(BaseModel):
    id: str
    name: str
    type: str = "FIXED"
    duration: int = 60
    priority: float  = 1.0
    location: str = ""
    latitude: float = 37.5665
    longitude: float = 126.9780
    startTime: str
    endTime: str

class FlexibleSchedule(BaseModel):
    id: str
    name: str
    type: str = "FLEXIBLE"
    duration: int = 60
    priority: float  = 3.0
    location: str = ""
    latitude: float = 37.5665
    longitude: float = 126.9780

class ExtractScheduleResponse(BaseModel):
    fixedSchedules: List[FixedSchedule] = []
    flexibleSchedules: List[FlexibleSchedule] = []

class LocationAnalysis(BaseModel):
    place_name: str
    region: str
    district: str
    category: str
    search_keywords: List[str]

class PlaceResult(BaseModel):
    name: str
    address: str
    latitude: float
    longitude: float
    source: str  # foursquare, kakao, google
    rating: Optional[float] = None


def safe_parse_json(json_str):
    """ì•ˆì „í•œ JSON íŒŒì‹± - í•œê¸€ ì§€ì›"""
    try:
        if isinstance(json_str, str):
            # í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
            return json.loads(json_str, strict=False)
        else:
            return json_str
    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ (í•œê¸€ í¬í•¨): {str(e)}")
        return {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }

def normalize_priorities(schedules_data: Dict[str, Any]) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì •ìˆ˜ë¡œ ì •ê·œí™”"""
    logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ìˆ˜ ë³€í™˜ ì‹œì‘")
    
    all_schedules = []
    all_schedules.extend(schedules_data.get("fixedSchedules", []))
    all_schedules.extend(schedules_data.get("flexibleSchedules", []))
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    all_schedules.sort(key=lambda s: s.get("priority", 999))
    
    # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ë¡œ ì¬í• ë‹¹
    for i, schedule in enumerate(all_schedules):
        old_priority = schedule.get("priority", "ì—†ìŒ")
        new_priority = i + 1
        schedule["priority"] = new_priority
        logger.info(f"ìš°ì„ ìˆœìœ„ ì •ê·œí™”: '{schedule.get('name', '')}' {old_priority} â†’ {new_priority}")
    
    # ë‹¤ì‹œ ë¶„ë¥˜
    fixed_schedules = [s for s in all_schedules if s.get("type") == "FIXED" and "startTime" in s]
    flexible_schedules = [s for s in all_schedules if s.get("type") != "FIXED" or "startTime" not in s]
    
    logger.info(f"âœ… ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì™„ë£Œ: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
    
    return {
        "fixedSchedules": fixed_schedules,
        "flexibleSchedules": flexible_schedules
    }
# ----- ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ -----
class AddressQualityChecker:
    """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ ë° ì¬ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
    
    @staticmethod
    def is_complete_address(address: str) -> bool:
        """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦"""
        if not address or address.strip() == "":
            return False
        
        # ê¸°ë³¸ ê²€ì¦
        address_lower = address.lower()
        
        # 1. ë„ˆë¬´ ì§§ì€ ì£¼ì†Œ (ë‹¨ì–´ 2ê°œ ì´í•˜)
        words = [word for word in address.split() if len(word) > 1]
        if len(words) <= 2:
            logger.info(f"âŒ ì£¼ì†Œ ë„ˆë¬´ ì§§ìŒ: {address} ({len(words)}ê°œ ë‹¨ì–´)")
            return False
        
        # 2. ëª¨í˜¸í•œ í‘œí˜„ ì²´í¬
        vague_terms = ["ê·¼ì²˜", "ì¸ê·¼", "ì£¼ë³€", "ê·¼ë°©", "ë¶€ê·¼", "ì¼ëŒ€", "ë™ë„¤"]
        if any(term in address for term in vague_terms):
            logger.info(f"âŒ ëª¨í˜¸í•œ ì£¼ì†Œ í‘œí˜„: {address}")
            return False
        
        # 3. í•œêµ­ ì£¼ì†Œ í•„ìˆ˜ ìš”ì†Œ ì²´í¬
        korean_regions = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        has_region = any(region in address for region in korean_regions)
        
        # 4. ìƒì„¸ ì£¼ì†Œ ìš”ì†Œ ì²´í¬ (êµ¬/ì‹œ/êµ° + ë™/ì/ë©´)
        detail_keywords = ["êµ¬", "ì‹œ", "êµ°", "ë™", "ì", "ë©´", "ë¡œ", "ê¸¸", "ê°€"]
        has_detail = any(keyword in address for keyword in detail_keywords)
        
        # 5. ê±´ë¬¼ëª…ì´ë‚˜ ë²ˆì§€ìˆ˜ ì²´í¬
        import re
        has_number = bool(re.search(r'\d+', address))
        
        quality_score = has_region + has_detail + has_number
        is_complete = quality_score >= 2  # 3ì  ë§Œì ì— 2ì  ì´ìƒ
        
        logger.info(f"ğŸ“Š ì£¼ì†Œ í’ˆì§ˆ ì ìˆ˜: {quality_score}/3 - {address}")
        logger.info(f"   ì§€ì—­í¬í•¨: {has_region}, ìƒì„¸ìš”ì†Œ: {has_detail}, ë²ˆì§€í¬í•¨: {has_number}")
        logger.info(f"   ì™„ì „ì„±: {'âœ… ì™„ì „' if is_complete else 'âŒ ë¶ˆì™„ì „'}")
        
        return is_complete
    
    @staticmethod
    def get_category_keywords(place_name: str) -> List[str]:
        """ì¥ì†Œëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        name_lower = place_name.lower()
        keywords = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        category_map = {
            "ì¹´í˜": ["ì¹´í˜", "ì»¤í”¼", "coffee", "dessert", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"],
            "ì‹ë‹¹": ["ì‹ë‹¹", "ë§›ì§‘", "ìŒì‹ì ", "ë ˆìŠ¤í† ë‘", "restaurant", "food"],
            "íšŒì˜": ["íšŒì˜ì‹¤", "ì˜¤í”¼ìŠ¤", "ì‚¬ë¬´ì‹¤", "ì»¨í¼ëŸ°ìŠ¤", "meeting"],
            "íšŒì‹": ["ìˆ ì§‘", "bar", "pub", "í˜¸í”„", "ì´ìì¹´ì•¼", "restaurant"],
            "ì‡¼í•‘": ["ì‡¼í•‘ëª°", "ë°±í™”ì ", "ë§ˆíŠ¸", "ìƒì ", "mall"],
            "ìˆ™ë°•": ["í˜¸í…”", "ëª¨í…”", "íœì…˜", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤", "ë¦¬ì¡°íŠ¸"]
        }
        
        for category, words in category_map.items():
            if any(word in name_lower for word in words):
                keywords.extend(words)
                logger.info(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ '{category}' ê°ì§€: {words}")
                break
        
        # ê¸°ë³¸ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¥ì†Œëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if not keywords:
            keywords = [place_name]
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°
class TripleLocationSearchService:
    """Foursquare + Kakao + Google 3ì¤‘ ìœ„ì¹˜ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    async def analyze_location_with_gpt(text: str, reference_location: Optional[str] = None) -> LocationAnalysis:
        """GPTë¡œ ì •í™•í•œ ì§€ì—­ê³¼ ì¥ì†Œ ë¶„ì„ - ì°¸ì¡° ìœ„ì¹˜ ì¶”ê°€"""
        
        # setì„ listë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
        korea_regions_list = {region: list(districts) for region, districts in KOREA_REGIONS.items()}
        regions_text = json.dumps(korea_regions_list, ensure_ascii=False, indent=2)
        
        # ì°¸ì¡° ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
        reference_context = ""
        if reference_location:
            reference_context = f"\nì°¸ì¡° ìœ„ì¹˜ (ì´ì „ ì¼ì •): {reference_location}"
            reference_context += "\n'ê·¼ì²˜', 'ì£¼ë³€' ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ì´ ì°¸ì¡° ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”."
        
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ì˜ ì •í™•í•œ ì§€ì—­ ì •ë³´ì™€ ì¥ì†Œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"{reference_context}

í•œêµ­ ì§€ì—­ ì •ë³´:
{regions_text}

**ì¤‘ìš”**: 
1. "ê·¼ì²˜", "ì£¼ë³€" ê°™ì€ í‘œí˜„ì´ ìˆìœ¼ë©´ ì°¸ì¡° ìœ„ì¹˜ì™€ ê°™ì€ ì§€ì—­ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
2. ëª¨í˜¸í•œ í‘œí˜„("ì¹´í˜", "ì‹ë‹¹")ë„ ì°¸ì¡° ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ ê²€ìƒ‰í•˜ë„ë¡ ì§€ì—­ì„ ì„¤ì •í•˜ì„¸ìš”.
3. êµ¬ì²´ì ì¸ ì¥ì†Œëª…(ì˜ˆ: ìš¸ì‚°ëŒ€í•™êµ, ë¬¸ìˆ˜ì›”ë“œì»µê²½ê¸°ì¥)ì€ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ìš°ì„ í•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "place_name": "ì¶”ì¶œëœ ì¥ì†Œëª…",
  "region": "ì‹œ/ë„ (ì°¸ì¡° ìœ„ì¹˜ ê³ ë ¤)",
  "district": "ì‹œ/êµ°/êµ¬ (ì°¸ì¡° ìœ„ì¹˜ ê³ ë ¤)",
  "category": "ì¥ì†Œ ì¹´í…Œê³ ë¦¬",
  "search_keywords": ["ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œë“¤", "ì§€ì—­ëª…+ì¥ì†Œëª…", "ì¹´í…Œê³ ë¦¬ëª…"]
}}
"""

        try:
            response = openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì§€ì—­ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì°¸ì¡° ìœ„ì¹˜ë¥¼ ê³ ë ¤í•˜ì—¬ 'ê·¼ì²˜', 'ì£¼ë³€' í‘œí˜„ì„ ì •í™•í•˜ê²Œ í•´ì„í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=300,
            )

            content = response.choices[0].message.content.strip()
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(content)
            return LocationAnalysis(**data)
            
        except Exception as e:
            logger.error(f"âŒ GPT ì§€ì—­ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ì°¸ì¡° ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ ê°™ì€ ì§€ì—­ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
            if reference_location:
                # ì°¸ì¡° ìœ„ì¹˜ì—ì„œ ì§€ì—­ ì¶”ì¶œ ì‹œë„
                for region in ["ìš¸ì‚°", "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „"]:
                    if region in reference_location:
                        return LocationAnalysis(
                            place_name=text,
                            region=f"{region}ê´‘ì—­ì‹œ" if region != "ì„œìš¸" else "ì„œìš¸íŠ¹ë³„ì‹œ",
                            district="ì¤‘êµ¬",  # ê¸°ë³¸ê°’
                            category="ì¥ì†Œ",
                            search_keywords=[f"{region} {text}", text]
                        )
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return LocationAnalysis(
                place_name=text,
                region="ì„œìš¸íŠ¹ë³„ì‹œ",
                district="ì¤‘êµ¬",
                category="ì¥ì†Œ",
                search_keywords=[text]
            )

    @staticmethod
    async def search_foursquare(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """1ìˆœìœ„: Foursquare API ê²€ìƒ‰ - ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ê°•í™”"""
        if not FOURSQUARE_API_KEY:
            logger.warning("âŒ Foursquare API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 1ìˆœìœ„ Foursquare ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            # ì§€ì—­ ì¢Œí‘œ (ê¸°ì¡´ê³¼ ë™ì¼)
            region_coords = {
                # íŠ¹ë³„ì‹œÂ·ê´‘ì—­ì‹œ
                "ì„œìš¸íŠ¹ë³„ì‹œ": {"lat": 37.5665, "lng": 126.9780},
                "ë¶€ì‚°ê´‘ì—­ì‹œ": {"lat": 35.1796, "lng": 129.0756},
                "ëŒ€êµ¬ê´‘ì—­ì‹œ": {"lat": 35.8714, "lng": 128.6014},
                "ì¸ì²œê´‘ì—­ì‹œ": {"lat": 37.4563, "lng": 126.7052},
                "ê´‘ì£¼ê´‘ì—­ì‹œ": {"lat": 35.1595, "lng": 126.8526},
                "ëŒ€ì „ê´‘ì—­ì‹œ": {"lat": 36.3504, "lng": 127.3845},
                "ìš¸ì‚°ê´‘ì—­ì‹œ": {"lat": 35.5384, "lng": 129.3114},
                
                # íŠ¹ë³„ìì¹˜ì‹œÂ·íŠ¹ë³„ìì¹˜ë„
                "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": {"lat": 36.4800, "lng": 127.2890},
                "ì œì£¼íŠ¹ë³„ìì¹˜ë„": {"lat": 33.4996, "lng": 126.5312},
                
                # ê²½ê¸°ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ê¸°ë„": {"lat": 37.4138, "lng": 127.5183},
                "ê°€í‰êµ°": {"lat": 37.8313, "lng": 127.5109},
                "ê³ ì–‘ì‹œ": {"lat": 37.6584, "lng": 126.8320},
                "ê³¼ì²œì‹œ": {"lat": 37.4292, "lng": 126.9876},
                "ê´‘ëª…ì‹œ": {"lat": 37.4784, "lng": 126.8664},
                "ê´‘ì£¼ì‹œ": {"lat": 37.4297, "lng": 127.2550},
                "êµ¬ë¦¬ì‹œ": {"lat": 37.5943, "lng": 127.1296},
                "êµ°í¬ì‹œ": {"lat": 37.3614, "lng": 126.9350},
                "ê¹€í¬ì‹œ": {"lat": 37.6150, "lng": 126.7158},
                "ë‚¨ì–‘ì£¼ì‹œ": {"lat": 37.6369, "lng": 127.2165},
                "ë™ë‘ì²œì‹œ": {"lat": 37.9036, "lng": 127.0606},
                "ë¶€ì²œì‹œ": {"lat": 37.5036, "lng": 126.7660},
                "ì„±ë‚¨ì‹œ": {"lat": 37.4201, "lng": 127.1262},
                "ìˆ˜ì›ì‹œ": {"lat": 37.2636, "lng": 127.0286},
                "ì‹œí¥ì‹œ": {"lat": 37.3803, "lng": 126.8030},
                "ì•ˆì‚°ì‹œ": {"lat": 37.3236, "lng": 126.8219},
                "ì•ˆì„±ì‹œ": {"lat": 37.0078, "lng": 127.2797},
                "ì•ˆì–‘ì‹œ": {"lat": 37.3943, "lng": 126.9568},
                "ì–‘ì£¼ì‹œ": {"lat": 37.7853, "lng": 127.0456},
                "ì–‘í‰êµ°": {"lat": 37.4916, "lng": 127.4874},
                "ì—¬ì£¼ì‹œ": {"lat": 37.2982, "lng": 127.6376},
                "ì—°ì²œêµ°": {"lat": 38.0960, "lng": 127.0751},
                "ì˜¤ì‚°ì‹œ": {"lat": 37.1499, "lng": 127.0776},
                "ìš©ì¸ì‹œ": {"lat": 37.2411, "lng": 127.1776},
                "ì˜ì™•ì‹œ": {"lat": 37.3448, "lng": 126.9687},
                "ì˜ì •ë¶€ì‹œ": {"lat": 37.7381, "lng": 127.0339},
                "ì´ì²œì‹œ": {"lat": 37.2724, "lng": 127.4349},
                "íŒŒì£¼ì‹œ": {"lat": 37.7598, "lng": 126.7800},
                "í‰íƒì‹œ": {"lat": 36.9921, "lng": 127.1127},
                "í¬ì²œì‹œ": {"lat": 37.8950, "lng": 127.2003},
                "í•˜ë‚¨ì‹œ": {"lat": 37.5394, "lng": 127.2147},
                "í™”ì„±ì‹œ": {"lat": 37.1996, "lng": 126.8310},
                
                # ê°•ì›íŠ¹ë³„ìì¹˜ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê°•ì›íŠ¹ë³„ìì¹˜ë„": {"lat": 37.8228, "lng": 128.1555},
                "ê°•ë¦‰ì‹œ": {"lat": 37.7519, "lng": 128.8761},
                "ê³ ì„±êµ°": {"lat": 38.3806, "lng": 128.4678},
                "ë™í•´ì‹œ": {"lat": 37.5244, "lng": 129.1144},
                "ì‚¼ì²™ì‹œ": {"lat": 37.4501, "lng": 129.1649},
                "ì†ì´ˆì‹œ": {"lat": 38.2070, "lng": 128.5918},
                "ì–‘êµ¬êµ°": {"lat": 38.1065, "lng": 127.9897},
                "ì–‘ì–‘êµ°": {"lat": 38.0759, "lng": 128.6190},
                "ì˜ì›”êµ°": {"lat": 37.1839, "lng": 128.4617},
                "ì›ì£¼ì‹œ": {"lat": 37.3422, "lng": 127.9202},
                "ì¸ì œêµ°": {"lat": 38.0695, "lng": 128.1707},
                "ì •ì„ êµ°": {"lat": 37.3801, "lng": 128.6607},
                "ì² ì›êµ°": {"lat": 38.1465, "lng": 127.3134},
                "ì¶˜ì²œì‹œ": {"lat": 37.8813, "lng": 127.7298},
                "íƒœë°±ì‹œ": {"lat": 37.1641, "lng": 128.9856},
                "í‰ì°½êµ°": {"lat": 37.3708, "lng": 128.3897},
                "í™ì²œêµ°": {"lat": 37.6971, "lng": 127.8888},
                "í™”ì²œêµ°": {"lat": 38.1063, "lng": 127.7082},
                "íš¡ì„±êµ°": {"lat": 37.4916, "lng": 127.9856},
                
                # ì¶©ì²­ë¶ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì¶©ì²­ë¶ë„": {"lat": 36.4919, "lng": 127.7417},
                "ê´´ì‚°êµ°": {"lat": 36.8154, "lng": 127.7874},
                "ë‹¨ì–‘êµ°": {"lat": 36.9845, "lng": 128.3659},
                "ë³´ì€êµ°": {"lat": 36.4894, "lng": 127.7293},
                "ì˜ë™êµ°": {"lat": 36.1750, "lng": 127.7764},
                "ì˜¥ì²œêµ°": {"lat": 36.3061, "lng": 127.5721},
                "ìŒì„±êµ°": {"lat": 36.9433, "lng": 127.6864},
                "ì œì²œì‹œ": {"lat": 37.1326, "lng": 128.1909},
                "ì¦í‰êµ°": {"lat": 36.7848, "lng": 127.5814},
                "ì§„ì²œêµ°": {"lat": 36.8565, "lng": 127.4335},
                "ì²­ì£¼ì‹œ": {"lat": 36.4919, "lng": 127.7417},
                "ì¶©ì£¼ì‹œ": {"lat": 36.9910, "lng": 127.9259},
                
                # ì¶©ì²­ë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì¶©ì²­ë‚¨ë„": {"lat": 36.5184, "lng": 126.8000},
                "ê³„ë£¡ì‹œ": {"lat": 36.2742, "lng": 127.2489},
                "ê³µì£¼ì‹œ": {"lat": 36.4464, "lng": 127.1248},
                "ê¸ˆì‚°êµ°": {"lat": 36.1088, "lng": 127.4881},
                "ë…¼ì‚°ì‹œ": {"lat": 36.1872, "lng": 127.0985},
                "ë‹¹ì§„ì‹œ": {"lat": 36.8934, "lng": 126.6292},
                "ë³´ë ¹ì‹œ": {"lat": 36.3334, "lng": 126.6127},
                "ë¶€ì—¬êµ°": {"lat": 36.2756, "lng": 126.9098},
                "ì„œì‚°ì‹œ": {"lat": 36.7848, "lng": 126.4503},
                "ì„œì²œêµ°": {"lat": 36.0805, "lng": 126.6919},
                "ì•„ì‚°ì‹œ": {"lat": 36.7898, "lng": 127.0019},
                "ì˜ˆì‚°êµ°": {"lat": 36.6826, "lng": 126.8503},
                "ì²œì•ˆì‹œ": {"lat": 36.8151, "lng": 127.1139},
                "ì²­ì–‘êµ°": {"lat": 36.4590, "lng": 126.8025},
                "íƒœì•ˆêµ°": {"lat": 36.7456, "lng": 126.2983},
                "í™ì„±êµ°": {"lat": 36.6012, "lng": 126.6608},
                
                # ì „ë¶íŠ¹ë³„ìì¹˜ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì „ë¶íŠ¹ë³„ìì¹˜ë„": {"lat": 35.7175, "lng": 127.1530},
                "ê³ ì°½êµ°": {"lat": 35.4346, "lng": 126.7017},
                "êµ°ì‚°ì‹œ": {"lat": 35.9678, "lng": 126.7368},
                "ê¹€ì œì‹œ": {"lat": 35.8033, "lng": 126.8805},
                "ë‚¨ì›ì‹œ": {"lat": 35.4163, "lng": 127.3906},
                "ë¬´ì£¼êµ°": {"lat": 36.0073, "lng": 127.6610},
                "ë¶€ì•ˆêµ°": {"lat": 35.7318, "lng": 126.7332},
                "ìˆœì°½êµ°": {"lat": 35.3748, "lng": 127.1374},
                "ì™„ì£¼êµ°": {"lat": 35.9058, "lng": 127.1649},
                "ìµì‚°ì‹œ": {"lat": 35.9483, "lng": 126.9575},
                "ì„ì‹¤êµ°": {"lat": 35.6176, "lng": 127.2896},
                "ì¥ìˆ˜êµ°": {"lat": 35.6477, "lng": 127.5217},
                "ì „ì£¼ì‹œ": {"lat": 35.8242, "lng": 127.1480},
                "ì •ìì‹œ": {"lat": 35.5700, "lng": 126.8557},
                "ì§„ì•ˆêµ°": {"lat": 35.7917, "lng": 127.4244},
                
                # ì „ë¼ë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ì „ë¼ë‚¨ë„": {"lat": 34.8679, "lng": 126.9910},
                "ê°•ì§„êµ°": {"lat": 34.6417, "lng": 126.7669},
                "ê³ í¥êµ°": {"lat": 34.6111, "lng": 127.2855},
                "ê³¡ì„±êµ°": {"lat": 35.2818, "lng": 127.2914},
                "ê´‘ì–‘ì‹œ": {"lat": 34.9406, "lng": 127.5956},
                "êµ¬ë¡€êµ°": {"lat": 35.2020, "lng": 127.4632},
                "ë‚˜ì£¼ì‹œ": {"lat": 35.0160, "lng": 126.7107},
                "ë‹´ì–‘êµ°": {"lat": 35.3214, "lng": 126.9882},
                "ëª©í¬ì‹œ": {"lat": 34.8118, "lng": 126.3922},
                "ë¬´ì•ˆêµ°": {"lat": 34.9900, "lng": 126.4816},
                "ë³´ì„±êµ°": {"lat": 34.7712, "lng": 127.0800},
                "ìˆœì²œì‹œ": {"lat": 34.9507, "lng": 127.4872},
                "ì‹ ì•ˆêµ°": {"lat": 34.8267, "lng": 126.1063},
                "ì—¬ìˆ˜ì‹œ": {"lat": 34.7604, "lng": 127.6622},
                "ì˜ê´‘êµ°": {"lat": 35.2773, "lng": 126.5120},
                "ì˜ì•”êµ°": {"lat": 34.8000, "lng": 126.6968},
                "ì™„ë„êµ°": {"lat": 34.3105, "lng": 126.7551},
                "ì¥ì„±êµ°": {"lat": 35.3017, "lng": 126.7886},
                "ì¥í¥êµ°": {"lat": 34.6816, "lng": 126.9066},
                "ì§„ë„êµ°": {"lat": 34.4867, "lng": 126.2636},
                "í•¨í‰êµ°": {"lat": 35.0666, "lng": 126.5168},
                "í•´ë‚¨êµ°": {"lat": 34.5736, "lng": 126.5986},
                "í™”ìˆœêµ°": {"lat": 35.0648, "lng": 126.9855},
                
                # ê²½ìƒë¶ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ìƒë¶ë„": {"lat": 36.4919, "lng": 128.8889},
                "ê²½ì‚°ì‹œ": {"lat": 35.8251, "lng": 128.7411},
                "ê²½ì£¼ì‹œ": {"lat": 35.8562, "lng": 129.2247},
                "ê³ ë ¹êµ°": {"lat": 35.7284, "lng": 128.2634},
                "êµ¬ë¯¸ì‹œ": {"lat": 36.1196, "lng": 128.3441},
                "êµ°ìœ„êµ°": {"lat": 36.2393, "lng": 128.5717},
                "ê¹€ì²œì‹œ": {"lat": 36.1395, "lng": 128.1137},
                "ë¬¸ê²½ì‹œ": {"lat": 36.5866, "lng": 128.1866},
                "ë´‰í™”êµ°": {"lat": 36.8932, "lng": 128.7327},
                "ìƒì£¼ì‹œ": {"lat": 36.4107, "lng": 128.1590},
                "ì„±ì£¼êµ°": {"lat": 35.9186, "lng": 128.2829},
                "ì•ˆë™ì‹œ": {"lat": 36.5684, "lng": 128.7294},
                "ì˜ë•êµ°": {"lat": 36.4153, "lng": 129.3655},
                "ì˜ì–‘êµ°": {"lat": 36.6666, "lng": 129.1124},
                "ì˜ì£¼ì‹œ": {"lat": 36.8056, "lng": 128.6239},
                "ì˜ì²œì‹œ": {"lat": 35.9733, "lng": 128.9386},
                "ì˜ˆì²œêµ°": {"lat": 36.6580, "lng": 128.4517},
                "ìš¸ë¦‰êµ°": {"lat": 37.4845, "lng": 130.9058},
                "ìš¸ì§„êµ°": {"lat": 36.9930, "lng": 129.4004},
                "ì˜ì„±êµ°": {"lat": 36.3526, "lng": 128.6974},
                "ì²­ë„êµ°": {"lat": 35.6477, "lng": 128.7363},
                "ì²­ì†¡êµ°": {"lat": 36.4359, "lng": 129.0572},
                "ì¹ ê³¡êµ°": {"lat": 35.9951, "lng": 128.4019},
                "í¬í•­ì‹œ": {"lat": 36.0190, "lng": 129.3435},
                
                # ê²½ìƒë‚¨ë„ ë° í•˜ìœ„ ì‹œÂ·êµ°
                "ê²½ìƒë‚¨ë„": {"lat": 35.4606, "lng": 128.2132},
                "ê±°ì œì‹œ": {"lat": 34.8804, "lng": 128.6212},
                "ê±°ì°½êµ°": {"lat": 35.6869, "lng": 127.9095},
                "ê³ ì„±êµ°": {"lat": 34.9735, "lng": 128.3229},
                "ê¹€í•´ì‹œ": {"lat": 35.2342, "lng": 128.8899},
                "ë‚¨í•´êµ°": {"lat": 34.8375, "lng": 127.8926},
                "ë°€ì–‘ì‹œ": {"lat": 35.5040, "lng": 128.7469},
                "ì‚¬ì²œì‹œ": {"lat": 35.0036, "lng": 128.0645},
                "ì‚°ì²­êµ°": {"lat": 35.4150, "lng": 127.8736},
                "ì–‘ì‚°ì‹œ": {"lat": 35.3350, "lng": 129.0371},
                "ì˜ë ¹êµ°": {"lat": 35.3219, "lng": 128.2618},
                "ì§„ì£¼ì‹œ": {"lat": 35.1800, "lng": 128.1076},
                "ì°½ë…•êµ°": {"lat": 35.5444, "lng": 128.4924},
                "ì°½ì›ì‹œ": {"lat": 35.2281, "lng": 128.6811},
                "í†µì˜ì‹œ": {"lat": 34.8544, "lng": 128.4331},
                "í•˜ë™êµ°": {"lat": 35.0675, "lng": 127.7514},
                "í•¨ì•ˆêµ°": {"lat": 35.2730, "lng": 128.4069},
                "í•¨ì–‘êµ°": {"lat": 35.5203, "lng": 127.7252},
                "í•©ì²œêµ°": {"lat": 35.5666, "lng": 128.1655},
            }
                        
            coords = region_coords.get(analysis.region, {"lat": 37.5665, "lng": 126.9780})
            
            url = "https://api.foursquare.com/v3/places/search"
            headers = {
                "Authorization": FOURSQUARE_API_KEY,
                "Accept": "application/json"
            }
            
            # ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§ ì¶”ê°€
            category_filters = {
                "ëŒ€í•™êµ": ["ëŒ€í•™êµ", "ëŒ€í•™", "university", "college"],
                "ê²½ê¸°ì¥": ["ê²½ê¸°ì¥", "stadium", "ìŠ¤í¬ì¸ ", "ì¶•êµ¬"],
                "ì‹ë‹¹": ["ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "restaurant", "ìŒì‹", "ë§›ì§‘"],
                "ì¹´í˜": ["ì¹´í˜", "ì»¤í”¼", "coffee", "cafe", "ë””ì €íŠ¸"]
            }
            
            # ê²€ìƒ‰ ì „ëµ ê°œì„ 
            search_strategies = []
            
            # 1) êµ¬ì²´ì ì¸ ì¥ì†Œëª… (ëŒ€í•™êµ, ê²½ê¸°ì¥ ë“±)
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ', 'ê³µí•­', 'ì—­']):
                search_strategies.append(analysis.place_name)
            
            # 2) ì§€ì—­ëª… + ì¥ì†Œëª…
            region_name = analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '')
            search_strategies.append(f"{region_name} {analysis.place_name}")
            
            # 3) ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ê²€ìƒ‰
            place_lower = analysis.place_name.lower()
            if "ì‹ë‹¹" in place_lower or "restaurant" in analysis.category.lower():
                search_strategies.extend([
                    f"{region_name} ë§›ì§‘",
                    f"{region_name} ì‹ë‹¹",
                    f"{region_name} restaurant"
                ])
            elif "ì¹´í˜" in place_lower or "cafe" in analysis.category.lower():
                search_strategies.extend([
                    f"{region_name} ì¹´í˜",
                    f"{region_name} ì»¤í”¼",
                    f"{region_name} cafe"
                ])
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        "query": strategy,
                        "ll": f"{coords['lat']},{coords['lng']}",
                        "radius": 15000,
                        "limit": 15,
                        "sort": "DISTANCE"
                    }
                    
                    logger.info(f"ğŸ” Foursquare ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get("results"):
                                    logger.info(f"âœ… Foursquare ê²°ê³¼ {len(data['results'])}ê°œ ë°œê²¬")
                                    
                                    # ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ì ìˆ˜ ê³„ì‚° ê°•í™”
                                    for i, place in enumerate(data["results"]):
                                        location = place.get("geocodes", {}).get("main", {})
                                        address = place.get("location", {}).get("formatted_address", "")
                                        place_name = place.get("name", "")
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        
                                        if not (location.get("latitude") and location.get("longitude")):
                                            continue
                                        
                                        # ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_keywords = [
                                            analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', ''),
                                            analysis.district
                                        ]
                                        region_match = any(keyword in address for keyword in region_keywords if keyword)
                                        
                                        # ì¥ì†Œëª… ìœ ì‚¬ë„ í™•ì¸ (ê°•í™”)
                                        name_similarity = 0
                                        search_terms = analysis.place_name.lower().split()
                                        place_terms = place_name.lower().split()
                                        
                                        for term in search_terms:
                                            if len(term) > 1:
                                                if any(term in pt for pt in place_terms):
                                                    name_similarity += 1
                                        
                                        # ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ í™•ì¸ (ìƒˆë¡œ ì¶”ê°€)
                                        category_match = 0
                                        for category, keywords in category_filters.items():
                                            if category in analysis.place_name.lower():
                                                for keyword in keywords:
                                                    if keyword in place_name.lower():
                                                        category_match += 1
                                                        break
                                        
                                        # ë¶€ì •ì ì¸ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (í•™ì›, ë³‘ì› ë“± ì œì™¸)
                                        negative_keywords = ["í•™ì›", "ë³‘ì›", "ì˜ì›", "í´ë¦¬ë‹‰", "academy", "hospital"]
                                        is_negative = any(neg in place_name.lower() for neg in negative_keywords)
                                        
                                        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
                                        score = (1 if region_match else 0) + (name_similarity * 0.5) + (category_match * 0.3)
                                        
                                        # ë¶€ì •ì  í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì ìˆ˜ ëŒ€í­ ê°ì†Œ
                                        if is_negative:
                                            score = max(0, score - 1.0)
                                        
                                        logger.info(f"     ì§€ì—­ì¼ì¹˜: {region_match}, ì´ë¦„ìœ ì‚¬ë„: {name_similarity}, ì¹´í…Œê³ ë¦¬ë§¤ì¹˜: {category_match}, ë¶€ì •ì : {is_negative}, ì ìˆ˜: {score}")
                                        
                                        # ìµœì†Œ ì ìˆ˜ ê¸°ì¤€ ìƒí–¥ ì¡°ì •
                                        if score >= 1.0:  # 0.5 â†’ 1.0ìœ¼ë¡œ ìƒí–¥
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=location["latitude"],
                                                longitude=location["longitude"],
                                                source="foursquare",
                                                rating=place.get("rating")
                                            )
                                            
                                            logger.info(f"âœ… Foursquare ê²€ìƒ‰ ì„±ê³µ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ ê²€ìƒ‰ì–´ '{strategy}' - ê²°ê³¼ ì—†ìŒ")
                            else:
                                logger.warning(f"âš ï¸ Foursquare API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Foursquare ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Foursquare ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def enhanced_search_with_quality_check(place_text: str) -> Optional[PlaceResult]:
        """ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦ê³¼ ì¬ê²€ìƒ‰ì„ í¬í•¨í•œ í–¥ìƒëœ ê²€ìƒ‰"""
        logger.info(f"ğŸ” í–¥ìƒëœ í’ˆì§ˆ ê²€ì¦ ê²€ìƒ‰ ì‹œì‘: {place_text}")
        
        # 1ë‹¨ê³„: ê¸°ë³¸ 3ì¤‘ API ê²€ìƒ‰
        result = await TripleLocationSearchService.search_triple_api(place_text)
        
        # 2ë‹¨ê³„: ì£¼ì†Œ ì™„ì „ì„± ê²€ì¦
        if result and AddressQualityChecker.is_complete_address(result.address):
            logger.info(f"âœ… 1ì°¨ ê²€ìƒ‰ ì„±ê³µ (ì™„ì „í•œ ì£¼ì†Œ): {result.address}")
            return result
        
        logger.warning(f"âš ï¸ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ ë¶ˆì™„ì „: {result.address if result else 'None'}")
        
        # 3ë‹¨ê³„: ì¬ê²€ìƒ‰ ì „ëµ
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_text)
        category_keywords = AddressQualityChecker.get_category_keywords(place_text)
        
        logger.info(f"ğŸ”„ ì¬ê²€ìƒ‰ ì‹œì‘ - ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ: {category_keywords}")
        
        # 4ë‹¨ê³„: í™•ì¥ ê²€ìƒ‰ (ë°˜ê²½ í™•ëŒ€ + ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ)
        for radius in [1000, 2000, 5000, 10000]:  # 1km â†’ 10kmê¹Œì§€ í™•ëŒ€
            logger.info(f"ğŸ” í™•ì¥ ê²€ìƒ‰ (ë°˜ê²½ {radius}m)")
            
            for keyword in category_keywords:
                enhanced_query = f"{analysis.region} {analysis.district} {keyword}"
                
                # Kakao í™•ì¥ ê²€ìƒ‰
                kakao_result = await TripleLocationSearchService.search_kakao_enhanced(
                    analysis, enhanced_query, radius
                )
                
                if kakao_result and AddressQualityChecker.is_complete_address(kakao_result.address):
                    logger.info(f"âœ… Kakao í™•ì¥ ê²€ìƒ‰ ì„±ê³µ: {kakao_result.address}")
                    return kakao_result
                
                # Google í™•ì¥ ê²€ìƒ‰
                google_result = await TripleLocationSearchService.search_google_enhanced(
                    analysis, enhanced_query
                )
                
                if google_result and AddressQualityChecker.is_complete_address(google_result.address):
                    logger.info(f"âœ… Google í™•ì¥ ê²€ìƒ‰ ì„±ê³µ: {google_result.address}")
                    return google_result
        
        # 5ë‹¨ê³„: ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì£¼ì†Œê°€ ì™„ì „í•˜ì§€ ì•Šë”ë¼ë„)
        if result:
            logger.warning(f"âš ï¸ í™•ì¥ ê²€ìƒ‰ ì‹¤íŒ¨, 1ì°¨ ê²°ê³¼ ì‚¬ìš©: {result.address}")
            return result
        
        logger.error(f"âŒ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {place_text}")
        return None

    @staticmethod
    async def search_kakao_enhanced(analysis: LocationAnalysis, query: str, radius: int) -> Optional[PlaceResult]:
        """Kakao API í™•ì¥ ê²€ìƒ‰"""
        if not KAKAO_REST_API_KEY:
            return None
            
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
            
            params = {
                "query": query,
                "size": 10,  # ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                "radius": radius
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get("documents"):
                            # ê°€ì¥ ì™„ì „í•œ ì£¼ì†Œë¥¼ ê°€ì§„ ê²°ê³¼ ì„ íƒ
                            for place in data["documents"]:
                                address = place.get("road_address_name") or place.get("address_name", "")
                                
                                if AddressQualityChecker.is_complete_address(address):
                                    return PlaceResult(
                                        name=place.get("place_name", analysis.place_name),
                                        address=address,
                                        latitude=float(place.get("y", 0)),
                                        longitude=float(place.get("x", 0)),
                                        source="kakao_enhanced"
                                    )
                                    
        except Exception as e:
            logger.error(f"âŒ Kakao í™•ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None

    @staticmethod
    async def search_google_enhanced(analysis: LocationAnalysis, query: str) -> Optional[PlaceResult]:
        """Google Places API í™•ì¥ ê²€ìƒ‰ - ìˆ˜ì •ëœ ë²„ì „"""
        if not GOOGLE_MAPS_API_KEY:
            return None
            
        try:
            url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
            
            # ì§€ì—­ ì œí•œ ê°•í™”
            region_query = f"{analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '')} {analysis.district} {query}"
            
            params = {
                'input': region_query,
                'inputtype': 'textquery',
                'fields': 'name,formatted_address,geometry,rating',
                'language': 'ko',
                'region': 'kr',
                'key': GOOGLE_MAPS_API_KEY
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get('status') == 'OK' and data.get('candidates'):
                            for place in data['candidates']:
                                address = place.get('formatted_address', '')
                                
                                # ì§€ì—­ ì¼ì¹˜ í™•ì¸ ê°•í™”
                                region_match = any(region_name in address for region_name in 
                                                 [analysis.region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', ''), 
                                                  analysis.district])
                                
                                if AddressQualityChecker.is_complete_address(address) and region_match:
                                    location = place['geometry']['location']
                                    return PlaceResult(
                                        name=place.get('name', analysis.place_name),
                                        address=address,
                                        latitude=location['lat'],
                                        longitude=location['lng'],
                                        source="google_enhanced",
                                        rating=place.get('rating')
                                    )
                                    
        except Exception as e:
            logger.error(f"âŒ Google í™•ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return None


    @staticmethod
    async def search_kakao(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """1ìˆœìœ„: Kakao API ê²€ìƒ‰ - ê°•í™”ëœ ë²„ì „"""
        if not KAKAO_REST_API_KEY:
            logger.warning("âŒ Kakao API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 1ìˆœìœ„ Kakao ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
            
            # ê²€ìƒ‰ ì „ëµ - êµ¬ì²´ì ì¸ ê²ƒë¶€í„° ì¼ë°˜ì ì¸ ê²ƒê¹Œì§€
            search_strategies = []
            
            # 1) êµ¬ì²´ì  ì¥ì†Œëª… (ëŒ€í•™êµ, ê²½ê¸°ì¥ ë“±)
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ', 'ê³µí•­', 'ì—­']):
                search_strategies.append(analysis.place_name)
                search_strategies.append(f"{analysis.region.replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ì‹œ', '')} {analysis.place_name}")
            
            # 2) ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
            place_lower = analysis.place_name.lower()
            region_name = analysis.region.replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ì‹œ', '')
            
            if any(word in place_lower for word in ['ì‹ë‹¹', 'restaurant', 'ë§›ì§‘']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} ë§›ì§‘",
                    f"{region_name} {analysis.district} ì‹ë‹¹",
                    f"{region_name} ë§›ì§‘",
                    f"{region_name} ì‹ë‹¹"
                ])
            elif any(word in place_lower for word in ['ì¹´í˜', 'cafe', 'ì»¤í”¼']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} ì¹´í˜",
                    f"{region_name} {analysis.district} ì»¤í”¼",
                    f"{region_name} ì¹´í˜",
                    f"{region_name} ì»¤í”¼ìˆ"
                ])
            else:
                # ì¼ë°˜ ê²€ìƒ‰
                search_strategies.extend([
                    f"{region_name} {analysis.place_name}",
                    f"{region_name} {analysis.district} {analysis.place_name}"
                ])
            
            logger.info(f"ğŸ” Kakao ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        "query": strategy,
                        "size": 15,  # ë” ë§ì€ ê²°ê³¼
                        "sort": "accuracy"  # ì •í™•ë„ìˆœ
                    }
                    
                    logger.info(f"ğŸ” Kakao ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, headers=headers, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get("documents"):
                                    logger.info(f"âœ… Kakao ê²°ê³¼ {len(data['documents'])}ê°œ ë°œê²¬")
                                    
                                    for i, place in enumerate(data["documents"]):
                                        place_name = place.get("place_name", "")
                                        address = place.get("road_address_name") or place.get("address_name", "")
                                        category = place.get("category_name", "")
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address} ({category})")
                                        
                                        if not address.strip():
                                            continue
                                        
                                        # ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_keywords = [
                                            analysis.region.replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ì‹œ', ''),
                                            analysis.district
                                        ]
                                        region_match = any(keyword in address for keyword in region_keywords if keyword)
                                        
                                        # ì¹´í…Œê³ ë¦¬ ì í•©ì„± í™•ì¸
                                        category_match = False
                                        if "ì‹ë‹¹" in analysis.place_name.lower() or "restaurant" in analysis.category.lower():
                                            category_match = any(word in category for word in ["ìŒì‹ì ", "ì‹ë‹¹", "ë ˆìŠ¤í† ë‘", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ì¹´í˜"])
                                        elif "ì¹´í˜" in analysis.place_name.lower() or "cafe" in analysis.category.lower():
                                            category_match = any(word in category for word in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"])
                                        elif "ëŒ€í•™êµ" in analysis.place_name.lower():
                                            category_match = any(word in category for word in ["ëŒ€í•™êµ", "í•™êµ", "êµìœ¡"])
                                        elif "ê²½ê¸°ì¥" in analysis.place_name.lower():
                                            category_match = any(word in category for word in ["ìŠ¤í¬ì¸ ", "ê²½ê¸°ì¥", "ì²´ìœ¡"])
                                        else:
                                            category_match = True  # ê¸°íƒ€ëŠ” ì¼ë‹¨ í—ˆìš©
                                        
                                        # ë¶€ì •ì  í‚¤ì›Œë“œ í•„í„°
                                        negative_keywords = ["í•™ì›", "ë³‘ì›", "ì˜ì›", "í´ë¦¬ë‹‰", "ì•½êµ­"]
                                        is_negative = any(neg in place_name for neg in negative_keywords)
                                        
                                        # ì ìˆ˜ ê³„ì‚°
                                        score = 0
                                        if region_match:
                                            score += 2
                                        if category_match:
                                            score += 1
                                        if is_negative:
                                            score -= 2
                                        
                                        logger.info(f"     ì§€ì—­ì¼ì¹˜: {region_match}, ì¹´í…Œê³ ë¦¬ì í•©: {category_match}, ë¶€ì •ì : {is_negative}, ì ìˆ˜: {score}")
                                        
                                        if score >= 1:  # ìµœì†Œ ì ìˆ˜
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=float(place.get("y", 0)),
                                                longitude=float(place.get("x", 0)),
                                                source="kakao"
                                            )
                                            
                                            logger.info(f"âœ… Kakao ê²€ìƒ‰ ì„±ê³µ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            logger.info(f"   ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {category}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ Kakao ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ Kakao ê²€ìƒ‰ì–´ '{strategy}' - ê²°ê³¼ ì—†ìŒ")
                            else:
                                logger.warning(f"âš ï¸ Kakao API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ Kakao ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Kakao ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Kakao ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def search_google(analysis: LocationAnalysis) -> Optional[PlaceResult]:
        """2ìˆœìœ„: Google Places API ê²€ìƒ‰ - ê°•í™”ëœ ë²„ì „"""
        if not GOOGLE_MAPS_API_KEY:
            logger.warning("âŒ Google API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        logger.info(f"ğŸ” 2ìˆœìœ„ Google ê²€ìƒ‰: {analysis.place_name}")
        
        try:
            url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
            
            # ê²€ìƒ‰ ì „ëµ
            region_name = analysis.region.replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ì‹œ', '')
            search_strategies = []
            
            # êµ¬ì²´ì  ì¥ì†Œëª…
            if any(keyword in analysis.place_name.lower() for keyword in ['ëŒ€í•™êµ', 'ê²½ê¸°ì¥', 'ì›”ë“œì»µ']):
                search_strategies.extend([
                    f"{region_name} {analysis.place_name}",
                    analysis.place_name
                ])
            
            # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
            place_lower = analysis.place_name.lower()
            if any(word in place_lower for word in ['ì‹ë‹¹', 'restaurant']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} restaurant",
                    f"{region_name} ë§›ì§‘"
                ])
            elif any(word in place_lower for word in ['ì¹´í˜', 'cafe']):
                search_strategies.extend([
                    f"{region_name} {analysis.district} cafe",
                    f"{region_name} ì¹´í˜"
                ])
            
            logger.info(f"ğŸ” Google ê²€ìƒ‰ ì „ëµ: {search_strategies}")
            
            for strategy in search_strategies:
                try:
                    params = {
                        'input': strategy,
                        'inputtype': 'textquery',
                        'fields': 'name,formatted_address,geometry,rating,types',
                        'language': 'ko',
                        'region': 'kr',
                        'key': GOOGLE_MAPS_API_KEY
                    }
                    
                    logger.info(f"ğŸ” Google ê²€ìƒ‰ì–´: '{strategy}'")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(url, params=params) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                if data.get('status') == 'OK' and data.get('candidates'):
                                    logger.info(f"âœ… Google ê²°ê³¼ {len(data['candidates'])}ê°œ ë°œê²¬")
                                    
                                    for i, place in enumerate(data['candidates']):
                                        place_name = place.get('name', '')
                                        address = place.get('formatted_address', '')
                                        types = place.get('types', [])
                                        
                                        logger.info(f"   í›„ë³´ {i+1}: {place_name} - {address}")
                                        logger.info(f"     íƒ€ì…: {types}")
                                        
                                        # ì§€ì—­ ì¼ì¹˜ í™•ì¸
                                        region_keywords = [region_name, analysis.district]
                                        region_match = any(keyword in address for keyword in region_keywords if keyword)
                                        
                                        # íƒ€ì… ì í•©ì„± í™•ì¸
                                        type_match = False
                                        if "ì‹ë‹¹" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["restaurant", "food", "meal_takeaway"])
                                        elif "ì¹´í˜" in analysis.place_name.lower():  
                                            type_match = any(t in types for t in ["cafe", "bakery"])
                                        elif "ëŒ€í•™êµ" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["university", "school"])
                                        elif "ê²½ê¸°ì¥" in analysis.place_name.lower():
                                            type_match = any(t in types for t in ["stadium", "gym"])
                                        else:
                                            type_match = True
                                        
                                        score = (1 if region_match else 0) + (1 if type_match else 0)
                                        logger.info(f"     ì§€ì—­ì¼ì¹˜: {region_match}, íƒ€ì…ì í•©: {type_match}, ì ìˆ˜: {score}")
                                        
                                        if score >= 1:
                                            location = place['geometry']['location']
                                            result = PlaceResult(
                                                name=place_name,
                                                address=address,
                                                latitude=location['lat'],
                                                longitude=location['lng'],
                                                source="google",
                                                rating=place.get('rating')
                                            )
                                            
                                            logger.info(f"âœ… Google ê²€ìƒ‰ ì„±ê³µ: {result.name}")
                                            logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                                            return result
                                    
                                    logger.info(f"âš ï¸ Google ê²€ìƒ‰ì–´ '{strategy}' - ì ì ˆí•œ ê²°ê³¼ ì—†ìŒ")
                                else:
                                    logger.info(f"âš ï¸ Google API ì‘ë‹µ: {data.get('status', 'UNKNOWN')}")
                            else:
                                logger.warning(f"âš ï¸ Google API ì˜¤ë¥˜: {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ Google ê²€ìƒ‰ì–´ '{strategy}' ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ Google ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ Google ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨: {analysis.place_name}")
        return None

    @staticmethod
    async def search_triple_api(place_text: str) -> Optional[PlaceResult]:
        """3ì¤‘ API ìˆœì°¨ ê²€ìƒ‰ - ì¹´ì¹´ì˜¤ ìš°ì„ ìœ¼ë¡œ ë³€ê²½"""
        logger.info(f"ğŸ¯ 3ì¤‘ API ê²€ìƒ‰ ì‹œì‘: {place_text}")
        
        # 1ë‹¨ê³„: GPTë¡œ ì§€ì—­ ë¶„ì„
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_text)
        logger.info(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {analysis.region} {analysis.district} - {analysis.place_name}")
        
        # 2ë‹¨ê³„: ê²€ìƒ‰ ìˆœì„œ ê²°ì • - ì¹´ì¹´ì˜¤ ìš°ì„ !
        search_methods = [
            ("Kakao (1ìˆœìœ„)", TripleLocationSearchService.search_kakao),
            ("Google (2ìˆœìœ„)", TripleLocationSearchService.search_google),
            ("Foursquare (3ìˆœìœ„)", TripleLocationSearchService.search_foursquare)
        ]
        
        for api_name, search_method in search_methods:
            try:
                result = await asyncio.wait_for(search_method(analysis), timeout=10)
                if result and result.address and result.address.strip():
                    logger.info(f"ğŸ‰ {api_name}ì—ì„œ ê²€ìƒ‰ ì„±ê³µ!")
                    return result
                else:
                    logger.info(f"âš ï¸ {api_name} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, ë‹¤ìŒ API ì‹œë„...")
            except asyncio.TimeoutError:
                logger.warning(f"â° {api_name} ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ")
            except Exception as e:
                logger.error(f"âŒ {api_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # ëª¨ë“  API ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¢Œí‘œ ë°˜í™˜
        logger.warning(f"âš ï¸ ëª¨ë“  API ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ì¢Œí‘œ ì‚¬ìš©: {place_text}")
        return None

# ----- ë¹„ë™ê¸° ìœ„ì¹˜ ì •ë³´ ë³´ê°• -----
async def enhance_locations_with_triple_api(schedule_data: Dict) -> Dict:
    """3ì¤‘ APIë¡œ ìœ„ì¹˜ ì •ë³´ ë³´ê°• - ì°¸ì¡° ìœ„ì¹˜ í™œìš©"""
    logger.info("ğŸš€ 3ì¤‘ API ìœ„ì¹˜ ì •ë³´ ë³´ê°• ì‹œì‘")
    
    try:
        enhanced_data = json.loads(json.dumps(schedule_data))
        
        # ëª¨ë“  ì¼ì • ìˆ˜ì§‘ (ìˆœì„œëŒ€ë¡œ)
        all_schedules = []
        all_schedules.extend(enhanced_data.get("fixedSchedules", []))
        all_schedules.extend(enhanced_data.get("flexibleSchedules", []))
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì´ì „ ì¼ì •ì˜ ìœ„ì¹˜ë¥¼ ì°¸ì¡°ë¡œ í™œìš©
        processed_schedules = []
        
        for i, schedule in enumerate(all_schedules):
            # ì´ì „ ì²˜ë¦¬ëœ ì¼ì •ë“¤ì„ ì°¸ì¡°ë¡œ ì „ë‹¬
            enhanced_schedule = await enhance_single_schedule_triple(schedule, processed_schedules)
            processed_schedules.append(enhanced_schedule)
        
        logger.info(f"âœ… 3ì¤‘ API ìœ„ì¹˜ ë³´ê°• ì™„ë£Œ: {len(processed_schedules)}ê°œ ì²˜ë¦¬")
        
        return enhanced_data
        
    except Exception as e:
        logger.error(f"âŒ 3ì¤‘ API ìœ„ì¹˜ ë³´ê°• ì‹¤íŒ¨: {e}")
        return schedule_data

def _is_reasonable_distance(address1: str, address2: str) -> bool:
    """ë‘ ì£¼ì†Œê°€ í•©ë¦¬ì ì¸ ê±°ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
    try:
        # ì‹œ/ë„ ë‹¨ìœ„ ë¹„êµ
        regions1 = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        
        region1 = None
        region2 = None
        
        for region in regions1:
            if region in address1:
                region1 = region
            if region in address2:
                region2 = region
        
        # ê°™ì€ ê´‘ì—­ì‹œ/ë„ë©´ OK
        if region1 == region2:
            return True
        
        # ì¸ì ‘ ì§€ì—­ í—ˆìš© (ì˜ˆ: ì„œìš¸-ê²½ê¸°, ë¶€ì‚°-ê²½ë‚¨ ë“±)
        adjacent_regions = {
            "ì„œìš¸": ["ê²½ê¸°"],
            "ê²½ê¸°": ["ì„œìš¸", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨"],
            "ë¶€ì‚°": ["ê²½ë‚¨"],
            "ê²½ë‚¨": ["ë¶€ì‚°", "ê²½ë¶"],
            "ìš¸ì‚°": ["ê²½ë‚¨", "ê²½ë¶"],
            "ëŒ€êµ¬": ["ê²½ë¶", "ê²½ë‚¨"]
        }
        
        if region1 in adjacent_regions and region2 in adjacent_regions[region1]:
            return True
        if region2 in adjacent_regions and region1 in adjacent_regions[region2]:
            return True
            
        # ê·¸ ì™¸ëŠ” ë„ˆë¬´ ë©€ë‹¤ê³  íŒë‹¨
        logger.info(f"ğŸ“ ê±°ë¦¬ ì²´í¬: {region1} vs {region2} - ë„ˆë¬´ ë©€ìŒ")
        return False
        
    except Exception:
        return True  # ì˜¤ë¥˜ ì‹œ í—ˆìš©
    
async def enhance_single_schedule_triple(schedule: Dict, reference_schedules: List[Dict] = None):
    """ë‹¨ì¼ ì¼ì •ì˜ 3ì¤‘ API + í’ˆì§ˆ ê²€ì¦ ìœ„ì¹˜ ê²€ìƒ‰ - ì¹´ì¹´ì˜¤ ìš°ì„ """
    place_name = schedule.get("name", "")
    if not place_name:
        return schedule
    
    logger.info(f"ğŸ¯ í’ˆì§ˆ ê²€ì¦ ìœ„ì¹˜ ê²€ìƒ‰: {place_name}")
    
    # ì°¸ì¡° ìœ„ì¹˜ ì°¾ê¸°
    reference_location = None
    if reference_schedules:
        for ref_schedule in reference_schedules:
            if ref_schedule.get("location") and ref_schedule["location"].strip():
                reference_location = ref_schedule["location"]
                logger.info(f"ğŸ“ ì°¸ì¡° ìœ„ì¹˜ ì„¤ì •: {reference_location}")
                break
    
    try:
        # ì°¸ì¡° ìœ„ì¹˜ë¥¼ ê³ ë ¤í•œ ë¶„ì„
        analysis = await TripleLocationSearchService.analyze_location_with_gpt(place_name, reference_location)
        
        # ì¹´ì¹´ì˜¤ ìš°ì„  ê²€ìƒ‰ ìˆœì„œ
        search_methods = [
            ("Kakao", TripleLocationSearchService.search_kakao),
            ("Google", TripleLocationSearchService.search_google),
            ("Foursquare", TripleLocationSearchService.search_foursquare)
        ]
        
        for api_name, search_method in search_methods:
            try:
                result = await asyncio.wait_for(search_method(analysis), timeout=10)
                if result and result.address and result.address.strip():
                    # ì°¸ì¡° ìœ„ì¹˜ì™€ì˜ ê±°ë¦¬ ì²´í¬
                    if reference_location and not _is_reasonable_distance(reference_location, result.address):
                        logger.warning(f"âš ï¸ {api_name} ê²°ê³¼ê°€ ì°¸ì¡° ìœ„ì¹˜ì™€ ë„ˆë¬´ ë©€ì–´ì„œ ì œì™¸: {result.address}")
                        continue
                    
                    schedule["location"] = result.address
                    schedule["latitude"] = result.latitude
                    schedule["longitude"] = result.longitude
                    
                    logger.info(f"âœ… {api_name} ìœ„ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {place_name}")
                    logger.info(f"   ğŸ“ ì£¼ì†Œ: {result.address}")
                    return schedule
                    
            except Exception as e:
                logger.error(f"âŒ {api_name} ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ ëª¨ë“  API ê²€ìƒ‰ ì‹¤íŒ¨: {place_name}")
            
    except Exception as e:
        logger.error(f"âŒ ìœ„ì¹˜ ê²€ìƒ‰ ì˜¤ë¥˜: {place_name}, {e}")
    
    return schedule

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ -----
async def run_in_executor(func, *args, **kwargs):
    """ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor(max_workers=4) as executor:
        return await loop.run_in_executor(executor, func, *args, **kwargs)

def safe_parse_json(json_str):
    """ì•ˆì „í•œ JSON íŒŒì‹±"""
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {
            "fixedSchedules": [],
            "flexibleSchedules": []
        }

def create_schedule_chain():
    """LangChainì„ ì‚¬ìš©í•œ ì¼ì • ì¶”ì¶œ ì²´ì¸ ìƒì„± - 3ê°œ ì¼ì • ê°•ì œ ì¶”ì¶œ"""
    current_time = int(datetime.datetime.now().timestamp() * 1000)
    
    today = datetime.datetime.now()
    tomorrow = today + datetime.timedelta(days=1)
    day_after_tomorrow = today + datetime.timedelta(days=2)
    
    template = """ë‹¤ìŒ ìŒì„± ë©”ì‹œì§€ì—ì„œ **ëª¨ë“  ì¼ì • ì •ë³´**ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ìŒì„± ë©”ì‹œì§€: {input}

í˜„ì¬ ë‚ ì§œ: {today_date}
ë‚´ì¼: {tomorrow_date}
ëª¨ë ˆ: {day_after_tomorrow_date}

**ì¤‘ìš”**: ë©”ì‹œì§€ì— ì–¸ê¸‰ëœ ëª¨ë“  ì¥ì†Œì™€ í™œë™ì„ ê°œë³„ ì¼ì •ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”!

ì˜ˆì‹œ ì…ë ¥: "ì œì£¼ê³µí•­ì—ì„œ ë§Œë‚˜ê³ , ì„±ì‚°ì¼ì¶œë´‰ì—ì„œ ëª¨ì„í•˜ê³ , í‘ë¼ì§€ ë§›ì§‘ì—ì„œ íšŒì‹í• ê±°ì•¼"
â†’ 3ê°œ ì¼ì •: 1) ì œì£¼ê³µí•­ 2) ì„±ì‚°ì¼ì¶œë´‰ 3) í‘ë¼ì§€ ë§›ì§‘ íšŒì‹

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
{{
  "fixedSchedules": [
    {{
      "id": "{current_time}",
      "name": "ì²« ë²ˆì§¸ ì¥ì†Œëª…",
      "type": "FIXED",
      "duration": 60,
      "priority": 1,
      "location": "",
      "latitude": 33.5,
      "longitude": 126.5,
      "startTime": "2025-05-26T10:00:00",
      "endTime": "2025-05-26T11:00:00"
    }},
    {{
      "id": "{current_time_2}",
      "name": "ë‘ ë²ˆì§¸ ì¥ì†Œëª…",
      "type": "FIXED",
      "duration": 60,
      "priority": 2,
      "location": "",
      "latitude": 33.4,
      "longitude": 126.9,
      "startTime": "2025-05-26T12:00:00",
      "endTime": "2025-05-26T13:00:00"
    }},
    {{
      "id": "{current_time_3}",
      "name": "ì„¸ ë²ˆì§¸ ì¥ì†Œëª… (íšŒì‹/ì‹ì‚¬/ëª¨ì„)",
      "type": "FIXED",
      "duration": 120,
      "priority": 3,
      "location": "",
      "latitude": 33.3,
      "longitude": 126.8,
      "startTime": "2025-05-26T18:00:00",
      "endTime": "2025-05-26T20:00:00"
    }}
  ],
  "flexibleSchedules": []
}}

ì£¼ì˜ì‚¬í•­:
1. **ëª¨ë“  ì–¸ê¸‰ëœ ì¥ì†Œë¥¼ ê°œë³„ ì¼ì •ìœ¼ë¡œ ì¶”ì¶œ**
2. íšŒì‹/ì‹ì‚¬ëŠ” durationì„ 120ë¶„ìœ¼ë¡œ ì„¤ì •
3. ì‹œê°„ ê°„ê²©ì„ ë‘ê³  ë°°ì¹˜ (ìµœì†Œ 1ì‹œê°„ ê°„ê²©)
4. "ì£¼ë§"ì€ í† ìš”ì¼(26ì¼)ë¡œ í•´ì„
5. JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€
"""
    
    prompt = PromptTemplate(
        template=template,
        input_variables=["input"],
        partial_variables={
            "current_time": str(current_time),
            "current_time_2": str(current_time + 1),
            "current_time_3": str(current_time + 2),
            "today_date": today.strftime("%Y-%m-%d"),
            "tomorrow_date": tomorrow.strftime("%Y-%m-%d"),
            "day_after_tomorrow_date": day_after_tomorrow.strftime("%Y-%m-%d")
        }
    )
    
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model_name="gpt-4-turbo",
        temperature=0
    )
    
    parser = JsonOutputParser()
    chain = prompt | llm | parser
    
    return chain

# ----- ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ -----
@app.get("/")
async def root():
    return {"message": "3ì¤‘ API (Foursquare+Kakao+Google) ì •í™•í•œ ì£¼ì†Œ ê²€ìƒ‰ ì¼ì • ì¶”ì¶œ API v3.0", "status": "running"}

# app.pyì—ì„œ AddressQualityChecker í´ë˜ìŠ¤ ë’¤ì— ì¶”ê°€ (í´ë˜ìŠ¤ ë°–ì—!)

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ -----
def normalize_priorities(schedules_data: Dict[str, Any]) -> Dict[str, Any]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì •ìˆ˜ë¡œ ì •ê·œí™”"""
    logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ìˆ˜ ë³€í™˜ ì‹œì‘")
    
    all_schedules = []
    all_schedules.extend(schedules_data.get("fixedSchedules", []))
    all_schedules.extend(schedules_data.get("flexibleSchedules", []))
    
    # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    all_schedules.sort(key=lambda s: s.get("priority", 999))
    
    # 1ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ë¡œ ì¬í• ë‹¹
    for i, schedule in enumerate(all_schedules):
        old_priority = schedule.get("priority", "ì—†ìŒ")
        new_priority = i + 1
        schedule["priority"] = new_priority
        logger.info(f"ìš°ì„ ìˆœìœ„ ì •ê·œí™”: '{schedule.get('name', '')}' {old_priority} â†’ {new_priority}")
    
    # ë‹¤ì‹œ ë¶„ë¥˜
    fixed_schedules = [s for s in all_schedules if s.get("type") == "FIXED" and "startTime" in s]
    flexible_schedules = [s for s in all_schedules if s.get("type") != "FIXED" or "startTime" not in s]
    
    logger.info(f"âœ… ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì™„ë£Œ: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
    
    return {
        "fixedSchedules": fixed_schedules,
        "flexibleSchedules": flexible_schedules
    }



# extract_schedule í•¨ìˆ˜ì—ì„œ ì‚¬ìš©
@app.post("/extract-schedule")
async def extract_schedule(request: ScheduleRequest):
    """3ì¤‘ APIë¡œ ì •í™•í•œ ì£¼ì†Œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¼ì • ì¶”ì¶œ API - í•œê¸€ ì¸ì½”ë”© ì§€ì›"""
    start_time = time.time()
    logger.info(f"ğŸ¯ 3ì¤‘ API ì¼ì • ì¶”ì¶œ ì‹œì‘: {request.voice_input}")
    
    try:
        # ... ê¸°ì¡´ ë¡œì§ ë™ì¼ ...
        
        # ğŸ”¥ 1. ê¸°ë³¸ ì¼ì • ì¶”ì¶œ (LLM í˜¸ì¶œ)
        llm_start = time.time()
        chain = create_schedule_chain()
        
        try:
            result = await asyncio.wait_for(
                run_in_executor(lambda: chain.invoke({"input": request.voice_input})),
                timeout=20
            )
            logger.info(f"âœ… LLM ì¶”ì¶œ ì™„ë£Œ: {time.time() - llm_start:.2f}ì´ˆ")
        except asyncio.TimeoutError:
            logger.error("âŒ LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
            return UnicodeJSONResponse(
                content={"fixedSchedules": [], "flexibleSchedules": []},
                status_code=200
            )
        
        # ğŸ”¥ 2. ê²°ê³¼ íŒŒì‹±
        schedule_data = result if isinstance(result, dict) else safe_parse_json(str(result))
        
        # ğŸ”¥ 3. 3ì¤‘ API ìœ„ì¹˜ ì •ë³´ ë³´ê°•
        location_start = time.time()
        enhanced_data = await asyncio.wait_for(
            enhance_locations_with_triple_api(schedule_data),
            timeout=60
        )
        logger.info(f"âœ… 3ì¤‘ API ìœ„ì¹˜ ê²€ìƒ‰ ì™„ë£Œ: {time.time() - location_start:.2f}ì´ˆ")
        
        # ğŸ”¥ 4. ëª¨ë“  ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë“ˆ í™œìš©
        try:
            # ì‹œê°„ ì¶”ë¡ 
            chains = create_enhancement_chain()
            enhanced_data = await asyncio.wait_for(
                run_in_executor(
                    apply_time_inference,
                    chains["time_chain"],
                    request.voice_input,
                    enhanced_data
                ),
                timeout=15
            )
            
            # ìš°ì„ ìˆœìœ„ ë¶„ì„
            enhanced_data = await asyncio.wait_for(
                run_in_executor(
                    apply_priorities,
                    chains["priority_chain"],
                    request.voice_input,
                    enhanced_data
                ),
                timeout=15
            )
            
            # ì¼ì • ê°„ ê´€ê³„ ë¶„ì„
            enhanced_data = await asyncio.wait_for(
                run_in_executor(
                    enhance_schedule_with_relationships,
                    request.voice_input,
                    enhanced_data
                ),
                timeout=10
            )
            
            # ì¶©ëŒ í•´ê²°
            enhanced_data = await asyncio.wait_for(
                run_in_executor(detect_and_resolve_time_conflicts, enhanced_data),
                timeout=10
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°íƒ€ ê°•í™” ì‘ì—… ìŠ¤í‚µ: {e}")
        
        # ğŸ”¥ 5. ìš°ì„ ìˆœìœ„ ì •ê·œí™”
        logger.info("ğŸ”¢ ìš°ì„ ìˆœìœ„ ì •ê·œí™” ì‹œì‘")
        enhanced_data = normalize_priorities(enhanced_data)
        
        # ğŸ”¥ 6. ìµœì¢… ë°ì´í„° ì •ë¦¬
        fixed_schedules = enhanced_data.get("fixedSchedules", [])
        flexible_schedules = enhanced_data.get("flexibleSchedules", [])
        
        # í•œê¸€ ë°ì´í„° ì •ì œ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        def clean_korean_text(text: str) -> str:
            """í•œê¸€ í…ìŠ¤íŠ¸ ì •ì œ"""
            if not text or not isinstance(text, str):
                return ""
            # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ë˜ í•œê¸€ì€ ìœ ì§€
            import re
            # í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ê¸°ë³¸ íŠ¹ìˆ˜ë¬¸ìë§Œ í—ˆìš©
            cleaned = re.sub(r'[^\w\sê°€-í£ã„±-ã…ã…-ã…£.,()-]', '', text)
            return cleaned.strip()
        
        # ëª¨ë“  ìŠ¤ì¼€ì¤„ ë°ì´í„°ì˜ í•œê¸€ í…ìŠ¤íŠ¸ ì •ì œ
        for schedule in fixed_schedules + flexible_schedules:
            if schedule.get("name"):
                schedule["name"] = clean_korean_text(schedule["name"])
            if schedule.get("location"):
                schedule["location"] = clean_korean_text(schedule["location"])
        
        final_data = {
            "fixedSchedules": fixed_schedules,
            "flexibleSchedules": flexible_schedules
        }
        
        total_time = time.time() - start_time
        logger.info(f"ğŸ‰ 3ì¤‘ API ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
        logger.info(f"   ğŸ“Š ê²°ê³¼: ê³ ì • {len(fixed_schedules)}ê°œ, ìœ ì—° {len(flexible_schedules)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ë¡œê¹… (í•œê¸€ í™•ì¸)
        for i, schedule in enumerate(fixed_schedules):
            logger.info(f"   ğŸ”’ ê³ ì • {i+1}: {schedule.get('name')} (ìš°ì„ ìˆœìœ„: {schedule.get('priority')}) - {schedule.get('location')}")
        for i, schedule in enumerate(flexible_schedules):
            logger.info(f"   ğŸ”„ ìœ ì—° {i+1}: {schedule.get('name')} (ìš°ì„ ìˆœìœ„: {schedule.get('priority')}) - {schedule.get('location')}")
        
        # í•œê¸€ì„ ê¹¨ëœ¨ë¦¬ì§€ ì•ŠëŠ” JSON ì‘ë‹µ
        return UnicodeJSONResponse(content=final_data, status_code=200)
            
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return UnicodeJSONResponse(
            content={"fixedSchedules": [], "flexibleSchedules": []},
            status_code=200
        )

# ì„œë²„ ì‹œì‘
if __name__ == "__main__":
    import uvicorn
    
    # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì„œë²„ ì‹œì‘
    uvicorn.run(
        "app:app", 
        host="0.0.0.0", 
        port=8081, 
        reload=True,
        # í•œê¸€ ì§€ì›ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        access_log=True,
        log_config={
            "version": 1,
            "disable_existing_loggers": False,
            "formatters": {
                "default": {
                    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                },
            },
            "handlers": {
                "default": {
                    "formatter": "default",
                    "class": "logging.StreamHandler",
                    "stream": "ext://sys.stdout",
                },
            },
            "root": {
                "level": "INFO",
                "handlers": ["default"],
            },
        }
    )